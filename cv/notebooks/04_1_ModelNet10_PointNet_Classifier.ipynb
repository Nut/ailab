{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PointNet Transfer Learning on subset of ModelNet10\n",
    "\n",
    "\n",
    "The ModelNet10 dataset contains 4899 3D Meshes from 10 different classes.\n",
    "\n",
    "The classes are:\n",
    "\n",
    "* bed\n",
    "* monitor\n",
    "* desk\n",
    "* chair\n",
    "* dresser\n",
    "* toilet\n",
    "* sofa\n",
    "* table\n",
    "* night stand\n",
    "* bathttub \n",
    "\n",
    "We provide you a pretrained version of PointNet. It was trained on 6 of the above 10 classes. Your task is to implement the PointNet Model and train it to classify the other 4 classes using transfer learning.\n",
    "\n",
    "The classes to be learnt are:\n",
    "\n",
    "* desk\n",
    "* chair\n",
    "* toilet \n",
    "* table\n",
    "\n",
    "\n",
    "\n",
    "Tasks:\n",
    "* implement the TODOs\n",
    "* transfer learn the PointNet to achieve an Accuracy > 90%\n",
    "Help:\n",
    "* use the PointNet Paper [clickedy](http://stanford.edu/~rqi/pointnet/)\n",
    "* use the Keras API Documentation [clickedy](https://www.keras.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/site-packages (2.3.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/site-packages (from keras) (1.0.7)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/site-packages (from keras) (1.0.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/site-packages (from keras) (5.1.2)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/site-packages (from keras) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/site-packages (from keras) (1.16.2)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting open3d\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/75/c029e5cf8b7fd491d71f29cf31b9bf7f4a66dba130314cf5cebc367ffa56/open3d-0.8.0.0-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.9MB 13.1MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: widgetsnbextension in /usr/local/lib/python3.6/site-packages (from open3d) (3.4.2)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.6/site-packages (from open3d) (5.7.6)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/site-packages (from open3d) (7.4.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from open3d) (1.16.2)\n",
      "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.6/site-packages (from notebook->open3d) (4.4.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/site-packages (from notebook->open3d) (0.8.1)\n",
      "Requirement already satisfied: tornado<7,>=4.1 in /usr/local/lib/python3.6/site-packages (from notebook->open3d) (6.0.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/site-packages (from notebook->open3d) (2.10)\n",
      "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.6/site-packages (from notebook->open3d) (5.2.4)\n",
      "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/site-packages (from notebook->open3d) (4.4.0)\n",
      "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.6/site-packages (from notebook->open3d) (4.3.2)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/site-packages (from notebook->open3d) (5.4.1)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/site-packages (from notebook->open3d) (1.5.0)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/site-packages (from notebook->open3d) (5.1.0)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.6/site-packages (from notebook->open3d) (0.6.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/site-packages (from notebook->open3d) (0.2.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.6/site-packages (from notebook->open3d) (18.0.1)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/site-packages (from ipywidgets->open3d) (7.3.0)\n",
      "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/site-packages (from terminado>=0.8.1->notebook->open3d) (0.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/site-packages (from jinja2->notebook->open3d) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/site-packages (from jupyter-client>=5.2.0->notebook->open3d) (2.8.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/site-packages (from nbformat->notebook->open3d) (3.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from traitlets>=4.2.1->notebook->open3d) (1.12.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/site-packages (from traitlets>=4.2.1->notebook->open3d) (4.4.0)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.6/site-packages (from nbconvert->notebook->open3d) (2.3.1)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.6/site-packages (from nbconvert->notebook->open3d) (0.4.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/site-packages (from nbconvert->notebook->open3d) (1.4.2)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.6/site-packages (from nbconvert->notebook->open3d) (3.1.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/site-packages (from nbconvert->notebook->open3d) (0.3)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/site-packages (from nbconvert->notebook->open3d) (0.5.0)\n",
      "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/site-packages (from nbconvert->notebook->open3d) (0.8.4)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->open3d) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->open3d) (2.0.9)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->open3d) (4.6.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->open3d) (0.13.3)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->open3d) (0.1.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->open3d) (40.6.3)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook->open3d) (0.14.11)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook->open3d) (19.1.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/site-packages (from bleach->nbconvert->notebook->open3d) (0.5.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->open3d) (0.1.7)\n",
      "Requirement already satisfied: parso>=0.3.0 in /usr/local/lib/python3.6/site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->open3d) (0.3.4)\n",
      "Installing collected packages: open3d\n",
      "Successfully installed open3d-0.8.0.0\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# We need Open3D for the preprocessing\n",
    "%pip install keras\n",
    "%pip install open3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import os\n",
    "\n",
    "from keras.utils import Sequence, to_categorical\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\" \n",
    "\n",
    "%load_ext autoreload\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "# download ModelNet10\n",
    "wget -q http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\n",
    "# unpack\n",
    "unzip -oq ModelNet10.zip\n",
    "# remove Archive\n",
    "rm ModelNet10.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP = [\"chair\", \"desk\", \"toilet\", \"table\"]\n",
    "classes = [f for f in os.scandir(\"ModelNet10/\") if os.path.isdir(f)]\n",
    "\n",
    "import shutil\n",
    "\n",
    "for c in classes:\n",
    "    if c.name not in KEEP:\n",
    "        shutil.rmtree(c.path, ignore_errors=False, onerror=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part One: Data Provider\n",
    "\n",
    "We use the Keras Sequence API to construct a data provider, which feeds our model during training and validation. Fill in all the ToDos to make it work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelNetProvider(Sequence):\n",
    "    \"\"\"\n",
    "    Lazily load point clouds and annotations from filesystem and prepare it for model training.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, batch_size, n_classes, sample_size):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.n_classes = n_classes\n",
    "        self.sample_size = sample_size\n",
    "\n",
    "        # indices of samples used for shuffling\n",
    "        self.indices = np.arange(len(dataset))\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sample_size / self.batch_size # ToDo: Define the length of the generator (Hint: Number of Steps in one Epoch)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data.\"\"\"\n",
    "        batch_indices = np.arange(index, index + self.batch_size) # ToDo: select the indices for the current batch, starting at `index`\n",
    "        batch_samples = self.dataset.iloc[batch_indices]\n",
    "\n",
    "        return self.__generate_data(batch_samples)\n",
    "\n",
    "    def __generate_data(self, batch_samples):\n",
    "        X = []\n",
    "        y = []\n",
    "        for i, row in batch_samples.iterrows():\n",
    "            mesh = o3d.io.read_triangle_mesh((row[\"path\"]))\n",
    "            pcd = mesh.sample_points_uniformly(number_of_points=self.sample_size)\n",
    "            points = np.asarray(pcd.points)\n",
    "            mean_points = points.mean(axis=0)\n",
    "            centered_points = np.asarray([point - mean_points for point in points]) # ToDo center the points to origin\n",
    "\n",
    "            max_points = np.abs(points).max(axis=0)\n",
    "            normalized_points = centered_points / max_points # ToDo normalize the centered points\n",
    "            X.append(normalized_points)\n",
    "            y.append(row[\"class\"])\n",
    "\n",
    "        return self.rotate_point_clouds(np.array(X)), to_categorical(np.array(y), num_classes=self.n_classes)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Shuffle training data, so batches are in different order\"\"\"\n",
    "        np.random.shuffle(self.indices)\n",
    "        \n",
    "        \n",
    "    def rotate_point_clouds(self, batch, rotation_angle_range=(-np.pi/8, np.pi/8)):\n",
    "        \"\"\"Rotate point cloud around y-axis (=up) by random angle\"\"\"\n",
    "        for b, pc in enumerate(batch):\n",
    "            phi = np.random.uniform(*rotation_angle_range)\n",
    "            c, s = np.cos(phi), np.sin(phi)\n",
    "            R = np.matrix([[c, 0, s],\n",
    "                           [0, 1, 0],\n",
    "                           [-s, 0, c]])\n",
    "            batch[b, :, :3] = np.dot(pc[:, :3], R)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[[-0.64640332  0.56898299  0.72879072]\n",
      " [-0.6476602   0.5612188   0.56978877]\n",
      " [-0.65010077  0.67033035  0.52123808]\n",
      " ...\n",
      " [ 0.07026649 -0.65024948 -0.74359898]\n",
      " [ 0.02718147 -0.34075281 -0.76206629]\n",
      " [-0.02285886 -0.90791411 -0.78375115]]\n"
     ]
    }
   ],
   "source": [
    "batch_indices = np.arange(0, 2) # ToDo: select the indices for the current batch, starting at `index`\n",
    "batch_samples = df.iloc[batch_indices]\n",
    "print(batch_indices)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for i, row in batch_samples.iterrows():\n",
    "    mesh = o3d.io.read_triangle_mesh((row[\"path\"]))\n",
    "    pcd = mesh.sample_points_uniformly(number_of_points=500)\n",
    "    points = np.asarray(pcd.points)\n",
    "    #print(points.mean(axis=0))\n",
    "    #print(points)\n",
    "    mean_points = points.mean(axis=0)\n",
    "    centered_points = np.asarray([point - mean_points for point in points]) # ToDo center the points to origin\n",
    "    \n",
    "    max_points = np.abs(points).max(axis=0)\n",
    "    normalized_points = centered_points / max_points # ToDo normalize the centered points\n",
    "    X.append(normalized_points)\n",
    "    y.append(row[\"class\"])\n",
    "\n",
    "print(normalized_points)\n",
    "#[-0.01174359  2.37781578 -0.59867143]\n",
    "#[-0.07872658  1.99953358 -1.0851834 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_dataset(data_directory, file_extension=\".off\"):\n",
    "    \"\"\"\n",
    "    Loads an index to all files and structures them.\n",
    "    :param data_directory: directory containing the data files\n",
    "    :param file_extension: extension of the data files\n",
    "    :return: pandas dataframe containing an index to all files and a label index, \n",
    "        mapping numerical label representations to label names.\n",
    "    \"\"\"\n",
    "    files = [\n",
    "        os.path.join(r, f)  \n",
    "            for r, d, fs in os.walk(data_directory) \n",
    "            for f in fs if f.endswith(file_extension)\n",
    "        ]\n",
    "    \n",
    "    dataframe = pd.DataFrame({\n",
    "        \"path\": files,\n",
    "        \"class\": pd.Categorical([f.rsplit(\"/\", 3)[1] for f in files]),\n",
    "        \"is_train\": [\"train\" in f for f in files]\n",
    "    })\n",
    "    \n",
    "    factorization = dataframe[\"class\"].factorize()\n",
    "    dataframe[\"class\"] = factorization[0]\n",
    "    \n",
    "    return dataframe, factorization[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two: PointNet Architecture\n",
    "\n",
    "Implement all the missing code pieces to complete the whole architecture. Follow the description in the paper or use the image below. If your model definition is right, you should be able to load our pretrained weigths without an error. \n",
    "\n",
    "We provided the definition of the T-Net, so you don't need to implement it on your own. If you are interested in the implementation details, just have a look at the pointnet_utils.py file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PointNet Architecture](http://stanford.edu/~rqi/pointnet/images/pointnet.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Input, Dropout, Dense, Dot, Lambda, \\\n",
    "    Reshape, concatenate, GlobalMaxPooling1D, BatchNormalization, \\\n",
    "    Activation, Conv1D, Multiply\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "from pointnet_utils import transform_net\n",
    "\n",
    "def conv1d_bn(x, num_filters, kernel_size, padding='same', strides=1,\n",
    "              use_bias=False, scope=None, activation='relu'):\n",
    "    \"\"\"\n",
    "    Utility function to apply Convolution + Batch Normalization.\n",
    "    \"\"\"\n",
    "    with K.name_scope(scope):\n",
    "        input_shape = x.get_shape().as_list()[-2:]\n",
    "        x = Conv1D(input_shape=input_shape, filters=num_filters, kernel_size=kernel_size, padding=padding, strides=strides,\n",
    "              use_bias=use_bias, activation=activation)(x) # ToDo define the Convolutional Part of this Layer\n",
    "        x = BatchNormalization()(x) # ToDo add BatchNormalization\n",
    "        x = Activation(activation)(x) # ToDo add activation function\n",
    "    return x\n",
    "\n",
    "\n",
    "def dense_bn(x, units, use_bias=True, scope=None, activation=None):\n",
    "    \"\"\"\n",
    "    Utility function to apply Dense + Batch Normalization.\n",
    "    \"\"\"\n",
    "    with K.name_scope(scope):\n",
    "        x = Dense(units, use_bias=use_bias, activation=activation)(x)# ToDo Add Dense Part of this Layer\n",
    "        x = BatchNormalization()(x) # ToDo add BatchNormalization\n",
    "        x = Activation(activation)(x) # ToDo add activation function\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointnet(input_shape, classes):\n",
    "    \"\"\"\n",
    "    PointNet Model definition for classification.\n",
    "    :param input_shape: The point cloud shape\n",
    "    :param classes: Number of classes in output.\n",
    "    :return: PointNet Model for classification with `classes` classes.\n",
    "    \"\"\"\n",
    "    # Generate input tensor\n",
    "    inputs = Input(shape=input_shape)# ToDo define Input-Layer\n",
    "\n",
    "    # Obtain spatial point transform from inputs and convert inputs\n",
    "    ptransform = transform_net(inputs, dense_bn, conv1d_bn, scope='transform_net1', regularize=False)\n",
    "    point_cloud_transformed = Dot(axes = (2, 1))([inputs, ptransform]) # ToDo Perform the matrix multiply between ptransform and inputs\n",
    "\n",
    "    # First block of convolutions\n",
    "    net = conv1d_bn(point_cloud_transformed, num_filters=64, kernel_size=(1), scope='First_block', use_bias=True) # ToDo, define first Conv-Layer\n",
    "    net = conv1d_bn(net, num_filters=64, kernel_size=(1), scope='First_block', use_bias=True)# ToDo, define second Conv-Layer\n",
    "\n",
    "    # Obtain feature transform and apply it to the network\n",
    "    ftransform = transform_net(net, dense_bn, conv1d_bn, scope='transform_net2', regularize=True)\n",
    "    net_transformed = Dot(axes = (2, 1))([net, ftransform])# ToDo Perform the matrix multiply between ftransform and net\n",
    "\n",
    "    # Second block of convolutions\n",
    "    net = conv1d_bn(net_transformed, num_filters=64, kernel_size=(1), scope='Second_block', use_bias=True) # ToDo, define third Conv-Layer\n",
    "    net = conv1d_bn(net, num_filters=128, kernel_size=(1), scope='Second_block', use_bias=True) # ToDo, define fourth Conv-Layer\n",
    "    net = conv1d_bn(net, num_filters=1024, kernel_size=(1), scope='Second_block', use_bias=True) # ToDo, define fifth Conv-Layer\n",
    "\n",
    "    # add Maxpooling \n",
    "    net = GlobalMaxPooling1D()(net)# Todo define MaxPool Layer\n",
    "\n",
    "    # Top layers\n",
    "    net = dense_bn(net, 512, scope='embedding_layer')# ToDo, define first Dense-Layer\n",
    "    net = Dropout(0.2)(net) # ToDo, define first Dropout-Layer\n",
    "    net = dense_bn(net, 256, scope='embedding_layer')# ToDo, define second Dense-Layer\n",
    "    net = Dropout(0.2)(net)# ToDo, define second Dropout-Layer\n",
    "    #net = dense_bn(net, classes, scope='embedding_layer', activation = 'softmax')# ToDo, define third Dense-Layer\n",
    "    net = Dense(units=classes, use_bias=True, activation='softmax')(net)\n",
    "\n",
    "    model = Model(inputs, net, name='pointnet')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Three: Transfer Learning of the PointNet\n",
    "\n",
    "Load the pretrained weigths for PointNet and change the output to four classes. Define all Hyperparameters and implement the train/test and your own learning rate scheduling algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pointnet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_50 (InputLayer)           (None, None, 3)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_313 (Conv1D)             (None, None, 64)     256         input_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_485 (BatchN (None, None, 64)     256         conv1d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_485 (Activation)     (None, None, 64)     0           batch_normalization_485[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_314 (Conv1D)             (None, None, 128)    8320        activation_485[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_486 (BatchN (None, None, 128)    512         conv1d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_486 (Activation)     (None, None, 128)    0           batch_normalization_486[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_315 (Conv1D)             (None, None, 1024)   132096      activation_486[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_487 (BatchN (None, None, 1024)   4096        conv1d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_487 (Activation)     (None, None, 1024)   0           batch_normalization_487[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_87 (Global (None, 1024)         0           activation_487[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_253 (Dense)               (None, 512)          524800      global_max_pooling1d_87[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_488 (BatchN (None, 512)          2048        dense_253[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_488 (Activation)     (None, 512)          0           batch_normalization_488[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_254 (Dense)               (None, 256)          131328      activation_488[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_489 (BatchN (None, 256)          1024        dense_254[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_489 (Activation)     (None, 256)          0           batch_normalization_489[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_255 (Dense)               (None, 9)            2313        activation_489[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_69 (Reshape)            (None, 3, 3)         0           dense_255[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_53 (Dot)                    (None, None, 3)      0           input_50[0][0]                   \n",
      "                                                                 reshape_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_316 (Conv1D)             (None, None, 64)     256         dot_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_490 (BatchN (None, None, 64)     256         conv1d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_490 (Activation)     (None, None, 64)     0           batch_normalization_490[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_317 (Conv1D)             (None, None, 64)     4160        activation_490[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_491 (BatchN (None, None, 64)     256         conv1d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_491 (Activation)     (None, None, 64)     0           batch_normalization_491[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_318 (Conv1D)             (None, None, 64)     4160        activation_491[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_492 (BatchN (None, None, 64)     256         conv1d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_492 (Activation)     (None, None, 64)     0           batch_normalization_492[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_319 (Conv1D)             (None, None, 128)    8320        activation_492[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_493 (BatchN (None, None, 128)    512         conv1d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_493 (Activation)     (None, None, 128)    0           batch_normalization_493[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_320 (Conv1D)             (None, None, 1024)   132096      activation_493[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_494 (BatchN (None, None, 1024)   4096        conv1d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_494 (Activation)     (None, None, 1024)   0           batch_normalization_494[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_88 (Global (None, 1024)         0           activation_494[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_256 (Dense)               (None, 512)          524800      global_max_pooling1d_88[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_495 (BatchN (None, 512)          2048        dense_256[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_495 (Activation)     (None, 512)          0           batch_normalization_495[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_257 (Dense)               (None, 256)          131328      activation_495[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_496 (BatchN (None, 256)          1024        dense_257[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_496 (Activation)     (None, 256)          0           batch_normalization_496[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_258 (Dense)               (None, 4096)         1052672     activation_496[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_70 (Reshape)            (None, 64, 64)       0           dense_258[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_54 (Dot)                    (None, None, 64)     0           activation_491[0][0]             \n",
      "                                                                 reshape_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_321 (Conv1D)             (None, None, 64)     4160        dot_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_497 (BatchN (None, None, 64)     256         conv1d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_497 (Activation)     (None, None, 64)     0           batch_normalization_497[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_322 (Conv1D)             (None, None, 128)    8320        activation_497[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_498 (BatchN (None, None, 128)    512         conv1d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_498 (Activation)     (None, None, 128)    0           batch_normalization_498[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_323 (Conv1D)             (None, None, 1024)   132096      activation_498[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_499 (BatchN (None, None, 1024)   4096        conv1d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_499 (Activation)     (None, None, 1024)   0           batch_normalization_499[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_89 (Global (None, 1024)         0           activation_499[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_259 (Dense)               (None, 512)          524800      global_max_pooling1d_89[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_500 (BatchN (None, 512)          2048        dense_259[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_500 (Activation)     (None, 512)          0           batch_normalization_500[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 512)          0           activation_500[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_260 (Dense)               (None, 256)          131328      dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_501 (BatchN (None, 256)          1024        dense_260[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_501 (Activation)     (None, 256)          0           batch_normalization_501[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 256)          0           activation_501[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_261 (Dense)               (None, 6)            1542        dropout_29[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,483,471\n",
      "Trainable params: 3,471,311\n",
      "Non-trainable params: 12,160\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = pointnet((None, 3), 6)\n",
    "pretrained_model.summary()\n",
    "pretrained_model.load_weights(\"pretrained-modelnet.h5\")\n",
    "\n",
    "# We need to replace the last layer, because it was trained to predict 6 classes instead of 4.\n",
    "#embedding_layer = pretrained_model.# ToDo find \"embedding layer\" (The layer before the old softmax layer)\n",
    "#outputs = # ToDo Define new Output Layer\n",
    "#new_model = Model(inputs=pretrained_model.inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define Hyperparameters\n",
    "SAMPLE_SIZE = \n",
    "EPOCHS = \n",
    "TRAIN_TEST_SPLIT = \n",
    "BATCH_SIZE ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(samples, atFraction):\n",
    "    \"\"\"\n",
    "    Perform the train/test split.\n",
    "    \"\"\"\n",
    "    print(\"atFraction = \", atFraction)\n",
    "    \n",
    "    # ToDo perform the train/test split.\n",
    "    pass\n",
    "\n",
    "\n",
    "def reduce_learning_rate(epoch, currentLearningRate):\n",
    "    \"\"\"\n",
    "    Implements adaptive learning rate scheduling.\n",
    "    \"\"\"\n",
    "    # ToDo define your own learning rate schedule.\n",
    "    return currentLearningRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, l_idx = initialize_dataset(\"ModelNet10/\")\n",
    "\n",
    "train_samples, validation_samples = random_split(df[df[\"is_train\"]], TRAIN_TEST_SPLIT)\n",
    "test_samples = df[~df[\"is_train\"]]\n",
    "\n",
    "print(\"Number of training samples: \", len(train_samples))\n",
    "print(\"Number of validation samples: \", len(validation_samples))\n",
    "print(\"Number of hold out test samples: \", len(test_samples))\n",
    "\n",
    "generator_training = ModelNetProvider(train_samples, batch_size=BATCH_SIZE, n_classes=4, sample_size=SAMPLE_SIZE)\n",
    "generator_validation = ModelNetProvider(validation_samples, batch_size=BATCH_SIZE, n_classes=4, sample_size=SAMPLE_SIZE)\n",
    "\n",
    "\n",
    "new_model.compile(optimizer=\"adam\", loss='categorical_crossentropy',\n",
    "              metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.LearningRateScheduler(reduce_learning_rate, verbose=1),\n",
    "    keras.callbacks.TensorBoard(\"logs/\", batch_size=BATCH_SIZE),\n",
    "    keras.callbacks.ModelCheckpoint(\"checkpoints/weights.{epoch:03d}-{val_loss:.2f}.h5\", save_weights_only=True, save_best_only=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "new_model.fit_generator(generator=generator_training, epochs=EPOCHS, callbacks=callbacks, \n",
    "                    validation_data=generator_validation, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate model\n",
    "generator_test = ModelNetProvider(test_samples, batch_size=1, n_classes=4, sample_size=SAMPLE_SIZE)\n",
    "\n",
    "val_df = pd.DataFrame({\"prediction\": [], \"ground_truth\": []})\n",
    "for i in range(len(generator_test)):\n",
    "    X, y = generator_test[i]\n",
    "    prediction = new_model.predict(X)\n",
    "    val_df = val_df.append({\"prediction\": l_idx[np.argmax(prediction)],  \"ground_truth\": l_idx[np.argmax(y)]}, \n",
    "                  ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_context('talk')\n",
    "palette = sns.color_palette(n_colors=6)\n",
    "\n",
    "cm = metrics.confusion_matrix(val_df.ground_truth, val_df.prediction)\n",
    "confusionMatrix = pd.DataFrame(cm, index=l_idx, columns=l_idx)\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "sns.heatmap(confusionMatrix, vmin=0, annot=True, fmt=\"d\", linewidth=.5, mask=(confusionMatrix==0), cmap=\"viridis\")\n",
    "plt.xlabel(\"Prediction\")\n",
    "plt.ylabel(\"Truth\")\n",
    "plt.ylim(4, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
