{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "text_generation_empty.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNTGXyR7VeM4",
        "colab_type": "text"
      },
      "source": [
        "# Textgenerierung\n",
        "\n",
        "Auch in dieser Woche beschäftigen wir uns mit Twitter-Daten. Diesmal geht es jedoch nicht um Sentiment Analysis, sondern wir wollen ein Modell trainieren, das es uns erlaubt, Tweets in einem bestimmten Stil zu generieren.\n",
        "\n",
        "Als Datengrundlage dienen uns Daten von http://www.trumptwitterarchive.com. Brendan Brown, der Betreiber der Seite hat sämtliche Tweets von Donald Trump seit Mai 2009 zusammengetragen. Da wir die Sprache des US-Präsidenten modellieren wollen, verwenden wir nur dessen eigene und keine Retweets.\n",
        "\n",
        "Unser Modell wird auf der Ebene von Einzelzeichen arbeiten, zunächst wollen wir uns aber auf einer höheren Ebene einen Überblick über den Datensatz verschaffen.\n",
        "\n",
        "## 1. Aufgabe: Überblick über den Datensatz\n",
        "### 1.1 Datensatz einlesen\n",
        "Lest den in der Datei ```all_tweets.json``` enthaltenen Datensatz in einen Pandas-Dataframe mit folgenden Spalten ein: ```created_at```, ```id```, ```text```. Die übrigen im JSON enthaltenen Felder können ignoriert werden.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tFDCyI7VeM8",
        "colab_type": "code",
        "outputId": "45cae460-6f37-4566-a5f3-5e491cbf2617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        }
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/data')\n",
        "\n",
        "tweets = pd.read_json('/data/My Drive/Colab Notebooks/data/all_tweets.json')\n",
        "\n",
        "tweets"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>text</th>\n",
              "      <th>created_at</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>is_retweet</th>\n",
              "      <th>id_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Will be interviewed by @MariaBartiromo on @Fox...</td>\n",
              "      <td>2019-04-28 12:59:53+00:00</td>\n",
              "      <td>4392</td>\n",
              "      <td>15808</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1122485588580605952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>....for the more traditional, but not very bri...</td>\n",
              "      <td>2019-04-28 03:10:25+00:00</td>\n",
              "      <td>13425</td>\n",
              "      <td>60142</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1122337243744497664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>The Democratic National Committee, sometimes r...</td>\n",
              "      <td>2019-04-28 03:10:24+00:00</td>\n",
              "      <td>13243</td>\n",
              "      <td>57238</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1122337240330297344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>....Ever since Andrew came to my office to ask...</td>\n",
              "      <td>2019-04-28 02:57:32+00:00</td>\n",
              "      <td>15124</td>\n",
              "      <td>58221</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1122334000519868416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Thank you to brilliant and highly respected at...</td>\n",
              "      <td>2019-04-28 02:57:31+00:00</td>\n",
              "      <td>15886</td>\n",
              "      <td>65548</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1122333996451418112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25690</th>\n",
              "      <td>Twitter Web Client</td>\n",
              "      <td>\"My persona will never be that of a wallflower...</td>\n",
              "      <td>2009-05-12 14:07:28+00:00</td>\n",
              "      <td>1421</td>\n",
              "      <td>1950</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1773561338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25691</th>\n",
              "      <td>Twitter Web Client</td>\n",
              "      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n",
              "      <td>2009-05-08 20:40:15+00:00</td>\n",
              "      <td>8</td>\n",
              "      <td>27</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1741160716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25692</th>\n",
              "      <td>Twitter Web Client</td>\n",
              "      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n",
              "      <td>2009-05-08 13:38:08+00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1737479987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25693</th>\n",
              "      <td>Twitter Web Client</td>\n",
              "      <td>Donald Trump will be appearing on The View tom...</td>\n",
              "      <td>2009-05-05 01:00:10+00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1701461182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25694</th>\n",
              "      <td>Twitter Web Client</td>\n",
              "      <td>Be sure to tune in and watch Donald Trump on L...</td>\n",
              "      <td>2009-05-04 18:54:25+00:00</td>\n",
              "      <td>253</td>\n",
              "      <td>202</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1698308935</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25695 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   source  ...               id_str\n",
              "0      Twitter for iPhone  ...  1122485588580605952\n",
              "1      Twitter for iPhone  ...  1122337243744497664\n",
              "2      Twitter for iPhone  ...  1122337240330297344\n",
              "3      Twitter for iPhone  ...  1122334000519868416\n",
              "4      Twitter for iPhone  ...  1122333996451418112\n",
              "...                   ...  ...                  ...\n",
              "25690  Twitter Web Client  ...           1773561338\n",
              "25691  Twitter Web Client  ...           1741160716\n",
              "25692  Twitter Web Client  ...           1737479987\n",
              "25693  Twitter Web Client  ...           1701461182\n",
              "25694  Twitter Web Client  ...           1698308935\n",
              "\n",
              "[25695 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF51qtxuVeNG",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Jahr hinzufügen\n",
        "Für unsere Auswertungen interessiert uns nur das Jahr, in dem der Tweet verfasst wurde, nicht das genaue Datum. Wir fügen daher dem Dataframe eine zusätzliche Spalte ```year``` hinzu. Hierbei kann zum Beispiel die Pandas-Funktion ```DatetimeIndex``` verwendet werden, um aus dem ```created_at``` String einen DatetimeIndex zu machen, auf dessen einzelne Felder (```year```, ```month```, ```day```, ...) dann mittels Punktoperator zugegriffen werden kann."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLOW0mboVeNI",
        "colab_type": "code",
        "outputId": "ff9b6872-986c-437a-9a71-ef2acc847f67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        }
      },
      "source": [
        "tweets['year'] = tweets.apply(lambda row: pd.to_datetime(row['created_at']).year, axis=1)\n",
        "tweets"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>text</th>\n",
              "      <th>created_at</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>is_retweet</th>\n",
              "      <th>id_str</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Will be interviewed by @MariaBartiromo on @Fox...</td>\n",
              "      <td>2019-04-28 12:59:53+00:00</td>\n",
              "      <td>4392</td>\n",
              "      <td>15808</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1122485588580605952</td>\n",
              "      <td>2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>....for the more traditional, but not very bri...</td>\n",
              "      <td>2019-04-28 03:10:25+00:00</td>\n",
              "      <td>13425</td>\n",
              "      <td>60142</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1122337243744497664</td>\n",
              "      <td>2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>The Democratic National Committee, sometimes r...</td>\n",
              "      <td>2019-04-28 03:10:24+00:00</td>\n",
              "      <td>13243</td>\n",
              "      <td>57238</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1122337240330297344</td>\n",
              "      <td>2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>....Ever since Andrew came to my office to ask...</td>\n",
              "      <td>2019-04-28 02:57:32+00:00</td>\n",
              "      <td>15124</td>\n",
              "      <td>58221</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1122334000519868416</td>\n",
              "      <td>2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Thank you to brilliant and highly respected at...</td>\n",
              "      <td>2019-04-28 02:57:31+00:00</td>\n",
              "      <td>15886</td>\n",
              "      <td>65548</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1122333996451418112</td>\n",
              "      <td>2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25690</th>\n",
              "      <td>Twitter Web Client</td>\n",
              "      <td>\"My persona will never be that of a wallflower...</td>\n",
              "      <td>2009-05-12 14:07:28+00:00</td>\n",
              "      <td>1421</td>\n",
              "      <td>1950</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1773561338</td>\n",
              "      <td>2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25691</th>\n",
              "      <td>Twitter Web Client</td>\n",
              "      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n",
              "      <td>2009-05-08 20:40:15+00:00</td>\n",
              "      <td>8</td>\n",
              "      <td>27</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1741160716</td>\n",
              "      <td>2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25692</th>\n",
              "      <td>Twitter Web Client</td>\n",
              "      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n",
              "      <td>2009-05-08 13:38:08+00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1737479987</td>\n",
              "      <td>2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25693</th>\n",
              "      <td>Twitter Web Client</td>\n",
              "      <td>Donald Trump will be appearing on The View tom...</td>\n",
              "      <td>2009-05-05 01:00:10+00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1701461182</td>\n",
              "      <td>2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25694</th>\n",
              "      <td>Twitter Web Client</td>\n",
              "      <td>Be sure to tune in and watch Donald Trump on L...</td>\n",
              "      <td>2009-05-04 18:54:25+00:00</td>\n",
              "      <td>253</td>\n",
              "      <td>202</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1698308935</td>\n",
              "      <td>2009</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25695 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   source  ...  year\n",
              "0      Twitter for iPhone  ...  2019\n",
              "1      Twitter for iPhone  ...  2019\n",
              "2      Twitter for iPhone  ...  2019\n",
              "3      Twitter for iPhone  ...  2019\n",
              "4      Twitter for iPhone  ...  2019\n",
              "...                   ...  ...   ...\n",
              "25690  Twitter Web Client  ...  2009\n",
              "25691  Twitter Web Client  ...  2009\n",
              "25692  Twitter Web Client  ...  2009\n",
              "25693  Twitter Web Client  ...  2009\n",
              "25694  Twitter Web Client  ...  2009\n",
              "\n",
              "[25695 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DRZ1Tv7VeNW",
        "colab_type": "text"
      },
      "source": [
        "### 1.3 Textlänge analysieren\n",
        "Naturgemäß gibt es bei Tweets nur eine begrenzte Varianz, was die Textlänge angeht. Wir wollen uns dennoch anschauen, wie sich die Textlänge im Laufe der Jahre entwickelt hat.\n",
        "Dazu fügen wir unserem Dataframe zunächst eine Spalte ```text_length``` hinzu, in der wir festhalten, welche Länge der jeweilige Tweet-Text hat.\n",
        "\n",
        "**Hinweis**\n",
        "Mittels ```apply``` lassen sich Funktionen auf Spalten des Dataframes mappen: ```df['new'] = df['old'].apply(lambda x : fancy_stuff(x))```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh8yM22VVeNY",
        "colab_type": "code",
        "outputId": "4a21b55d-4b1f-4d08-8422-2dd25e5cd7be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        }
      },
      "source": [
        "tweets['text_length'] = tweets.apply(lambda row: len(row['text']), axis=1) # TODO Spalte füllen\n",
        "tweets"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>text</th>\n",
              "      <th>created_at</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>is_retweet</th>\n",
              "      <th>id_str</th>\n",
              "      <th>year</th>\n",
              "      <th>text_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Will be interviewed by @MariaBartiromo on @Fox...</td>\n",
              "      <td>2019-04-28 12:59:53+00:00</td>\n",
              "      <td>4392</td>\n",
              "      <td>15808</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1122485588580605952</td>\n",
              "      <td>2019</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>....for the more traditional, but not very bri...</td>\n",
              "      <td>2019-04-28 03:10:25+00:00</td>\n",
              "      <td>13425</td>\n",
              "      <td>60142</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1122337243744497664</td>\n",
              "      <td>2019</td>\n",
              "      <td>177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>The Democratic National Committee, sometimes r...</td>\n",
              "      <td>2019-04-28 03:10:24+00:00</td>\n",
              "      <td>13243</td>\n",
              "      <td>57238</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1122337240330297344</td>\n",
              "      <td>2019</td>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>....Ever since Andrew came to my office to ask...</td>\n",
              "      <td>2019-04-28 02:57:32+00:00</td>\n",
              "      <td>15124</td>\n",
              "      <td>58221</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1122334000519868416</td>\n",
              "      <td>2019</td>\n",
              "      <td>214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Thank you to brilliant and highly respected at...</td>\n",
              "      <td>2019-04-28 02:57:31+00:00</td>\n",
              "      <td>15886</td>\n",
              "      <td>65548</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1122333996451418112</td>\n",
              "      <td>2019</td>\n",
              "      <td>145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25690</th>\n",
              "      <td>Twitter Web Client</td>\n",
              "      <td>\"My persona will never be that of a wallflower...</td>\n",
              "      <td>2009-05-12 14:07:28+00:00</td>\n",
              "      <td>1421</td>\n",
              "      <td>1950</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1773561338</td>\n",
              "      <td>2009</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25691</th>\n",
              "      <td>Twitter Web Client</td>\n",
              "      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n",
              "      <td>2009-05-08 20:40:15+00:00</td>\n",
              "      <td>8</td>\n",
              "      <td>27</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1741160716</td>\n",
              "      <td>2009</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25692</th>\n",
              "      <td>Twitter Web Client</td>\n",
              "      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n",
              "      <td>2009-05-08 13:38:08+00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1737479987</td>\n",
              "      <td>2009</td>\n",
              "      <td>116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25693</th>\n",
              "      <td>Twitter Web Client</td>\n",
              "      <td>Donald Trump will be appearing on The View tom...</td>\n",
              "      <td>2009-05-05 01:00:10+00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1701461182</td>\n",
              "      <td>2009</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25694</th>\n",
              "      <td>Twitter Web Client</td>\n",
              "      <td>Be sure to tune in and watch Donald Trump on L...</td>\n",
              "      <td>2009-05-04 18:54:25+00:00</td>\n",
              "      <td>253</td>\n",
              "      <td>202</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1698308935</td>\n",
              "      <td>2009</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25695 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   source  ... text_length\n",
              "0      Twitter for iPhone  ...         191\n",
              "1      Twitter for iPhone  ...         177\n",
              "2      Twitter for iPhone  ...         144\n",
              "3      Twitter for iPhone  ...         214\n",
              "4      Twitter for iPhone  ...         145\n",
              "...                   ...  ...         ...\n",
              "25690  Twitter Web Client  ...         109\n",
              "25691  Twitter Web Client  ...         103\n",
              "25692  Twitter Web Client  ...         116\n",
              "25693  Twitter Web Client  ...         131\n",
              "25694  Twitter Web Client  ...         117\n",
              "\n",
              "[25695 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQb0WDfqVeNd",
        "colab_type": "text"
      },
      "source": [
        "Für einen groben Überblick schauen wir uns einige Kennzahlen zur Textlänge an. Dazu gruppieren wir nach ```year```und nutzen dann die ```describe```-Methode des Dataframes, wobei wir nur Spalten vom Typ ```numpy.number``` betrachten und daher der ```describe```-Methode eine entsprechende ```include```-Liste mitgeben."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbo727gEVeNe",
        "colab_type": "code",
        "outputId": "7b955d3d-1e09-4729-b7d9-0e1ef6fc86f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "source": [
        "import numpy as np\n",
        "tweets.groupby(tweets['year']).describe(include=[np.number])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"8\" halign=\"left\">retweet_count</th>\n",
              "      <th colspan=\"8\" halign=\"left\">favorite_count</th>\n",
              "      <th colspan=\"8\" halign=\"left\">is_retweet</th>\n",
              "      <th colspan=\"8\" halign=\"left\">id_str</th>\n",
              "      <th colspan=\"8\" halign=\"left\">year</th>\n",
              "      <th colspan=\"8\" halign=\"left\">text_length</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>year</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2009</th>\n",
              "      <td>56.0</td>\n",
              "      <td>39.071429</td>\n",
              "      <td>191.165503</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.00</td>\n",
              "      <td>1421.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>50.089286</td>\n",
              "      <td>260.351320</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>6.5</td>\n",
              "      <td>14.00</td>\n",
              "      <td>1950.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>2.896500e+09</td>\n",
              "      <td>1.386292e+09</td>\n",
              "      <td>1.698309e+09</td>\n",
              "      <td>1.863037e+09</td>\n",
              "      <td>2.280281e+09</td>\n",
              "      <td>3.462656e+09</td>\n",
              "      <td>6.971080e+09</td>\n",
              "      <td>56.0</td>\n",
              "      <td>2009.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2009.0</td>\n",
              "      <td>2009.0</td>\n",
              "      <td>2009.0</td>\n",
              "      <td>2009.0</td>\n",
              "      <td>2009.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>112.214286</td>\n",
              "      <td>20.056932</td>\n",
              "      <td>62.0</td>\n",
              "      <td>103.75</td>\n",
              "      <td>115.0</td>\n",
              "      <td>126.25</td>\n",
              "      <td>140.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010</th>\n",
              "      <td>142.0</td>\n",
              "      <td>79.380282</td>\n",
              "      <td>417.097668</td>\n",
              "      <td>3.0</td>\n",
              "      <td>12.00</td>\n",
              "      <td>21.0</td>\n",
              "      <td>36.75</td>\n",
              "      <td>3813.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>64.676056</td>\n",
              "      <td>466.223070</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.00</td>\n",
              "      <td>4559.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>1.440030e+15</td>\n",
              "      <td>4.090839e+15</td>\n",
              "      <td>7.677152e+09</td>\n",
              "      <td>1.318076e+10</td>\n",
              "      <td>1.753370e+10</td>\n",
              "      <td>2.455505e+10</td>\n",
              "      <td>2.059549e+16</td>\n",
              "      <td>142.0</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>122.528169</td>\n",
              "      <td>21.394536</td>\n",
              "      <td>45.0</td>\n",
              "      <td>111.00</td>\n",
              "      <td>132.5</td>\n",
              "      <td>138.00</td>\n",
              "      <td>140.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011</th>\n",
              "      <td>774.0</td>\n",
              "      <td>187.506460</td>\n",
              "      <td>556.265788</td>\n",
              "      <td>3.0</td>\n",
              "      <td>38.00</td>\n",
              "      <td>95.5</td>\n",
              "      <td>209.00</td>\n",
              "      <td>13689.0</td>\n",
              "      <td>774.0</td>\n",
              "      <td>73.599483</td>\n",
              "      <td>590.011693</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.00</td>\n",
              "      <td>15.0</td>\n",
              "      <td>27.00</td>\n",
              "      <td>15457.0</td>\n",
              "      <td>774.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>774.0</td>\n",
              "      <td>1.163851e+17</td>\n",
              "      <td>2.985790e+16</td>\n",
              "      <td>2.521253e+16</td>\n",
              "      <td>1.009352e+17</td>\n",
              "      <td>1.214507e+17</td>\n",
              "      <td>1.416105e+17</td>\n",
              "      <td>1.528272e+17</td>\n",
              "      <td>774.0</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>774.0</td>\n",
              "      <td>107.739018</td>\n",
              "      <td>27.061936</td>\n",
              "      <td>38.0</td>\n",
              "      <td>86.00</td>\n",
              "      <td>114.0</td>\n",
              "      <td>133.00</td>\n",
              "      <td>140.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012</th>\n",
              "      <td>3530.0</td>\n",
              "      <td>457.685836</td>\n",
              "      <td>3625.044171</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.00</td>\n",
              "      <td>125.0</td>\n",
              "      <td>308.75</td>\n",
              "      <td>141644.0</td>\n",
              "      <td>3530.0</td>\n",
              "      <td>233.687819</td>\n",
              "      <td>2747.058763</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.00</td>\n",
              "      <td>26.0</td>\n",
              "      <td>77.00</td>\n",
              "      <td>99141.0</td>\n",
              "      <td>3530.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3530.0</td>\n",
              "      <td>2.338664e+17</td>\n",
              "      <td>3.690381e+16</td>\n",
              "      <td>1.542710e+17</td>\n",
              "      <td>2.047411e+17</td>\n",
              "      <td>2.456090e+17</td>\n",
              "      <td>2.636903e+17</td>\n",
              "      <td>2.847717e+17</td>\n",
              "      <td>3530.0</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>3530.0</td>\n",
              "      <td>106.975921</td>\n",
              "      <td>32.147123</td>\n",
              "      <td>12.0</td>\n",
              "      <td>87.00</td>\n",
              "      <td>117.0</td>\n",
              "      <td>135.00</td>\n",
              "      <td>148.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013</th>\n",
              "      <td>5775.0</td>\n",
              "      <td>239.694719</td>\n",
              "      <td>1613.828343</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>29.0</td>\n",
              "      <td>182.00</td>\n",
              "      <td>60747.0</td>\n",
              "      <td>5775.0</td>\n",
              "      <td>161.064589</td>\n",
              "      <td>1422.672765</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>22.0</td>\n",
              "      <td>101.00</td>\n",
              "      <td>57700.0</td>\n",
              "      <td>5775.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5775.0</td>\n",
              "      <td>3.391614e+17</td>\n",
              "      <td>3.727767e+16</td>\n",
              "      <td>2.861273e+17</td>\n",
              "      <td>3.063865e+17</td>\n",
              "      <td>3.300694e+17</td>\n",
              "      <td>3.699051e+17</td>\n",
              "      <td>4.181450e+17</td>\n",
              "      <td>5775.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>5775.0</td>\n",
              "      <td>86.123983</td>\n",
              "      <td>43.081747</td>\n",
              "      <td>9.0</td>\n",
              "      <td>41.00</td>\n",
              "      <td>94.0</td>\n",
              "      <td>128.00</td>\n",
              "      <td>152.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014</th>\n",
              "      <td>2433.0</td>\n",
              "      <td>332.652692</td>\n",
              "      <td>1283.491376</td>\n",
              "      <td>0.0</td>\n",
              "      <td>28.00</td>\n",
              "      <td>123.0</td>\n",
              "      <td>360.00</td>\n",
              "      <td>34453.0</td>\n",
              "      <td>2433.0</td>\n",
              "      <td>332.122483</td>\n",
              "      <td>1241.712941</td>\n",
              "      <td>0.0</td>\n",
              "      <td>47.00</td>\n",
              "      <td>155.0</td>\n",
              "      <td>359.00</td>\n",
              "      <td>34807.0</td>\n",
              "      <td>2433.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2433.0</td>\n",
              "      <td>4.880322e+17</td>\n",
              "      <td>3.704741e+16</td>\n",
              "      <td>4.183651e+17</td>\n",
              "      <td>4.573088e+17</td>\n",
              "      <td>4.893819e+17</td>\n",
              "      <td>5.208777e+17</td>\n",
              "      <td>5.503998e+17</td>\n",
              "      <td>2433.0</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>2433.0</td>\n",
              "      <td>114.132758</td>\n",
              "      <td>27.615667</td>\n",
              "      <td>21.0</td>\n",
              "      <td>98.00</td>\n",
              "      <td>124.0</td>\n",
              "      <td>136.00</td>\n",
              "      <td>148.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015</th>\n",
              "      <td>3057.0</td>\n",
              "      <td>1131.147203</td>\n",
              "      <td>1549.863696</td>\n",
              "      <td>0.0</td>\n",
              "      <td>97.00</td>\n",
              "      <td>688.0</td>\n",
              "      <td>1535.00</td>\n",
              "      <td>16929.0</td>\n",
              "      <td>3057.0</td>\n",
              "      <td>2332.345764</td>\n",
              "      <td>3001.243607</td>\n",
              "      <td>1.0</td>\n",
              "      <td>183.00</td>\n",
              "      <td>1445.0</td>\n",
              "      <td>3348.00</td>\n",
              "      <td>29617.0</td>\n",
              "      <td>3057.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3057.0</td>\n",
              "      <td>6.229778e+17</td>\n",
              "      <td>3.891979e+16</td>\n",
              "      <td>5.505476e+17</td>\n",
              "      <td>5.919861e+17</td>\n",
              "      <td>6.235615e+17</td>\n",
              "      <td>6.582454e+17</td>\n",
              "      <td>6.827032e+17</td>\n",
              "      <td>3057.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>3057.0</td>\n",
              "      <td>109.009486</td>\n",
              "      <td>31.873999</td>\n",
              "      <td>15.0</td>\n",
              "      <td>87.00</td>\n",
              "      <td>120.0</td>\n",
              "      <td>137.00</td>\n",
              "      <td>155.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016</th>\n",
              "      <td>3465.0</td>\n",
              "      <td>8374.749784</td>\n",
              "      <td>10837.525448</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3531.00</td>\n",
              "      <td>6060.0</td>\n",
              "      <td>10145.00</td>\n",
              "      <td>344806.0</td>\n",
              "      <td>3465.0</td>\n",
              "      <td>24010.087734</td>\n",
              "      <td>28142.103434</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10432.00</td>\n",
              "      <td>17297.0</td>\n",
              "      <td>27717.00</td>\n",
              "      <td>633253.0</td>\n",
              "      <td>3465.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3465.0</td>\n",
              "      <td>7.438493e+17</td>\n",
              "      <td>3.707584e+16</td>\n",
              "      <td>6.827240e+17</td>\n",
              "      <td>7.087148e+17</td>\n",
              "      <td>7.452963e+17</td>\n",
              "      <td>7.779584e+17</td>\n",
              "      <td>8.152709e+17</td>\n",
              "      <td>3465.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>3465.0</td>\n",
              "      <td>113.363925</td>\n",
              "      <td>30.697098</td>\n",
              "      <td>14.0</td>\n",
              "      <td>93.00</td>\n",
              "      <td>127.0</td>\n",
              "      <td>138.00</td>\n",
              "      <td>148.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017</th>\n",
              "      <td>2284.0</td>\n",
              "      <td>19504.978984</td>\n",
              "      <td>14416.083801</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12378.50</td>\n",
              "      <td>16695.5</td>\n",
              "      <td>23370.00</td>\n",
              "      <td>369530.0</td>\n",
              "      <td>2284.0</td>\n",
              "      <td>84005.754378</td>\n",
              "      <td>41770.131586</td>\n",
              "      <td>1.0</td>\n",
              "      <td>58470.25</td>\n",
              "      <td>75926.0</td>\n",
              "      <td>101226.00</td>\n",
              "      <td>616217.0</td>\n",
              "      <td>2284.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2284.0</td>\n",
              "      <td>8.865922e+17</td>\n",
              "      <td>3.796267e+16</td>\n",
              "      <td>8.154223e+17</td>\n",
              "      <td>8.560855e+17</td>\n",
              "      <td>8.906965e+17</td>\n",
              "      <td>9.189161e+17</td>\n",
              "      <td>9.476141e+17</td>\n",
              "      <td>2284.0</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>2284.0</td>\n",
              "      <td>133.917688</td>\n",
              "      <td>46.279751</td>\n",
              "      <td>2.0</td>\n",
              "      <td>119.00</td>\n",
              "      <td>138.0</td>\n",
              "      <td>143.00</td>\n",
              "      <td>320.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018</th>\n",
              "      <td>3104.0</td>\n",
              "      <td>21092.619201</td>\n",
              "      <td>10443.373373</td>\n",
              "      <td>6.0</td>\n",
              "      <td>14661.25</td>\n",
              "      <td>19519.0</td>\n",
              "      <td>25592.25</td>\n",
              "      <td>191837.0</td>\n",
              "      <td>3104.0</td>\n",
              "      <td>88109.316366</td>\n",
              "      <td>37886.727188</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64614.75</td>\n",
              "      <td>83612.5</td>\n",
              "      <td>106110.75</td>\n",
              "      <td>508327.0</td>\n",
              "      <td>3046.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3104.0</td>\n",
              "      <td>1.020171e+18</td>\n",
              "      <td>3.587214e+16</td>\n",
              "      <td>9.478026e+17</td>\n",
              "      <td>9.928010e+17</td>\n",
              "      <td>1.023553e+18</td>\n",
              "      <td>1.051105e+18</td>\n",
              "      <td>1.079888e+18</td>\n",
              "      <td>3104.0</td>\n",
              "      <td>2018.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2018.0</td>\n",
              "      <td>2018.0</td>\n",
              "      <td>2018.0</td>\n",
              "      <td>2018.0</td>\n",
              "      <td>2018.0</td>\n",
              "      <td>3104.0</td>\n",
              "      <td>198.084407</td>\n",
              "      <td>83.564703</td>\n",
              "      <td>8.0</td>\n",
              "      <td>131.00</td>\n",
              "      <td>221.0</td>\n",
              "      <td>277.00</td>\n",
              "      <td>315.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019</th>\n",
              "      <td>1075.0</td>\n",
              "      <td>24635.476279</td>\n",
              "      <td>10951.524073</td>\n",
              "      <td>3.0</td>\n",
              "      <td>18475.50</td>\n",
              "      <td>23070.0</td>\n",
              "      <td>29483.50</td>\n",
              "      <td>116749.0</td>\n",
              "      <td>1075.0</td>\n",
              "      <td>107030.795349</td>\n",
              "      <td>45779.247384</td>\n",
              "      <td>1.0</td>\n",
              "      <td>78783.00</td>\n",
              "      <td>101829.0</td>\n",
              "      <td>126213.00</td>\n",
              "      <td>462655.0</td>\n",
              "      <td>1075.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1075.0</td>\n",
              "      <td>1.102251e+18</td>\n",
              "      <td>1.272214e+16</td>\n",
              "      <td>1.079900e+18</td>\n",
              "      <td>1.090609e+18</td>\n",
              "      <td>1.103036e+18</td>\n",
              "      <td>1.113900e+18</td>\n",
              "      <td>1.122486e+18</td>\n",
              "      <td>1075.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>1075.0</td>\n",
              "      <td>183.999070</td>\n",
              "      <td>92.820761</td>\n",
              "      <td>5.0</td>\n",
              "      <td>102.50</td>\n",
              "      <td>205.0</td>\n",
              "      <td>276.00</td>\n",
              "      <td>302.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     retweet_count                              ... text_length               \n",
              "             count          mean           std  ...         50%     75%    max\n",
              "year                                            ...                           \n",
              "2009          56.0     39.071429    191.165503  ...       115.0  126.25  140.0\n",
              "2010         142.0     79.380282    417.097668  ...       132.5  138.00  140.0\n",
              "2011         774.0    187.506460    556.265788  ...       114.0  133.00  140.0\n",
              "2012        3530.0    457.685836   3625.044171  ...       117.0  135.00  148.0\n",
              "2013        5775.0    239.694719   1613.828343  ...        94.0  128.00  152.0\n",
              "2014        2433.0    332.652692   1283.491376  ...       124.0  136.00  148.0\n",
              "2015        3057.0   1131.147203   1549.863696  ...       120.0  137.00  155.0\n",
              "2016        3465.0   8374.749784  10837.525448  ...       127.0  138.00  148.0\n",
              "2017        2284.0  19504.978984  14416.083801  ...       138.0  143.00  320.0\n",
              "2018        3104.0  21092.619201  10443.373373  ...       221.0  277.00  315.0\n",
              "2019        1075.0  24635.476279  10951.524073  ...       205.0  276.00  302.0\n",
              "\n",
              "[11 rows x 48 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXoy09gmVeNj",
        "colab_type": "text"
      },
      "source": [
        "### 1.4. Top-Hashtags und -Mentions\n",
        "Nachdem wir uns mit der Länge der Texte beschäftigt haben, wollen wir nun herausfinden, wen Donald Trump in seinen Tweets erwähnt und welche Themen er (hash)taggt. Dabei interessiert uns die Entwicklung über die Jahre.\n",
        "\n",
        "Anbei ein Vorschlag bezüglich des Vorgehens:\n",
        "Wir beginnen mit den Hashtags und verwenden zunächst einen kleinen Trick, um ein Dictionary zu erstellen, das für jedes Jahr einen \"Sub-Dataframe\" enthält. \n",
        "\n",
        "Aus diesen Dataframes extrahieren wir dann pro Jahr alle Tweettexte in Form eines einzelnen Strings. Dazu konkatenieren wir die ```text```-Felder der Dataframes per ```' '.join(frame['text']) for frame in ...```\n",
        "\n",
        "Damit haben wir ein Dictionary, das pro Jahr alle konkatenierten Tweet-Texte enthält, aus denen wir dann die Hashtags extrahieren können. \n",
        "Hierbei machen wir uns noch keine allzu großen Gedanken über Normalisierung, sondern zerlegen die langen Texte einfach per ```split()``` in einzelne Tokens, aus denen wir dann die Hashtags herausfiltern. \n",
        "Um die Top-Hashtags in Erfahrung zu bringen, verwenden wir wieder ```Counter```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl5OEABMVeNl",
        "colab_type": "code",
        "outputId": "d308c01d-193f-4995-e069-efa0e0ca0d7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "tweets_by_year = dict(list(tweets.groupby(['year'])))\n",
        "texts_per_year = {}\n",
        "\n",
        "for item in tweets_by_year.items():\n",
        "  texts_per_year.update({item[0]: ' '.join(item[1]['text'])})\n",
        "\n",
        "top_hashtags_per_year= {}\n",
        "for item in texts_per_year.items():\n",
        "  #tokens = re.split(' |, |\\.*|\\\\n|! *|: ', item[1].encode('ascii', 'ignore').decode('ascii'))# item[1].split(' ')\n",
        "  replaced_string = re.sub(r'\\.|!|:|\\n|-|,|\\?|\\'', ' ', item[1].encode('ascii', 'ignore').decode('ascii'))\n",
        "  replaced_string = re.sub(r'#', ' #', replaced_string)\n",
        "  tokens = replaced_string.split(' ')\n",
        "  hashtags = [token for token in tokens if '#' in token]\n",
        "  top_hashtags_per_year.update({item[0]: Counter(hashtags)})\n",
        "\n",
        "for item in top_hashtags_per_year.items():\n",
        "  print(item[0], item[1].most_common(10))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2009 []\n",
            "2010 [('#EvanForSI', 1)]\n",
            "2011 [('#TimeToGetTough', 59), ('#trumpvlog', 43), ('#1', 7), ('#TrumpRoast', 4), ('#Apprentice', 3), ('#TImeToGetTough', 2), ('#badratings', 2), ('#MissUSA', 2), ('#VEGASusa11', 2), ('#noratings', 1)]\n",
            "2012 [('#TimeToGetTough', 33), ('#trumpvlog', 19), ('#sweepstweet', 19), ('#CelebrityApprentice', 14), ('#TrumpTuesday', 13), ('#CelebApprentice', 13), ('#1', 11), ('#MissUniverse', 9), ('#TRUMP', 8), ('#VPDebate', 8)]\n",
            "2013 [('#CelebApprentice', 128), ('#1', 29), ('#WWEHOF', 18), ('#TrumpVine', 9), ('#TBT', 7), ('#MakeDCListen', 6), ('#FundAnything', 6), ('#CPAC2013', 4), ('#2', 3), ('#RoadHard', 3)]\n",
            "2014 [('#Oscars', 19), ('#TBT', 13), ('#1', 13), ('#TrumpVlog', 12), ('#FreeOurMarine', 6), ('#FlashbackFriday', 5), ('#TrumpAdvice', 5), ('#BlueMonster', 4), ('#IceBucketChallenge', 4), ('#BringBackOurMarine', 4)]\n",
            "2015 [('#MakeAmericaGreatAgain', 127), ('#Trump2016', 115), ('#1', 23), ('#CelebApprentice', 20), ('#GOPDebate', 12), ('#FITN', 10), ('#asktrump', 10), ('#TBT', 9), ('#DemDebate', 9), ('#Periscope', 6)]\n",
            "2016 [('#Trump2016', 313), ('#MakeAmericaGreatAgain', 231), ('#MAGA', 92), ('#AmericaFirst', 85), ('#DrainTheSwamp', 78), ('#VoteTrump', 59), ('#ImWithYou', 57), ('#BigLeagueTruth', 46), ('#CrookedHillary', 42), ('#Debate', 33)]\n",
            "2017 [('#MAGA', 33), ('#USA', 28), ('#FakeNews', 17), ('#AmericaFirst', 13), ('#TaxReform', 10), ('#UNGA', 10), ('#ICYMI', 9), ('#WeeklyAddress', 8), ('#HurricaneHarvey', 8), ('#APEC2017', 7)]\n",
            "2018 [('#MAGA', 77), ('#MAGARally', 10), ('#JobsNotMobs', 9), ('#1', 8), ('#UNGA', 6), ('#WEF18', 6), ('#HurricaneMichael', 5), ('#NeverForget', 5), ('#IACP2018', 4), ('#CPAC2018', 4)]\n",
            "2019 [('#MAGA', 17), ('#TakeBackDay', 2), ('#RxSummit2019', 2), ('#SOTU', 2), ('#MLKDay', 2), ('#FakeNews', 2), ('#TrumpRally', 1), ('#MAGAhttps', 1), ('#NRAAM', 1), ('#NationalAutismAwarenessMonth', 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlIlCmcosW6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sElwrhIrVeNq",
        "colab_type": "text"
      },
      "source": [
        "Als nächstes interessieren uns die Mentions. Wir können hier analog zu den Hashtags vorgehen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unTUqpgYVeNs",
        "colab_type": "code",
        "outputId": "abad6bcd-cfbe-4891-af58-99dc3d530288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "top_mentions_per_year = {} # TODO\n",
        "\n",
        "for item in texts_per_year.items():\n",
        "  replaced_string = re.sub(r'\\.|!|:|\\n|-|,|\\?|\\'', ' ', item[1].encode('ascii', 'ignore').decode('ascii'))\n",
        "  replaced_string = re.sub(r'@', ' @', replaced_string)\n",
        "  tokens = replaced_string.split(' ')\n",
        "  hashtags = [token for token in tokens if '@' in token and len(token) > 1]\n",
        "  top_mentions_per_year.update({item[0]: Counter(hashtags)})\n",
        "\n",
        "for item in top_mentions_per_year.items():\n",
        "  print(item[0], item[1].most_common(10))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2009 [('@IvankaTrump', 1)]\n",
            "2010 [('@kingsthings', 1), ('@bretmichaels', 1), ('@hollyrpeete', 1)]\n",
            "2011 [('@BarackObama', 155), ('@FoxNews', 18), ('@iontv', 17), ('@Israel', 14), ('@gretawire', 12), ('@foxandfriends', 8), ('@Lawrence', 7), ('@johnboehner', 6), ('@JonHuntsman', 5), ('@TeamCavuto', 5)]\n",
            "2012 [('@BarackObama', 544), ('@MittRomney', 288), ('@CelebApprentice', 45), ('@SquawkCNBC', 40), ('@foxandfriends', 38), ('@gretawire', 26), ('@Yankees', 25), ('@RickSantorum', 22), ('@Lord_Sugar', 21), ('@Rosie', 20)]\n",
            "2013 [('@ApprenticeNBC', 106), ('@realDonaldTrump', 91), ('@billmaher', 66), ('@CelebApprentice', 62), ('@GOP', 36), ('@AlexSalmond', 34), ('@IvankaTrump', 33), ('@TrumpTowerNY', 31), ('@THEGaryBusey', 30), ('@DannyZuker', 29)]\n",
            "2014 [('@TrumpDoral', 36), ('@AGSchneiderman', 30), ('@foxandfriends', 29), ('@TrumpChicago', 22), ('@TrumpNewYork', 19), ('@ApprenticeNBC', 18), ('@TrumpTurnberry', 16), ('@AlexSalmond', 15), ('@Macys', 13), ('@Newsmax_Media', 13)]\n",
            "2015 [('@FoxNews', 87), ('@CNN', 67), ('@foxandfriends', 42), ('@oreillyfactor', 35), ('@ApprenticeNBC', 32), ('@BreitbartNews', 30), ('@KarlRove', 27), ('@JebBush', 24), ('@megynkelly', 24), ('@seanhannity', 22)]\n",
            "2016 [('@CNN', 74), ('@FoxNews', 66), ('@nytimes', 49), ('@HillaryClinton', 30), ('@foxandfriends', 30), ('@oreillyfactor', 26), ('@megynkelly', 20), ('@Morning_Joe', 17), ('@JebBush', 15), ('@Mike_Pence', 14)]\n",
            "2017 [('@foxandfriends', 46), ('@WhiteHouse', 43), ('@FoxNews', 30), ('@nytimes', 28), ('@FLOTUS', 25), ('@VP', 18), ('@CNN', 16), ('@NBCNews', 13), ('@SenateMajLdr', 9), ('@USNavy', 8)]\n",
            "2018 [('@FoxNews', 64), ('@foxandfriends', 50), ('@WhiteHouse', 49), ('@FLOTUS', 16), ('@LouDobbs', 15), ('@EmmanuelMacron', 9), ('@AbeShinzo', 9), ('@nytimes', 9), ('@CNN', 8), ('@TuckerCarlson', 8)]\n",
            "2019 [('@FoxNews', 33), ('@foxandfriends', 26), ('@WhiteHouse', 11), ('@seanhannity', 10), ('@TuckerCarlson', 10), ('@LouDobbs', 7), ('@JesseBWatters', 6), ('@TigerWoods', 6), ('@OANN', 5), ('@MariaBartiromo', 4)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AyTB7y2VeNz",
        "colab_type": "text"
      },
      "source": [
        "### 1.5 Vokabular\n",
        "Bevor wir endgültig auf die Ebene der Einzelzeichen herabsteigen, wollen wir uns das von Trump verwendete Vokabular genauer ansehen und dabei auch herausfinden, ob weitere Vorverarbeitungsschritte nötig sind.\n",
        "\n",
        "Dazu erstellen wir uns zunächst eine Liste aller Tokens, die in den Dokumenten vorkommen. Wir gruppieren nicht mehr per Jahr, sondern gehen ganz simpel vor und konkatenieren alle Tweet-Texte in einen langen String, den wir dann in einzelne Terme splitten.\n",
        "\n",
        "Gebt die 20 häufigsten Terme aus. Was fällt auf (insbesondere bei Betrachtung des hinteren Endes der Liste)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUEjiSpmVeN0",
        "colab_type": "code",
        "outputId": "ed51c11f-851c-417a-b3b1-eb5cc4be0f58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "tweet_texts = ' '.join(tweets['text'])\n",
        "tokens = tweet_texts.split()\n",
        "\n",
        "Counter(tokens).most_common(20)\n",
        "# TODO Top-20 Terme"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 17252),\n",
              " ('to', 11653),\n",
              " ('and', 9303),\n",
              " ('of', 8246),\n",
              " ('a', 7975),\n",
              " ('is', 7535),\n",
              " ('in', 6777),\n",
              " ('for', 5067),\n",
              " ('I', 4861),\n",
              " ('on', 4842),\n",
              " ('be', 4023),\n",
              " ('will', 3761),\n",
              " ('that', 3217),\n",
              " ('are', 3177),\n",
              " ('with', 2980),\n",
              " ('you', 2963),\n",
              " ('at', 2800),\n",
              " ('&amp;', 2764),\n",
              " ('The', 2759),\n",
              " ('have', 2546)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEx4GDH0VeN4",
        "colab_type": "text"
      },
      "source": [
        "Wenn es euch auch sinnvoll erscheint, die Html-Escapes wieder rückgängig zu machen, könnt ihr das hier tun."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCzmSHbcVeN5",
        "colab_type": "code",
        "outputId": "6722a368-ab62-4b61-b715-661f433f061e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "import html\n",
        "cleaned_tweet_texts = []\n",
        "for token in tokens:\n",
        "  cleaned_tweet_texts.append(html.unescape(token))# TODO\n",
        "Counter(cleaned_tweet_texts).most_common(20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 17252),\n",
              " ('to', 11653),\n",
              " ('and', 9303),\n",
              " ('of', 8246),\n",
              " ('a', 7975),\n",
              " ('is', 7535),\n",
              " ('in', 6777),\n",
              " ('for', 5067),\n",
              " ('I', 4861),\n",
              " ('on', 4842),\n",
              " ('be', 4023),\n",
              " ('will', 3761),\n",
              " ('that', 3217),\n",
              " ('are', 3177),\n",
              " ('with', 2980),\n",
              " ('you', 2963),\n",
              " ('&', 2809),\n",
              " ('at', 2800),\n",
              " ('The', 2759),\n",
              " ('have', 2546)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXbur-87VeOA",
        "colab_type": "text"
      },
      "source": [
        "### 1.6 Verwendete Zeichen\n",
        "Zum Ende unserer Analysephase schauen wir uns noch an, welche Einzelzeichen in den Tweets vorkommen. Dazu greifen wir wieder auf die konkatenierten (und bereinigten) Tweettexte zurück, die in der Variable ```cleaned_tweet_texts``` gespeichert sind.\n",
        "Wie viele Zeichen gibt es und wie häufig werden sie verwendet?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHwi-qDcVeOB",
        "colab_type": "code",
        "outputId": "b4c93434-fd90-4300-aa48-75881a245aaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "cleaned_tweets = ' '.join(cleaned_tweet_texts)\n",
        "tweet_chars = [char for char in cleaned_tweets]# TODO Tweets als Liste von Zeichen (inklusive Duplikate). \"Das hier sind alle Tweets\" => ['D', 'a', 's', ' ', 'h', 'i', 'e', ....] (String => Liste)\n",
        "Counter(tweet_chars).most_common(80)\n",
        "# TODO: Welche Zeichen kommen vor?\n",
        "# TODO: Wie oft wird welches Zeichen verwendet?"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(' ', 495487),\n",
              " ('e', 251197),\n",
              " ('t', 203968),\n",
              " ('a', 181386),\n",
              " ('o', 180107),\n",
              " ('n', 156202),\n",
              " ('i', 152156),\n",
              " ('r', 141102),\n",
              " ('s', 130437),\n",
              " ('h', 99586),\n",
              " ('l', 95030),\n",
              " ('d', 73567),\n",
              " ('u', 64669),\n",
              " ('c', 63887),\n",
              " ('m', 56675),\n",
              " ('g', 50691),\n",
              " ('p', 50529),\n",
              " ('y', 49148),\n",
              " ('.', 44782),\n",
              " ('w', 42146),\n",
              " ('f', 37350),\n",
              " ('b', 36134),\n",
              " ('/', 25392),\n",
              " ('v', 23573),\n",
              " ('k', 23007),\n",
              " ('T', 22293),\n",
              " ('A', 18312),\n",
              " (',', 17799),\n",
              " ('I', 15825),\n",
              " ('C', 15356),\n",
              " ('S', 15184),\n",
              " ('@', 13742),\n",
              " ('!', 13161),\n",
              " ('M', 12357),\n",
              " ('N', 11580),\n",
              " (':', 10938),\n",
              " ('R', 10460),\n",
              " ('O', 10206),\n",
              " ('E', 10181),\n",
              " ('W', 9758),\n",
              " ('B', 9570),\n",
              " ('-', 9134),\n",
              " ('D', 8983),\n",
              " ('P', 8822),\n",
              " ('G', 8544),\n",
              " ('H', 8113),\n",
              " ('L', 6885),\n",
              " ('F', 6682),\n",
              " ('0', 6599),\n",
              " ('x', 5871),\n",
              " (\"'\", 5395),\n",
              " ('1', 5278),\n",
              " ('j', 5251),\n",
              " ('U', 5235),\n",
              " ('J', 5181),\n",
              " ('V', 4327),\n",
              " ('2', 4030),\n",
              " ('Y', 4007),\n",
              " ('\"', 3794),\n",
              " ('#', 3736),\n",
              " ('z', 3706),\n",
              " ('K', 3686),\n",
              " ('’', 3316),\n",
              " ('&', 2884),\n",
              " ('3', 2617),\n",
              " ('6', 2603),\n",
              " ('5', 2577),\n",
              " ('7', 2370),\n",
              " ('4', 2253),\n",
              " ('q', 2209),\n",
              " ('8', 2141),\n",
              " ('9', 2131),\n",
              " ('“', 2008),\n",
              " ('”', 1995),\n",
              " ('?', 1952),\n",
              " (')', 1646),\n",
              " ('(', 1641),\n",
              " ('Z', 1509),\n",
              " ('Q', 1436),\n",
              " ('X', 1401)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsHpjjYAVeOF",
        "colab_type": "text"
      },
      "source": [
        "### 1.7 Vom Text zur Zeichenliste\n",
        "Betrachtet die in der vorherigen Teilaufgabe generierte Liste der verwendeten Zeichen. Welche Bereinigungsschritte könnten angemessen sein? Kurze Begründung bitte.\n",
        "\n",
        "Bevor wir daran gehen, vektorisierte Trainingsdaten für unser Modell zu generieren, wandeln wir unsere Tweets in dieser Teilaufgabe in eine (bereinigte) Liste von Einzelzeichen um und speichern diese in der Variable ```cleaned_tweet_chars```.\n",
        "\n",
        "```['d', 'i', 'e', 's', ' ', 'i', 's', 't', ' ', 'e', 'i', 'n', ' ', 'b', 'e', 'i', 's', 'p', 'i', 'e', 'l', ',', ' ', 'w', 'i', 'e', ' ', 'd', 'i', 'e', ' ', 'l', 'i', 's', 't', 'e', ' ', 'b', 'e', 'g', 'i', 'n', 'n', 'e', 'n', ' ', 'k', 'ö', 'n', 'n', 't', 'e', '.']```\n",
        "\n",
        "\n",
        "**Hinweise**: \n",
        "* In Python gibt es eine Methode ```str.isprintable()```, die bei der Bereinigung hilfreich sein könnte ...\n",
        "* Vereinfachung ist legitim. Je mehr Einzelzeichen wir bei der Modellierung berücksichtigen, umso komplexer wird unser Modell und umso höher ist der Trainingsaufwand."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OqbO-6gVeOG",
        "colab_type": "code",
        "outputId": "2ea528e6-27d8-46b5-f34c-a275c3b57591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "cleaned_tweet_chars = [char.lower() for char in cleaned_tweets if str.isprintable(char)]# TODO Alle Tweets in Einzelzeichen zerlegt und ggf. bereinigt hier rein\n",
        "#Counter(cleaned_tweet_chars).most_common(57)\n",
        "cleaned_tweet_chars"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['w',\n",
              " 'i',\n",
              " 'l',\n",
              " 'l',\n",
              " ' ',\n",
              " 'b',\n",
              " 'e',\n",
              " ' ',\n",
              " 'i',\n",
              " 'n',\n",
              " 't',\n",
              " 'e',\n",
              " 'r',\n",
              " 'v',\n",
              " 'i',\n",
              " 'e',\n",
              " 'w',\n",
              " 'e',\n",
              " 'd',\n",
              " ' ',\n",
              " 'b',\n",
              " 'y',\n",
              " ' ',\n",
              " '@',\n",
              " 'm',\n",
              " 'a',\n",
              " 'r',\n",
              " 'i',\n",
              " 'a',\n",
              " 'b',\n",
              " 'a',\n",
              " 'r',\n",
              " 't',\n",
              " 'i',\n",
              " 'r',\n",
              " 'o',\n",
              " 'm',\n",
              " 'o',\n",
              " ' ',\n",
              " 'o',\n",
              " 'n',\n",
              " ' ',\n",
              " '@',\n",
              " 'f',\n",
              " 'o',\n",
              " 'x',\n",
              " 'n',\n",
              " 'e',\n",
              " 'w',\n",
              " 's',\n",
              " ' ',\n",
              " 'a',\n",
              " 't',\n",
              " ' ',\n",
              " '1',\n",
              " '0',\n",
              " ':',\n",
              " '0',\n",
              " '0',\n",
              " ' ',\n",
              " 'a',\n",
              " 'm',\n",
              " '.',\n",
              " ' ',\n",
              " 't',\n",
              " 'a',\n",
              " 'l',\n",
              " 'k',\n",
              " 'i',\n",
              " 'n',\n",
              " 'g',\n",
              " ' ',\n",
              " 'a',\n",
              " 'b',\n",
              " 'o',\n",
              " 'u',\n",
              " 't',\n",
              " ' ',\n",
              " 't',\n",
              " 'h',\n",
              " 'e',\n",
              " ' ',\n",
              " 's',\n",
              " 'o',\n",
              " 'u',\n",
              " 't',\n",
              " 'h',\n",
              " 'e',\n",
              " 'r',\n",
              " 'n',\n",
              " ' ',\n",
              " 'b',\n",
              " 'o',\n",
              " 'r',\n",
              " 'd',\n",
              " 'e',\n",
              " 'r',\n",
              " ' ',\n",
              " 'a',\n",
              " 'n',\n",
              " 'd',\n",
              " ' ',\n",
              " 'h',\n",
              " 'o',\n",
              " 'w',\n",
              " ' ',\n",
              " 't',\n",
              " 'h',\n",
              " 'e',\n",
              " ' ',\n",
              " 'd',\n",
              " 'e',\n",
              " 'm',\n",
              " 's',\n",
              " ' ',\n",
              " 'm',\n",
              " 'u',\n",
              " 's',\n",
              " 't',\n",
              " ' ',\n",
              " 'a',\n",
              " 'c',\n",
              " 't',\n",
              " ' ',\n",
              " 'f',\n",
              " 'a',\n",
              " 's',\n",
              " 't',\n",
              " ' ',\n",
              " 't',\n",
              " 'o',\n",
              " ' ',\n",
              " 'c',\n",
              " 'h',\n",
              " 'a',\n",
              " 'n',\n",
              " 'g',\n",
              " 'e',\n",
              " ' ',\n",
              " 'o',\n",
              " 'u',\n",
              " 'r',\n",
              " ' ',\n",
              " 'p',\n",
              " 'a',\n",
              " 't',\n",
              " 'h',\n",
              " 'e',\n",
              " 't',\n",
              " 'i',\n",
              " 'c',\n",
              " ' ',\n",
              " 'i',\n",
              " 'm',\n",
              " 'm',\n",
              " 'i',\n",
              " 'g',\n",
              " 'r',\n",
              " 'a',\n",
              " 't',\n",
              " 'i',\n",
              " 'o',\n",
              " 'n',\n",
              " ' ',\n",
              " 'l',\n",
              " 'a',\n",
              " 'w',\n",
              " 's',\n",
              " '.',\n",
              " ' ',\n",
              " 'w',\n",
              " 'i',\n",
              " 'l',\n",
              " 'l',\n",
              " ' ',\n",
              " 'b',\n",
              " 'e',\n",
              " ' ',\n",
              " 't',\n",
              " 'o',\n",
              " 'u',\n",
              " 'g',\n",
              " 'h',\n",
              " ',',\n",
              " ' ',\n",
              " 'w',\n",
              " 'a',\n",
              " 't',\n",
              " 'c',\n",
              " 'h',\n",
              " '!',\n",
              " ' ',\n",
              " '.',\n",
              " '.',\n",
              " '.',\n",
              " '.',\n",
              " 'f',\n",
              " 'o',\n",
              " 'r',\n",
              " ' ',\n",
              " 't',\n",
              " 'h',\n",
              " 'e',\n",
              " ' ',\n",
              " 'm',\n",
              " 'o',\n",
              " 'r',\n",
              " 'e',\n",
              " ' ',\n",
              " 't',\n",
              " 'r',\n",
              " 'a',\n",
              " 'd',\n",
              " 'i',\n",
              " 't',\n",
              " 'i',\n",
              " 'o',\n",
              " 'n',\n",
              " 'a',\n",
              " 'l',\n",
              " ',',\n",
              " ' ',\n",
              " 'b',\n",
              " 'u',\n",
              " 't',\n",
              " ' ',\n",
              " 'n',\n",
              " 'o',\n",
              " 't',\n",
              " ' ',\n",
              " 'v',\n",
              " 'e',\n",
              " 'r',\n",
              " 'y',\n",
              " ' ',\n",
              " 'b',\n",
              " 'r',\n",
              " 'i',\n",
              " 'g',\n",
              " 'h',\n",
              " 't',\n",
              " ',',\n",
              " ' ',\n",
              " 's',\n",
              " 'l',\n",
              " 'e',\n",
              " 'e',\n",
              " 'p',\n",
              " 'y',\n",
              " ' ',\n",
              " 'j',\n",
              " 'o',\n",
              " 'e',\n",
              " ' ',\n",
              " 'b',\n",
              " 'i',\n",
              " 'd',\n",
              " 'e',\n",
              " 'n',\n",
              " '.',\n",
              " ' ',\n",
              " 'h',\n",
              " 'e',\n",
              " 'r',\n",
              " 'e',\n",
              " ' ',\n",
              " 'w',\n",
              " 'e',\n",
              " ' ',\n",
              " 'g',\n",
              " 'o',\n",
              " ' ',\n",
              " 'a',\n",
              " 'g',\n",
              " 'a',\n",
              " 'i',\n",
              " 'n',\n",
              " ' ',\n",
              " 'b',\n",
              " 'e',\n",
              " 'r',\n",
              " 'n',\n",
              " 'i',\n",
              " 'e',\n",
              " ',',\n",
              " ' ',\n",
              " 'b',\n",
              " 'u',\n",
              " 't',\n",
              " ' ',\n",
              " 't',\n",
              " 'h',\n",
              " 'i',\n",
              " 's',\n",
              " ' ',\n",
              " 't',\n",
              " 'i',\n",
              " 'm',\n",
              " 'e',\n",
              " ' ',\n",
              " 'p',\n",
              " 'l',\n",
              " 'e',\n",
              " 'a',\n",
              " 's',\n",
              " 'e',\n",
              " ' ',\n",
              " 's',\n",
              " 'h',\n",
              " 'o',\n",
              " 'w',\n",
              " ' ',\n",
              " 'a',\n",
              " ' ',\n",
              " 'l',\n",
              " 'i',\n",
              " 't',\n",
              " 't',\n",
              " 'l',\n",
              " 'e',\n",
              " ' ',\n",
              " 'm',\n",
              " 'o',\n",
              " 'r',\n",
              " 'e',\n",
              " ' ',\n",
              " 'a',\n",
              " 'n',\n",
              " 'g',\n",
              " 'e',\n",
              " 'r',\n",
              " ' ',\n",
              " 'a',\n",
              " 'n',\n",
              " 'd',\n",
              " ' ',\n",
              " 'i',\n",
              " 'n',\n",
              " 'd',\n",
              " 'i',\n",
              " 'g',\n",
              " 'n',\n",
              " 'a',\n",
              " 't',\n",
              " 'i',\n",
              " 'o',\n",
              " 'n',\n",
              " ' ',\n",
              " 'w',\n",
              " 'h',\n",
              " 'e',\n",
              " 'n',\n",
              " ' ',\n",
              " 'y',\n",
              " 'o',\n",
              " 'u',\n",
              " ' ',\n",
              " 'g',\n",
              " 'e',\n",
              " 't',\n",
              " ' ',\n",
              " 's',\n",
              " 'c',\n",
              " 'r',\n",
              " 'e',\n",
              " 'w',\n",
              " 'e',\n",
              " 'd',\n",
              " '!',\n",
              " ' ',\n",
              " 't',\n",
              " 'h',\n",
              " 'e',\n",
              " ' ',\n",
              " 'd',\n",
              " 'e',\n",
              " 'm',\n",
              " 'o',\n",
              " 'c',\n",
              " 'r',\n",
              " 'a',\n",
              " 't',\n",
              " 'i',\n",
              " 'c',\n",
              " ' ',\n",
              " 'n',\n",
              " 'a',\n",
              " 't',\n",
              " 'i',\n",
              " 'o',\n",
              " 'n',\n",
              " 'a',\n",
              " 'l',\n",
              " ' ',\n",
              " 'c',\n",
              " 'o',\n",
              " 'm',\n",
              " 'm',\n",
              " 'i',\n",
              " 't',\n",
              " 't',\n",
              " 'e',\n",
              " 'e',\n",
              " ',',\n",
              " ' ',\n",
              " 's',\n",
              " 'o',\n",
              " 'm',\n",
              " 'e',\n",
              " 't',\n",
              " 'i',\n",
              " 'm',\n",
              " 'e',\n",
              " 's',\n",
              " ' ',\n",
              " 'r',\n",
              " 'e',\n",
              " 'f',\n",
              " 'e',\n",
              " 'r',\n",
              " 'r',\n",
              " 'e',\n",
              " 'd',\n",
              " ' ',\n",
              " 't',\n",
              " 'o',\n",
              " ' ',\n",
              " 'a',\n",
              " 's',\n",
              " ' ',\n",
              " 't',\n",
              " 'h',\n",
              " 'e',\n",
              " ' ',\n",
              " 'd',\n",
              " 'n',\n",
              " 'c',\n",
              " ',',\n",
              " ' ',\n",
              " 'i',\n",
              " 's',\n",
              " ' ',\n",
              " 'a',\n",
              " 'g',\n",
              " 'a',\n",
              " 'i',\n",
              " 'n',\n",
              " ' ',\n",
              " 'w',\n",
              " 'o',\n",
              " 'r',\n",
              " 'k',\n",
              " 'i',\n",
              " 'n',\n",
              " 'g',\n",
              " ' ',\n",
              " 'i',\n",
              " 't',\n",
              " 's',\n",
              " ' ',\n",
              " 'm',\n",
              " 'a',\n",
              " 'g',\n",
              " 'i',\n",
              " 'c',\n",
              " ' ',\n",
              " 'i',\n",
              " 'n',\n",
              " ' ',\n",
              " 'i',\n",
              " 't',\n",
              " 's',\n",
              " ' ',\n",
              " 'q',\n",
              " 'u',\n",
              " 'e',\n",
              " 's',\n",
              " 't',\n",
              " ' ',\n",
              " 't',\n",
              " 'o',\n",
              " ' ',\n",
              " 'd',\n",
              " 'e',\n",
              " 's',\n",
              " 't',\n",
              " 'r',\n",
              " 'o',\n",
              " 'y',\n",
              " ' ',\n",
              " 'c',\n",
              " 'r',\n",
              " 'a',\n",
              " 'z',\n",
              " 'y',\n",
              " ' ',\n",
              " 'b',\n",
              " 'e',\n",
              " 'r',\n",
              " 'n',\n",
              " 'i',\n",
              " 'e',\n",
              " ' ',\n",
              " 's',\n",
              " 'a',\n",
              " 'n',\n",
              " 'd',\n",
              " 'e',\n",
              " 'r',\n",
              " 's',\n",
              " '.',\n",
              " '.',\n",
              " '.',\n",
              " '.',\n",
              " ' ',\n",
              " '.',\n",
              " '.',\n",
              " '.',\n",
              " '.',\n",
              " 'e',\n",
              " 'v',\n",
              " 'e',\n",
              " 'r',\n",
              " ' ',\n",
              " 's',\n",
              " 'i',\n",
              " 'n',\n",
              " 'c',\n",
              " 'e',\n",
              " ' ',\n",
              " 'a',\n",
              " 'n',\n",
              " 'd',\n",
              " 'r',\n",
              " 'e',\n",
              " 'w',\n",
              " ' ',\n",
              " 'c',\n",
              " 'a',\n",
              " 'm',\n",
              " 'e',\n",
              " ' ',\n",
              " 't',\n",
              " 'o',\n",
              " ' ',\n",
              " 'm',\n",
              " 'y',\n",
              " ' ',\n",
              " 'o',\n",
              " 'f',\n",
              " 'f',\n",
              " 'i',\n",
              " 'c',\n",
              " 'e',\n",
              " ' ',\n",
              " 't',\n",
              " 'o',\n",
              " ' ',\n",
              " 'a',\n",
              " 's',\n",
              " 'k',\n",
              " ' ',\n",
              " 't',\n",
              " 'h',\n",
              " 'a',\n",
              " 't',\n",
              " ' ',\n",
              " 'i',\n",
              " ' ',\n",
              " 'a',\n",
              " 'p',\n",
              " 'p',\n",
              " 'o',\n",
              " 'i',\n",
              " 'n',\n",
              " 't',\n",
              " ' ',\n",
              " 'h',\n",
              " 'i',\n",
              " 'm',\n",
              " ' ',\n",
              " 't',\n",
              " 'o',\n",
              " ' ',\n",
              " 't',\n",
              " 'h',\n",
              " 'e',\n",
              " ' ',\n",
              " 'u',\n",
              " '.',\n",
              " 's',\n",
              " '.',\n",
              " ' ',\n",
              " 's',\n",
              " 'u',\n",
              " 'p',\n",
              " 'r',\n",
              " 'e',\n",
              " 'm',\n",
              " 'e',\n",
              " ' ',\n",
              " 'c',\n",
              " 'o',\n",
              " 'u',\n",
              " 'r',\n",
              " 't',\n",
              " ',',\n",
              " ' ',\n",
              " 'a',\n",
              " 'n',\n",
              " 'd',\n",
              " ' ',\n",
              " 'i',\n",
              " ' ',\n",
              " 's',\n",
              " 'a',\n",
              " 'i',\n",
              " 'd',\n",
              " ' ',\n",
              " 'n',\n",
              " 'o',\n",
              " ',',\n",
              " ' ',\n",
              " 'h',\n",
              " 'e',\n",
              " ' ',\n",
              " 'h',\n",
              " 'a',\n",
              " 's',\n",
              " ' ',\n",
              " 'b',\n",
              " 'e',\n",
              " 'e',\n",
              " 'n',\n",
              " ' ',\n",
              " 'v',\n",
              " 'e',\n",
              " 'r',\n",
              " 'y',\n",
              " ' ',\n",
              " 'h',\n",
              " 'o',\n",
              " 's',\n",
              " 't',\n",
              " 'i',\n",
              " 'l',\n",
              " 'e',\n",
              " '!',\n",
              " ' ',\n",
              " 'a',\n",
              " 'l',\n",
              " 's',\n",
              " 'o',\n",
              " ' ',\n",
              " 'a',\n",
              " 's',\n",
              " 'k',\n",
              " 'e',\n",
              " 'd',\n",
              " ' ',\n",
              " 'f',\n",
              " 'o',\n",
              " 'r',\n",
              " ' ',\n",
              " 'p',\n",
              " 'a',\n",
              " 'r',\n",
              " 'd',\n",
              " 'o',\n",
              " 'n',\n",
              " ' ',\n",
              " 'f',\n",
              " 'o',\n",
              " 'r',\n",
              " ' ',\n",
              " 'h',\n",
              " 'i',\n",
              " 's',\n",
              " ' ',\n",
              " 'f',\n",
              " 'r',\n",
              " 'i',\n",
              " 'e',\n",
              " 'n',\n",
              " 'd',\n",
              " '.',\n",
              " ' ',\n",
              " 'a',\n",
              " ' ',\n",
              " 'g',\n",
              " 'o',\n",
              " 'o',\n",
              " 'd',\n",
              " ' ',\n",
              " '“',\n",
              " 'p',\n",
              " 'a',\n",
              " 'l',\n",
              " '”',\n",
              " ' ',\n",
              " 'o',\n",
              " 'f',\n",
              " ' ',\n",
              " 'l',\n",
              " 'o',\n",
              " 'w',\n",
              " ' ',\n",
              " 'r',\n",
              " 'a',\n",
              " 't',\n",
              " 'i',\n",
              " 'n',\n",
              " 'g',\n",
              " 's',\n",
              " ' ',\n",
              " 's',\n",
              " 'h',\n",
              " 'e',\n",
              " 'p',\n",
              " 'a',\n",
              " 'r',\n",
              " 'd',\n",
              " ' ',\n",
              " 's',\n",
              " 'm',\n",
              " 'i',\n",
              " 't',\n",
              " 'h',\n",
              " '.',\n",
              " ' ',\n",
              " 't',\n",
              " 'h',\n",
              " 'a',\n",
              " 'n',\n",
              " 'k',\n",
              " ' ',\n",
              " 'y',\n",
              " 'o',\n",
              " 'u',\n",
              " ' ',\n",
              " 't',\n",
              " 'o',\n",
              " ' ',\n",
              " 'b',\n",
              " 'r',\n",
              " 'i',\n",
              " 'l',\n",
              " 'l',\n",
              " 'i',\n",
              " 'a',\n",
              " 'n',\n",
              " 't',\n",
              " ' ',\n",
              " 'a',\n",
              " 'n',\n",
              " 'd',\n",
              " ' ',\n",
              " 'h',\n",
              " 'i',\n",
              " 'g',\n",
              " 'h',\n",
              " 'l',\n",
              " 'y',\n",
              " ' ',\n",
              " 'r',\n",
              " 'e',\n",
              " 's',\n",
              " 'p',\n",
              " 'e',\n",
              " 'c',\n",
              " 't',\n",
              " 'e',\n",
              " 'd',\n",
              " ' ',\n",
              " 'a',\n",
              " 't',\n",
              " 't',\n",
              " 'o',\n",
              " 'r',\n",
              " 'n',\n",
              " 'e',\n",
              " 'y',\n",
              " ' ',\n",
              " 'a',\n",
              " 'l',\n",
              " 'a',\n",
              " 'n',\n",
              " ' ',\n",
              " 'd',\n",
              " 'e',\n",
              " 'r',\n",
              " 's',\n",
              " 'h',\n",
              " 'o',\n",
              " 'w',\n",
              " 'i',\n",
              " 't',\n",
              " 'z',\n",
              " ' ',\n",
              " 'f',\n",
              " 'o',\n",
              " 'r',\n",
              " ' ',\n",
              " 'd',\n",
              " 'e',\n",
              " 's',\n",
              " 't',\n",
              " 'r',\n",
              " 'o',\n",
              " 'y',\n",
              " 'i',\n",
              " 'n',\n",
              " 'g',\n",
              " ' ',\n",
              " 't',\n",
              " 'h',\n",
              " 'e',\n",
              " ' ',\n",
              " 'v',\n",
              " 'e',\n",
              " 'r',\n",
              " 'y',\n",
              " ' ',\n",
              " 'd',\n",
              " 'u',\n",
              " 'm',\n",
              " 'b',\n",
              " ' ',\n",
              " 'l',\n",
              " 'e',\n",
              " 'g',\n",
              " 'a',\n",
              " 'l',\n",
              " ' ',\n",
              " 'a',\n",
              " 'r',\n",
              " 'g',\n",
              " 'u',\n",
              " 'm',\n",
              " 'e',\n",
              " 'n',\n",
              " 't',\n",
              " ' ',\n",
              " 'o',\n",
              " 'f',\n",
              " ' ',\n",
              " '“',\n",
              " 'j',\n",
              " 'u',\n",
              " 'd',\n",
              " 'g',\n",
              " 'e',\n",
              " '”',\n",
              " ' ',\n",
              " 'a',\n",
              " 'n',\n",
              " 'd',\n",
              " 'r',\n",
              " 'e',\n",
              " 'w',\n",
              " ' ',\n",
              " 'n',\n",
              " 'a',\n",
              " 'p',\n",
              " 'o',\n",
              " 'l',\n",
              " 'i',\n",
              " 't',\n",
              " 'a',\n",
              " 'n',\n",
              " 'o',\n",
              " '.',\n",
              " '.',\n",
              " '.',\n",
              " '.',\n",
              " ' ',\n",
              " 't',\n",
              " 'h',\n",
              " 'a',\n",
              " 'n',\n",
              " 'k',\n",
              " ' ',\n",
              " 'y',\n",
              " 'o',\n",
              " 'u',\n",
              " ' ',\n",
              " 'g',\n",
              " 'r',\n",
              " 'e',\n",
              " 'e',\n",
              " 'n',\n",
              " ' ',\n",
              " 'b',\n",
              " 'a',\n",
              " 'y',\n",
              " ',',\n",
              " ' ',\n",
              " 'w',\n",
              " 'i',\n",
              " 's',\n",
              " 'c',\n",
              " 'o',\n",
              " 'n',\n",
              " 's',\n",
              " 'i',\n",
              " 'n',\n",
              " '!',\n",
              " ' ',\n",
              " 'm',\n",
              " 'a',\n",
              " 'k',\n",
              " 'e',\n",
              " ' ',\n",
              " 'a',\n",
              " 'm',\n",
              " 'e',\n",
              " 'r',\n",
              " 'i',\n",
              " 'c',\n",
              " 'a',\n",
              " ' ',\n",
              " 'g',\n",
              " 'r',\n",
              " 'e',\n",
              " 'a',\n",
              " 't',\n",
              " ' ',\n",
              " 'a',\n",
              " 'g',\n",
              " 'a',\n",
              " 'i',\n",
              " 'n',\n",
              " '!',\n",
              " '!',\n",
              " ' ',\n",
              " 'h',\n",
              " 't',\n",
              " 't',\n",
              " 'p',\n",
              " 's',\n",
              " ':',\n",
              " '/',\n",
              " '/',\n",
              " 't',\n",
              " '.',\n",
              " 'c',\n",
              " 'o',\n",
              " '/',\n",
              " 'c',\n",
              " 'h',\n",
              " 'g',\n",
              " 'l',\n",
              " 'x',\n",
              " 'g',\n",
              " 's',\n",
              " 'p',\n",
              " 'q',\n",
              " 'h',\n",
              " ' ',\n",
              " 'b',\n",
              " 'e',\n",
              " 'a',\n",
              " 'u',\n",
              " 't',\n",
              " 'i',\n",
              " 'f',\n",
              " 'u',\n",
              " 'l',\n",
              " ' ',\n",
              " '#',\n",
              " 't',\n",
              " 'r',\n",
              " 'u',\n",
              " 'm',\n",
              " 'p',\n",
              " 'r',\n",
              " 'a',\n",
              " 'l',\n",
              " 'l',\n",
              " 'y',\n",
              " ' ',\n",
              " 't',\n",
              " 'o',\n",
              " 'n',\n",
              " 'i',\n",
              " 'g',\n",
              " 'h',\n",
              " 't',\n",
              " ' ',\n",
              " 'i',\n",
              " 'n',\n",
              " ' ',\n",
              " 'g',\n",
              " 'r',\n",
              " 'e',\n",
              " 'e',\n",
              " 'n',\n",
              " ' ',\n",
              " 'b',\n",
              " 'a',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu_i5puIVeOK",
        "colab_type": "text"
      },
      "source": [
        "## Aufgabe 2\n",
        "Nachdem wir uns einen Überblick über den Datensatz verschafft und uns für die Zeichen entschieden haben, die wir bei der Modellierung berücksichtigen wollen, geht es nun darum, die Daten so aufzubereiten, dass wir ein Modell trainieren können.\n",
        "\n",
        "Das Training soll wie folgt ablaufen: Gegeben n Zeichen, soll das Modell das n+1-te Zeichen vorhersagen. Dazu müssen wir die einzelnen Zeichen in Vektorform bringen. Wir wählen dazu ein One-Hot-Encoding und bilden folglich jedes der Einzelzeichen in ```cleaned_tweet_chars``` auf einen Vektor ab, der genau eine 1 enthält.\n",
        "\n",
        "(Zu) einfaches Beispiel: ```['a', 'b', 'c'] => [(1,0,0), (0,1,0), (0,0,1)]```\n",
        "\n",
        "### 2.1 Indizes für das One-Hot-Encoding\n",
        "Um entscheiden zu können, an welcher Stelle wir die 1 setzen, müssen wir jedem Zeichen einen eindeutigen Index zuweisen.\n",
        "Umgekehrt wollen wir auch zu jedem Index schnell das zugehörige Zeichen ermitteln können. Wir erstellen daher zwei Dictionaries: ```char2index``` für die Abbildung von Zeichen zu Index und ```index2char``` für die umgekehrte Abbildung von Index zu Zeichen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrlVlNqVVeOM",
        "colab_type": "code",
        "outputId": "266033c6-7ef5-4c4c-8cad-d93e4d9cfd55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import collections\n",
        "top_chars = Counter(cleaned_tweet_chars).most_common(57)\n",
        "top_chars[0][0]\n",
        "\n",
        "#char_set = collections.OrderedDict.fromkeys(item for sublist in cleaned_tweet_chars for item in sublist)# TODO Menge aller verwendeten Zeichen nach Bereinigung\n",
        "print('Anzahl Zeichen: {}'.format(len(top_chars)))\n",
        "char2index = {word[0]: index for index, word in enumerate(top_chars)}# TODO Abbildung Zeichen => Index\n",
        "index2char = {index: word[0] for index, word in enumerate(top_chars)}# TODO Abbildung Index => Zeichen\n",
        "print(char2index)\n",
        "print(index2char)\n",
        "\n",
        "\n",
        "cleaned_tweet_chars = [char for char in cleaned_tweet_chars if char in char2index.keys() ]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Anzahl Zeichen: 57\n",
            "{' ': 0, 'e': 1, 't': 2, 'a': 3, 'o': 4, 'i': 5, 'n': 6, 'r': 7, 's': 8, 'h': 9, 'l': 10, 'd': 11, 'c': 12, 'u': 13, 'm': 14, 'p': 15, 'g': 16, 'y': 17, 'w': 18, 'b': 19, '.': 20, 'f': 21, 'v': 22, 'k': 23, '/': 24, ',': 25, '@': 26, '!': 27, ':': 28, 'j': 29, '-': 30, 'x': 31, '0': 32, \"'\": 33, '1': 34, 'z': 35, '2': 36, '\"': 37, '#': 38, 'q': 39, '’': 40, '&': 41, '3': 42, '6': 43, '5': 44, '7': 45, '4': 46, '8': 47, '9': 48, '“': 49, '”': 50, '?': 51, ')': 52, '(': 53, '_': 54, '$': 55, '%': 56}\n",
            "{0: ' ', 1: 'e', 2: 't', 3: 'a', 4: 'o', 5: 'i', 6: 'n', 7: 'r', 8: 's', 9: 'h', 10: 'l', 11: 'd', 12: 'c', 13: 'u', 14: 'm', 15: 'p', 16: 'g', 17: 'y', 18: 'w', 19: 'b', 20: '.', 21: 'f', 22: 'v', 23: 'k', 24: '/', 25: ',', 26: '@', 27: '!', 28: ':', 29: 'j', 30: '-', 31: 'x', 32: '0', 33: \"'\", 34: '1', 35: 'z', 36: '2', 37: '\"', 38: '#', 39: 'q', 40: '’', 41: '&', 42: '3', 43: '6', 44: '5', 45: '7', 46: '4', 47: '8', 48: '9', 49: '“', 50: '”', 51: '?', 52: ')', 53: '(', 54: '_', 55: '$', 56: '%'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w-tsl0yVeOQ",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 Generiere Trainingsdaten\n",
        "Wie bereits beschrieben, soll das Modell n Zeichen entgegennehmen und das n+1-te Zeichen vorhersagen. Wir generieren uns Trainingsdaten, indem wir ```sentences``` eine Liste von ```input_length``` Zeichen aus ```cleaned_tweet_chars``` hinzufügen, ```next_chars``` das darauf folgende ```input_length+1```-te Zeichen und dies alle ```step``` Zeichen wiederholen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ3Vdd-xVeOR",
        "colab_type": "code",
        "outputId": "60d81698-0189-4928-a6c0-bbc064a30ee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_length = 30\n",
        "step = 4\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "\n",
        "for i in range(0, len(cleaned_tweet_chars) - (input_length + 1), 4):\n",
        "    sentences.append(cleaned_tweet_chars[i:i + input_length])\n",
        "    next_chars.append(cleaned_tweet_chars[i + input_length + 1])\n",
        "print('Anzahl Trainingssätze: {}'.format(len(sentences)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Anzahl Trainingssätze: 777294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YiTJXnPVeOV",
        "colab_type": "text"
      },
      "source": [
        "### 2.3 Vektorisierung\n",
        "Nun können wir daran gehen, die Daten zu vektorisieren. Die Eingabe ```x``` enthält für jeden der Trainingssätze in ```sentences``` one-hot-codierte Vektoren der Zeichen, aus denen der jeweilige Satz besteht. \n",
        "Die erwartete Ausgabe ```y``` basiert auf ```next_chars``` und enthält für jeden der Trainingssätze einen einzelnen one-hot-codierten Vektor für das als Fortsetzung des Satzes erwartete Zeichen.\n",
        "\n",
        "Beispiel: Wenn ```sentences``` an Position ```i``` die Sequenz ```['a', 'b', 'c']``` und ```next_chars``` an derselben Stelle ```'d'``` enthält, dann enthält ```x``` bei entsprechender Kodierung an Position ```i``` ```[[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0]]``` und ```y``` an der entsprechenden Stelle ```[0, 0, 0, 1]```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xcxkGYTVeOV",
        "colab_type": "code",
        "outputId": "2f26b92b-7151-4c10-a841-fc787ad7dac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "print('Vektorisierung ...')\n",
        "x = np.zeros((len(sentences), input_length, len(char2index)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(char2index)), dtype=np.bool)\n",
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i][t][char2index[char]] = 1\n",
        "    y[i][char2index[next_chars[i]]] = 1\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vektorisierung ...\n",
            "[[False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " ...\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHfESVgLVeOb",
        "colab_type": "text"
      },
      "source": [
        "### 2.4 Definition des Modells\n",
        "\n",
        "Für unseren Tweet-Generator werden wir ein recht einfaches Modell trainieren. Wir verwenden wieder die Sequential-API. \n",
        "\n",
        "Der erste Layer ist direkt das Herzstück unseres Modells: Der LSTM-Layer. \n",
        "\n",
        "Als Anzahl der Units verwenden wir 128.\n",
        "Welche Dimensionen hat die ```input_shape```? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGU1YTsLVeOc",
        "colab_type": "code",
        "outputId": "d71251d9-6238-484c-c3d3-90499ff58827",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "from keras import metrics\n",
        "\n",
        "number_chars = len(char2index)\n",
        "\n",
        "print('Erstelle Model...')\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(input_length, number_chars)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Erstelle Model...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9KrGcSWVeOg",
        "colab_type": "text"
      },
      "source": [
        "Als Ausgabelayer fügen wir einen Dense-Layer hinzu. Wie müssen wir die Anzahl der Hidden-Units wählen? Wieso ist ```softmax``` eine geeignete Aktivierungsfunktion?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK9LZ3mwVeOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(number_chars, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV2nfXRnVeOm",
        "colab_type": "text"
      },
      "source": [
        "Als Optimizer wählen wir RMSprop mit einer Learning-Rate von 0.005 und als Loss-Funktion ```categorical_crossentropy```.\n",
        "\n",
        "Wieso können wir nicht wie im letzten Labor ```binary_crossentropy``` verwenden?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20GSsCi3VeOm",
        "colab_type": "code",
        "outputId": "a1ec26bd-bd1e-4289-a232-8278ade94df0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "optimizer = RMSprop(lr=0.005)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 128)               95232     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 57)                7353      \n",
            "=================================================================\n",
            "Total params: 102,585\n",
            "Trainable params: 102,585\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TLC1GunVeOr",
        "colab_type": "text"
      },
      "source": [
        "### 2.5 Training des Models\n",
        "\n",
        "Nach all den Vorarbeiten können wir nun daran gehen, unser Model zu trainieren.\n",
        "Um das Model bei Bedarf nicht neu definieren zu müssen, speichern wir uns dessen Struktur als JSON ab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCS2dnGXVeOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_structure = model.to_json()\n",
        "with open(\"/data/My Drive/Colab Notebooks/data/text_generation_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_structure)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UN70jJpkVeOv",
        "colab_type": "text"
      },
      "source": [
        "Um unsere Trainingsfortschritte nicht zu verlieren, definieren wir uns eine Checkpoint-Funktion, die als Callback aufgerufen wird und den aktuellen Modelzustand abspeichert, solange das Modell besser ist, als das bisher gespeicherte Model. Gespeichert werden soll das komplette Model, nicht nur die Gewichte."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5x8BnPzVeOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "model_checkpoint = ModelCheckpoint('/data/My Drive/Colab Notebooks/data/text_generation.hd5', monitor='acc', save_best_only=True)# TODO nur bestes Model speichern, komplettes Model speichern"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evpRDb_tVeOz",
        "colab_type": "text"
      },
      "source": [
        "Wir können unser Model nun trainieren. Um in ansehbarer Zeit Ergebnisse zu sehen, führen wir unser Training über 20 Epochen mit eine Batch-Size von 100 durch.\n",
        "\n",
        "Um die Entwicklung des Models später auswerten zu können, speichern wir uns die History."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdIW6Cr_VeO1",
        "colab_type": "code",
        "outputId": "836909a5-07b7-4dca-aa08-03ae5e7960f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pickle\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 100\n",
        "\n",
        "\n",
        "model_history = model.fit(x, y, epochs=epochs, batch_size=batch_size, callbacks=[model_checkpoint]) \n",
        "# TODO Model fit mit Trainingsdaten, angegebenen Parametern und checkpoint\n",
        "\n",
        "with open(\"/data/My Drive/Colab Notebooks/data/text_generation_history\", 'wb') as hist_file:\n",
        "    pickle.dump(model_history.history, hist_file)\n",
        "print('History gespeichert.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "777294/777294 [==============================] - 465s 598us/step - loss: 2.4475 - acc: 0.3290\n",
            "Epoch 2/20\n",
            "777294/777294 [==============================] - 491s 632us/step - loss: 2.2183 - acc: 0.3902\n",
            "Epoch 3/20\n",
            "777294/777294 [==============================] - 487s 627us/step - loss: 2.1595 - acc: 0.4051\n",
            "Epoch 4/20\n",
            "777294/777294 [==============================] - 494s 635us/step - loss: 2.1294 - acc: 0.4125\n",
            "Epoch 5/20\n",
            "777294/777294 [==============================] - 490s 630us/step - loss: 2.1103 - acc: 0.4173\n",
            "Epoch 6/20\n",
            "777294/777294 [==============================] - 491s 632us/step - loss: 2.0982 - acc: 0.4203\n",
            "Epoch 7/20\n",
            "777294/777294 [==============================] - 492s 633us/step - loss: 2.0892 - acc: 0.4234\n",
            "Epoch 8/20\n",
            "777294/777294 [==============================] - 487s 627us/step - loss: 2.0796 - acc: 0.4260\n",
            "Epoch 9/20\n",
            "777294/777294 [==============================] - 504s 648us/step - loss: 2.0755 - acc: 0.4270\n",
            "Epoch 10/20\n",
            "777294/777294 [==============================] - 496s 638us/step - loss: 2.0697 - acc: 0.4287\n",
            "Epoch 11/20\n",
            "777294/777294 [==============================] - 498s 641us/step - loss: 2.0638 - acc: 0.4301\n",
            "Epoch 12/20\n",
            "777294/777294 [==============================] - 495s 637us/step - loss: 2.0612 - acc: 0.4303\n",
            "Epoch 13/20\n",
            "777294/777294 [==============================] - 496s 638us/step - loss: 2.0579 - acc: 0.4319\n",
            "Epoch 14/20\n",
            "777294/777294 [==============================] - 493s 634us/step - loss: 2.0570 - acc: 0.4325\n",
            "Epoch 15/20\n",
            "777294/777294 [==============================] - 500s 643us/step - loss: 2.0546 - acc: 0.4331\n",
            "Epoch 16/20\n",
            "777294/777294 [==============================] - 503s 647us/step - loss: 2.0520 - acc: 0.4339\n",
            "Epoch 17/20\n",
            "777294/777294 [==============================] - 498s 640us/step - loss: 2.0526 - acc: 0.4338\n",
            "Epoch 18/20\n",
            "777294/777294 [==============================] - 499s 642us/step - loss: 2.0516 - acc: 0.4344\n",
            "Epoch 19/20\n",
            "777294/777294 [==============================] - 490s 631us/step - loss: 2.0516 - acc: 0.4343\n",
            "Epoch 20/20\n",
            "777294/777294 [==============================] - 497s 640us/step - loss: 2.0504 - acc: 0.4349\n",
            "History gespeichert.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHftTUtkVeO3",
        "colab_type": "text"
      },
      "source": [
        "## Aufgabe 3\n",
        "Zum Abschluss wollen wir noch etwas Spaß mit unserem Modell haben. Aus diesem Grund laden wir uns das gespeicherte (bisher) beste Model und verwenden es, um basierend auf einem \"Seed\" neue Tweets zu generieren."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GszYMfWFVeO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "loaded_model = load_model('text_generation.hd5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ai9RNX7yVeO7",
        "colab_type": "text"
      },
      "source": [
        "### Eine kleine Hilfsfunktion\n",
        "Der Ausgabelayer unseres Models beschreibt eine Wahrscheinlichkeitsverteilung über alle möglichen Ausgabezeichen. Was wir tun wollen, ist anhand dieser Verteilung eine repräsentative Stichprobe zu ziehen. Ähnlich wie bei Markov-Ketten wählen wir als nächstes Zeichen nicht zwangsläufig das, mit der höchsten Auftrittswahrscheinlichkeit, denn wir wollen uns ja eine gewissen künstlerisch-kreative Freiheit erhalten, aber wir orientieren uns bei der Auswahl an der Auftrittswahrscheinlichkeit der potentiellen Folgetokens im gegebenen Kontext.\n",
        "\n",
        "Die Hilfsmethode, die wir dazu verwenden, ist aus dem Keras-Tutorial zu LSTMs übernommen. Der Parameter ```temperature``` schärft die ursprüngliche Wahrscheinlichkeitsverteilung oder schwächt sie ab. Bei ```temperature > 1``` ist die Ausgabe diverser, allerdings potentiell auch konfuser, bei ```temperature < 1 ``` bleiben wir näher an den Originaltweets.\n",
        "\n",
        "```multinominal(num_samples, probabilities_list, size``` zieht ```size```-mal ```num_samples``` Beispiele aus einer Verteilung, deren Eigenschaften durch ```probabilities_list``` beschrieben wird. In unserem Fall wollen wir einmal ziehen und zwar genau ein Beispiel. Ausgabe ist demnach eine Liste, die einen einzigen Vektor enthält, der genauso lang ist, wie die Wahrscheinlichkeitsverteilung, die wir in die Funktion hineingeben, und der eine einzige 1 enthält. Für den Index dieser 1 interessieren wir uns, weil wir das entsprechend one-hot-codierte Zeichen als nächstes ausgeben wollen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WtjJPlbVeO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds.clip(min=0.0001)) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cCU8Q4pVePB",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Tweets erzeugen\n",
        "Um neue Tweets zu erzeugen, brauchen wir einen Seed, mit dem unser Model arbeiten kann. Wir machen es uns einfach und wählen einen zufälligen Startindex, ab dem ```input_length``` Zeichen aus unserer langen Tweet-Liste ```cleaned_tweet_chars``` herausgenommen werden.\n",
        "\n",
        "Diese vektorisieren wir dann und füttern unser Model mit dem so entstandenen Vektor, um das nächste Zeichen vorherzusagen, das dann wiederum Teil des Seeds für die nächste Vorhersage ist.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "w6aIR6XwVePF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "seed_start_index = # TODO Zufallszahl für Startindex innerhalb von cleaned_tweet_chars wählen\n",
        "\n",
        "for diversity in [0.2, 0.5, 0.8, 1.0, 1.2]:\n",
        "    print()\n",
        "    print('----- Diversität:', diversity)\n",
        "\n",
        "    generated = ''\n",
        "    sentence = # Subliste der passenden Länge aus cleaned_tweet_charts extrahieren\n",
        "    generated += ''.join(sentence)\n",
        "    print('----- Erzeuge Tweet aus Seed: \"' + ''.join(sentence) + '\"\\n')\n",
        "    sys.stdout.write(generated)\n",
        "\n",
        "    for i in range(250):\n",
        "        x = np.zeros((1, #TODO 2. Dimension?, len(char_set)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x[0, t, # TODO Wo muss die 1 hin?] = 1.\n",
        "\n",
        "        preds = loaded_model.predict(x, verbose=0)[0]\n",
        "        next_index = sample(preds, diversity)\n",
        "        next_char = # TODO Welchem Zeichen entspricht der Index?\n",
        "\n",
        "        generated += next_char\n",
        "        sentence = # TODO sentence bleibt eine Liste von Zeichen, aber das erste fällt weg und next_char kommt am Ende neu hinzu\n",
        "\n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAyRZJSCVePI",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Entwicklung von Loss und Accuracy\n",
        "Um die Aufgabe abzuschließen, wollen wir noch einen Blick auf die Entwicklung von Loss und Accuracy über die Trainingsepochen werfen. Wir haben die \"Geschichte\" unseres Models in der Datei ```text_generation_history``` abgespeichert.\n",
        "\n",
        "Nutzt ```pyplot```, um die Entwicklung von Accuracy und Loss grafisch darzustellen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA3W0A2sVePJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with open(\"text_generation_history\", 'rb') as hist_file:\n",
        "    history = pickle.load(hist_file)\n",
        "    \n",
        "plt.plot(# Entwicklung der Accuracy)\n",
        "plt.title('Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "\n",
        "# TODO Loss plotten\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}