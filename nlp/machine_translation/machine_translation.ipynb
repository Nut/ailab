{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "machine_translation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbzAdFoSwwRn",
        "colab_type": "text"
      },
      "source": [
        "# Machine Translation\n",
        "\n",
        "In diesem Notebook möchten wir uns mit der Königsdisziplin des Natural Language Processings beschäftigen, der maschinellen Übersetzung.\n",
        "Vermutlich gibt es keine NLP-Anwendung, die einerseits vielen bekannt ist, anderseits durch Deep Learning und neuronalen Netzen einen solchen Aufschwung bekommen hat.\n",
        "Vor dem Siegeszug der neuronalen Netzen, wurde maschinelle Übersetzung deshalb als schwierig angesehen, weil sie alle Teilaspekte von Sprache beinhaltet. Neben grammatikalischer Korrektheit, sollen maschinell übersetzte Texte den Sinn des Originaltextes wiedergeben und darüberhinaus auch den Subtext, wie Ironie, Witz, erfassen.\n",
        "Ob letzteres einfach gelingt, sei hier mal dahingestellt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ssQRQSPwwRr",
        "colab_type": "text"
      },
      "source": [
        "## Daten\n",
        "Im Vergleich zu den bisherigen Notebooks sind die Daten für machine translation etwas dröge. Daher möchten wir uns hier nicht allzu lange aufhalten. Speichert zunächst folgende Datei ab und entpackt sie: http://www.manythings.org/anki/fra-eng.zip\n",
        "\n",
        "Danach wollen wir die Daten einlesen. Das Format ist einfach, pro Zeile steht ein Satzpaar getrennt von einem Tab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v6uVewgw5q5",
        "colab_type": "code",
        "outputId": "9ee141ff-e2eb-4185-b3ea-bc1bd475a405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/data')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /data; to attempt to forcibly remount, call drive.mount(\"/data\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcE2FjmdwwRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/data/My Drive/Colab Notebooks/data/fra.txt', 'r') as f:\n",
        "    lines = f.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyjxNXBdwwR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pairs = [tuple(l.split(\"\\t\")) for l in lines]\n",
        "pairs = pairs[:5000]\n",
        "# pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PaFLVEIwwR-",
        "colab_type": "code",
        "outputId": "b1ded446-9baf-435b-a7c9-7c0a0a48c4fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pairs_cleaned = [(e, f.strip()) for e, f, m in pairs]\n",
        "pairs_cleaned"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Go.', 'Va !'),\n",
              " ('Hi.', 'Salut !'),\n",
              " ('Hi.', 'Salut.'),\n",
              " ('Run!', 'Cours\\u202f!'),\n",
              " ('Run!', 'Courez\\u202f!'),\n",
              " ('Who?', 'Qui ?'),\n",
              " ('Wow!', 'Ça alors\\u202f!'),\n",
              " ('Fire!', 'Au feu !'),\n",
              " ('Help!', \"À l'aide\\u202f!\"),\n",
              " ('Jump.', 'Saute.'),\n",
              " ('Stop!', 'Ça suffit\\u202f!'),\n",
              " ('Stop!', 'Stop\\u202f!'),\n",
              " ('Stop!', 'Arrête-toi !'),\n",
              " ('Wait!', 'Attends !'),\n",
              " ('Wait!', 'Attendez !'),\n",
              " ('Go on.', 'Poursuis.'),\n",
              " ('Go on.', 'Continuez.'),\n",
              " ('Go on.', 'Poursuivez.'),\n",
              " ('Hello!', 'Bonjour !'),\n",
              " ('Hello!', 'Salut !'),\n",
              " ('I see.', 'Je comprends.'),\n",
              " ('I try.', \"J'essaye.\"),\n",
              " ('I won!', \"J'ai gagné !\"),\n",
              " ('I won!', \"Je l'ai emporté !\"),\n",
              " ('I won.', 'J’ai gagné.'),\n",
              " ('Oh no!', 'Oh non !'),\n",
              " ('Attack!', 'Attaque !'),\n",
              " ('Attack!', 'Attaquez !'),\n",
              " ('Cheers!', 'Santé !'),\n",
              " ('Cheers!', 'À votre santé !'),\n",
              " ('Cheers!', 'Merci !'),\n",
              " ('Cheers!', 'Tchin-tchin !'),\n",
              " ('Get up.', 'Lève-toi.'),\n",
              " ('Go now.', 'Va, maintenant.'),\n",
              " ('Go now.', 'Allez-y maintenant.'),\n",
              " ('Go now.', 'Vas-y maintenant.'),\n",
              " ('Got it!', \"J'ai pigé !\"),\n",
              " ('Got it!', 'Compris !'),\n",
              " ('Got it?', 'Pigé\\u202f?'),\n",
              " ('Got it?', 'Compris\\u202f?'),\n",
              " ('Got it?', \"T'as capté\\u202f?\"),\n",
              " ('Hop in.', 'Monte.'),\n",
              " ('Hop in.', 'Montez.'),\n",
              " ('Hug me.', 'Serre-moi dans tes bras !'),\n",
              " ('Hug me.', 'Serrez-moi dans vos bras !'),\n",
              " ('I fell.', 'Je suis tombée.'),\n",
              " ('I fell.', 'Je suis tombé.'),\n",
              " ('I know.', 'Je sais.'),\n",
              " ('I left.', 'Je suis parti.'),\n",
              " ('I left.', 'Je suis partie.'),\n",
              " ('I lost.', \"J'ai perdu.\"),\n",
              " ('I paid.', 'J’ai payé.'),\n",
              " (\"I'm 19.\", \"J'ai 19 ans.\"),\n",
              " (\"I'm OK.\", 'Je vais bien.'),\n",
              " (\"I'm OK.\", 'Ça va.'),\n",
              " ('Listen.', 'Écoutez !'),\n",
              " ('No way!', \"C'est pas possible\\u202f!\"),\n",
              " ('No way!', 'Impossible\\u202f!'),\n",
              " ('No way!', 'En aucun cas.'),\n",
              " ('No way!', 'Sans façons\\u202f!'),\n",
              " ('No way!', \"C'est hors de question !\"),\n",
              " ('No way!', \"Il n'en est pas question !\"),\n",
              " ('No way!', \"C'est exclu !\"),\n",
              " ('No way!', 'En aucune manière !'),\n",
              " ('No way!', 'Hors de question !'),\n",
              " ('Really?', 'Vraiment\\u202f?'),\n",
              " ('Really?', 'Vrai ?'),\n",
              " ('Really?', 'Ah bon ?'),\n",
              " ('Thanks.', 'Merci !'),\n",
              " ('We try.', 'On essaye.'),\n",
              " ('We won.', 'Nous avons gagné.'),\n",
              " ('We won.', 'Nous gagnâmes.'),\n",
              " ('We won.', \"Nous l'avons emporté.\"),\n",
              " ('We won.', \"Nous l'emportâmes.\"),\n",
              " ('Ask Tom.', 'Demande à Tom.'),\n",
              " ('Awesome!', 'Fantastique\\u202f!'),\n",
              " ('Be calm.', 'Sois calme !'),\n",
              " ('Be calm.', 'Soyez calme !'),\n",
              " ('Be calm.', 'Soyez calmes !'),\n",
              " ('Be cool.', 'Sois détendu !'),\n",
              " ('Be fair.', 'Sois juste !'),\n",
              " ('Be fair.', 'Soyez juste !'),\n",
              " ('Be fair.', 'Soyez justes !'),\n",
              " ('Be fair.', 'Sois équitable !'),\n",
              " ('Be fair.', 'Soyez équitable !'),\n",
              " ('Be fair.', 'Soyez équitables !'),\n",
              " ('Be kind.', 'Sois gentil.'),\n",
              " ('Be nice.', 'Sois gentil !'),\n",
              " ('Be nice.', 'Sois gentille !'),\n",
              " ('Be nice.', 'Soyez gentil !'),\n",
              " ('Be nice.', 'Soyez gentille !'),\n",
              " ('Be nice.', 'Soyez gentils !'),\n",
              " ('Be nice.', 'Soyez gentilles !'),\n",
              " ('Beat it.', 'Dégage\\u202f!'),\n",
              " ('Call me.', 'Appelle-moi !'),\n",
              " ('Call me.', 'Appellez-moi !'),\n",
              " ('Call us.', 'Appelle-nous !'),\n",
              " ('Call us.', 'Appelez-nous !'),\n",
              " ('Come in.', 'Entrez\\u202f!'),\n",
              " ('Come in.', 'Entre.'),\n",
              " ('Come in.', 'Entre !'),\n",
              " ('Come in.', 'Entrez !'),\n",
              " ('Come on!', 'Allez\\u202f!'),\n",
              " ('Come on.', 'Allez !'),\n",
              " ('Come on.', 'Viens !'),\n",
              " ('Come on.', 'Venez !'),\n",
              " ('Drop it!', 'Laisse tomber !'),\n",
              " ('Drop it!', 'Laissez tomber !'),\n",
              " ('Drop it!', 'Laisse-le tomber !'),\n",
              " ('Drop it!', 'Laissez-le tomber !'),\n",
              " ('Get Tom.', 'Va chercher Tom.'),\n",
              " ('Get out!', 'Sortez\\u202f!'),\n",
              " ('Get out!', 'Sors !'),\n",
              " ('Get out!', 'Sortez !'),\n",
              " ('Get out.', 'Sors.'),\n",
              " ('Get out.', 'Casse-toi.'),\n",
              " ('Go away!', 'Dégage\\u202f!'),\n",
              " ('Go away!', 'Pars !'),\n",
              " ('Go away.', 'Va te faire foutre !'),\n",
              " ('Go away.', 'Pars !'),\n",
              " ('Go away.', 'Dégage !'),\n",
              " ('Go away.', 'Fous le camp !'),\n",
              " ('Go away.', \"Pars d'ici.\"),\n",
              " ('Go away.', \"Va t'en !\"),\n",
              " ('Go away.', 'Disparais !'),\n",
              " ('Go away.', 'Allez-vous en !'),\n",
              " ('Go home.', 'Rentrez à la maison.'),\n",
              " ('Go home.', 'Rentre à la maison.'),\n",
              " ('Go home.', 'Rentre chez toi.'),\n",
              " ('Go home.', 'Rentrez chez vous.'),\n",
              " ('Go slow.', 'Va doucement !'),\n",
              " ('Go slow.', 'Allez doucement !'),\n",
              " ('Goodbye!', 'Adieu !'),\n",
              " ('Goodbye!', 'À la revoyure.'),\n",
              " ('Hang on!', 'Attends un peu !'),\n",
              " ('Hang on!', 'Attendez un peu !'),\n",
              " ('Hang on.', 'Tiens bon !'),\n",
              " ('Hang on.', 'Tenez bon !'),\n",
              " ('He quit.', 'Il laissa tomber.'),\n",
              " ('He quit.', 'Il a laissé tomber.'),\n",
              " ('He runs.', 'Il court.'),\n",
              " ('Help me!', 'Aide-moi !'),\n",
              " ('Help me.', 'Aide-moi.'),\n",
              " ('Help me.', 'Aidez-moi.'),\n",
              " ('Help us.', 'Aidez-nous !'),\n",
              " ('Help us.', 'Aide-nous !'),\n",
              " ('Hold it!', 'Ne bouge plus !'),\n",
              " ('Hold on.', 'Ne quittez pas.'),\n",
              " ('Hug Tom.', 'Fais un câlin à Tom.'),\n",
              " ('I agree.', 'Je suis du même avis.'),\n",
              " ('I cried.', \"J'ai pleuré.\"),\n",
              " ('I dozed.', 'Je me suis assoupi.'),\n",
              " ('I dozed.', 'Je me suis assoupie.'),\n",
              " ('I drive.', 'Je conduis.'),\n",
              " ('I smoke.', 'Je fume.'),\n",
              " ('I snore.', 'Je ronfle.'),\n",
              " ('I stink.', 'Je pue.'),\n",
              " ('I stood.', 'Je me suis tenu debout.'),\n",
              " ('I stood.', 'Je me suis tenue debout.'),\n",
              " ('I swore.', 'J’ai promis.'),\n",
              " ('I swore.', 'J’ai juré.'),\n",
              " ('I tried.', \"J'essayai.\"),\n",
              " ('I tried.', \"J'ai essayé.\"),\n",
              " ('I tried.', \"J'ai tenté.\"),\n",
              " ('I waved.', 'J’ai fait signe.'),\n",
              " (\"I'll go.\", \"J'irai.\"),\n",
              " (\"I'm Tom.\", 'Je suis Tom.'),\n",
              " (\"I'm fat.\", 'Je suis gras.'),\n",
              " (\"I'm fat.\", 'Je suis gros.'),\n",
              " (\"I'm fit.\", 'Je suis en forme.'),\n",
              " (\"I'm hit!\", 'Je suis touché !'),\n",
              " (\"I'm hit!\", 'Je suis touchée !'),\n",
              " (\"I'm ill.\", 'Je suis malade.'),\n",
              " (\"I'm sad.\", 'Je suis triste.'),\n",
              " (\"I'm shy.\", 'Je suis timide.'),\n",
              " (\"I'm wet.\", 'Je suis mouillé.'),\n",
              " (\"I'm wet.\", 'Je suis mouillée.'),\n",
              " (\"It's me!\", \"C'est bibi\\u202f!\"),\n",
              " ('Join us.', 'Joignez-vous.'),\n",
              " ('Join us.', 'Joignez-vous à nous.'),\n",
              " ('Keep it.', 'Garde-le !'),\n",
              " ('Keep it.', 'Gardez-le !'),\n",
              " ('Kiss me.', 'Embrasse-moi.'),\n",
              " ('Kiss me.', 'Embrassez-moi.'),\n",
              " ('Me, too.', 'Moi aussi.'),\n",
              " ('Open up.', 'Ouvre-moi\\u202f!'),\n",
              " ('Open up.', 'Ouvre.'),\n",
              " ('Perfect!', 'Parfait\\u202f!'),\n",
              " ('See you.', 'À plus.'),\n",
              " ('Show me.', 'Montre-moi !'),\n",
              " ('Show me.', 'Montrez-moi !'),\n",
              " ('Shut up!', 'Taisez-vous\\u202f!'),\n",
              " ('Shut up!', 'Ferme-la\\u202f!'),\n",
              " ('Shut up!', 'Tais-toi !'),\n",
              " ('Shut up!', 'Ferme-la !'),\n",
              " ('Shut up!', 'La ferme !'),\n",
              " ('So long.', 'À plus tard !'),\n",
              " ('Take it.', 'Prends-le\\u202f!'),\n",
              " ('Take it.', 'Prenez-le\\u202f!'),\n",
              " ('Take it.', 'Prends-le !'),\n",
              " ('Take it.', 'Prenez-le !'),\n",
              " ('Tell me.', 'Dis-moi !'),\n",
              " ('Tell me.', 'Dites-moi !'),\n",
              " ('Tom won.', 'Tom a gagné.'),\n",
              " ('Wake up!', 'Réveille-toi\\u202f!'),\n",
              " ('Wake up!', 'Réveille-toi !'),\n",
              " ('Wake up!', 'Réveillez-vous !'),\n",
              " ('Wake up.', 'Réveille-toi !'),\n",
              " ('Wake up.', 'Réveillez-vous !'),\n",
              " ('Wash up.', 'Lave-toi !'),\n",
              " ('Wash up.', 'Lavez-vous !'),\n",
              " ('We know.', 'Nous savons.'),\n",
              " ('We lost.', 'Nous perdîmes.'),\n",
              " ('We lost.', 'Nous avons perdu.'),\n",
              " ('We lost.', 'Nous fûmes battus.'),\n",
              " ('We lost.', 'Nous fûmes battues.'),\n",
              " ('We lost.', 'Nous fûmes défaits.'),\n",
              " ('We lost.', 'Nous fûmes défaites.'),\n",
              " ('We lost.', 'Nous avons été défaits.'),\n",
              " ('We lost.', 'Nous avons été défaites.'),\n",
              " ('We lost.', 'Nous avons été battus.'),\n",
              " ('We lost.', 'Nous avons été battues.'),\n",
              " ('Welcome.', 'Bienvenue\\u202f!'),\n",
              " ('Who won?', 'Qui a gagné ?'),\n",
              " ('Who won?', \"Qui l'a emporté ?\"),\n",
              " ('You run.', 'Tu cours.'),\n",
              " ('Am I fat?', 'Suis-je gros ?'),\n",
              " ('Am I fat?', 'Suis-je grosse ?'),\n",
              " ('Ask them.', 'Demande-leur.'),\n",
              " ('Ask them.', 'Demandez-leur.'),\n",
              " ('Back off!', 'Recule\\u2009!'),\n",
              " ('Back off!', 'Reculez.'),\n",
              " ('Back off.', 'Recule\\u2009!'),\n",
              " ('Back off.', 'Reculez.'),\n",
              " ('Back off.', 'Retire-toi\\u2009!'),\n",
              " ('Back off.', 'Retirez-vous.'),\n",
              " ('Be a man.', 'Sois un homme !'),\n",
              " ('Be a man.', 'Soyez un homme !'),\n",
              " ('Be still.', 'Sois calme !'),\n",
              " ('Be still.', 'Soyez calme !'),\n",
              " ('Be still.', 'Soyez calmes !'),\n",
              " ('Beats me.', 'Aucune idée.'),\n",
              " ('Beats me.', \"J'en sais foutre rien.\"),\n",
              " ('Call Tom.', 'Appelle Tom.'),\n",
              " ('Call Tom.', 'Appelez Tom.'),\n",
              " ('Cheer up!', 'Courage\\u202f!'),\n",
              " ('Cool off!', 'Détends-toi\\u202f!'),\n",
              " ('Cuff him.', 'Menottez-le.'),\n",
              " ('Drive on.', 'Avance !'),\n",
              " ('Drive on.', 'Avancez !'),\n",
              " ('Drive on.', 'Continue à rouler !'),\n",
              " ('Drive on.', 'Continuez à rouler !'),\n",
              " ('Find Tom.', 'Trouve Tom.'),\n",
              " ('Find Tom.', 'Trouvez Tom.'),\n",
              " ('Fix this.', 'Réparez ceci.'),\n",
              " ('Fix this.', 'Répare ça.'),\n",
              " ('Get down!', 'Lâche-toi !'),\n",
              " ('Get down.', 'Descends !'),\n",
              " ('Get down.', 'Descendez !'),\n",
              " ('Get down.', 'Lâche-toi !'),\n",
              " ('Get down.', 'Lâchez-vous !'),\n",
              " ('Get lost!', \"Va voir ailleurs si j'y suis\\u202f!\"),\n",
              " ('Get lost!', 'Dégage\\u202f!'),\n",
              " ('Get lost!', 'Va au diable !'),\n",
              " ('Get real!', 'Sois réaliste !'),\n",
              " ('Go ahead.', 'Vas-y.'),\n",
              " ('Go ahead.', 'Poursuis !'),\n",
              " ('Go ahead.', 'Passe devant !'),\n",
              " ('Go ahead.', 'Vas-y !'),\n",
              " ('Good job!', 'Bien joué\\u202f!'),\n",
              " ('Good job!', 'Bon boulot\\u202f!'),\n",
              " ('Good job!', 'Beau travail\\u202f!'),\n",
              " ('Grab him.', 'Attrape-le.'),\n",
              " ('Grab him.', 'Attrapez-le.'),\n",
              " ('Have fun.', 'Amuse-toi bien !'),\n",
              " ('Have fun.', 'Amusez-vous bien !'),\n",
              " ('He tries.', 'Il essaye.'),\n",
              " (\"He's wet.\", 'Il est mouillé.'),\n",
              " ('Help Tom.', 'Aide Tom.'),\n",
              " ('Help Tom.', 'Aidez Tom.'),\n",
              " ('Hi, guys.', 'Salut, les mecs !'),\n",
              " ('How cute!', \"Comme c'est mignon\\u202f!\"),\n",
              " ('How deep?', 'Quelle profondeur\\u202f?'),\n",
              " ('How nice!', \"Comme c'est chouette !\"),\n",
              " ('How nice!', \"Comme c'est gentil !\"),\n",
              " ('How nice!', \"C'est du joli !\"),\n",
              " ('How nice!', \"Comme c'est agréable !\"),\n",
              " ('Hurry up.', 'Dépêche-toi.'),\n",
              " ('Hurry up.', 'Grouille\\u202f!'),\n",
              " ('Hurry up.', 'Pressez-vous !'),\n",
              " ('Hurry up.', 'Fiça !'),\n",
              " ('I am fat.', 'Je suis gras.'),\n",
              " ('I did OK.', \"Je m'en suis bien sorti.\"),\n",
              " ('I did OK.', \"Je m'en suis bien sortie.\"),\n",
              " ('I did it.', \"Je l'ai fait.\"),\n",
              " ('I did it.', \"C'est moi qui l'ai fait.\"),\n",
              " ('I failed.', \"J'ai échoué.\"),\n",
              " ('I forgot.', \"J'ai oublié.\"),\n",
              " ('I get it.', \"J'ai compris.\"),\n",
              " ('I got it.', \"J'ai compris.\"),\n",
              " ('I got it.', \"J'ai capté.\"),\n",
              " ('I helped.', \"J'ai aidé.\"),\n",
              " ('I jumped.', \"J'ai sauté.\"),\n",
              " ('I looked.', 'J’ai regardé.'),\n",
              " ('I moaned.', 'J’ai râlé.'),\n",
              " ('I nodded.', 'J’ai fait signe de la tête.'),\n",
              " ('I obeyed.', 'J’ai obéi.'),\n",
              " ('I phoned.', 'Je téléphonai.'),\n",
              " ('I phoned.', \"J'ai téléphoné.\"),\n",
              " ('I refuse.', 'Je refuse.'),\n",
              " ('I refuse.', 'Je le refuse.'),\n",
              " ('I rested.', 'Je me suis reposé.'),\n",
              " ('I rested.', 'Je me suis reposée.'),\n",
              " ('I saw it.', \"Je l'ai vu.\"),\n",
              " ('I saw it.', 'Je l’ai vu.'),\n",
              " ('I sighed.', 'J’ai soupiré.'),\n",
              " ('I stayed.', 'Je suis resté.'),\n",
              " ('I stayed.', 'Je suis restée.'),\n",
              " ('I talked.', 'J’ai parlé.'),\n",
              " ('I use it.', \"Je l'utilise.\"),\n",
              " ('I use it.', \"J'en fais usage.\"),\n",
              " ('I use it.', \"Je m'en sers.\"),\n",
              " (\"I'll pay.\", 'Je paierai.'),\n",
              " (\"I'll try.\", 'Je vais essayer.'),\n",
              " (\"I'll try.\", \"J'essaierai.\"),\n",
              " (\"I'm back.\", 'Je suis revenu.'),\n",
              " (\"I'm back.\", 'Me revoilà.'),\n",
              " (\"I'm bald.\", 'Je suis chauve.'),\n",
              " (\"I'm busy.\", 'Je suis occupé.'),\n",
              " (\"I'm busy.\", 'Je suis occupée.'),\n",
              " (\"I'm calm.\", 'Je suis calme.'),\n",
              " (\"I'm cold.\", \"J'ai froid.\"),\n",
              " (\"I'm cool.\", 'Je suis détendu.'),\n",
              " (\"I'm cool.\", 'Je suis détendue.'),\n",
              " (\"I'm deaf.\", 'Je suis sourd.'),\n",
              " (\"I'm deaf.\", 'Je suis sourde.'),\n",
              " (\"I'm done.\", \"J'en ai fini.\"),\n",
              " (\"I'm fair.\", 'Je suis juste.'),\n",
              " (\"I'm fair.\", \"J'ai la peau claire.\"),\n",
              " (\"I'm fair.\", \"J'ai le teint clair.\"),\n",
              " (\"I'm fast.\", 'Je suis rapide.'),\n",
              " (\"I'm fine.\", 'Tout va bien.'),\n",
              " (\"I'm fine.\", 'Je vais bien.'),\n",
              " (\"I'm fine.\", 'Ça va.'),\n",
              " (\"I'm free!\", 'Je suis libre !'),\n",
              " (\"I'm free.\", 'Je suis libre.'),\n",
              " (\"I'm free.\", 'Je suis disponible.'),\n",
              " (\"I'm full.\", 'Je suis repu\\u202f!'),\n",
              " (\"I'm full.\", 'Je suis rassasié\\u202f!'),\n",
              " (\"I'm game.\", \"J'en suis.\"),\n",
              " (\"I'm game.\", 'Je suis de la partie.'),\n",
              " (\"I'm glad.\", 'Je suis content.'),\n",
              " (\"I'm home.\", 'Je suis chez moi.'),\n",
              " (\"I'm late.\", 'Je suis en retard.'),\n",
              " (\"I'm lazy.\", 'Je suis paresseux.'),\n",
              " (\"I'm lazy.\", 'Je suis fainéant.'),\n",
              " (\"I'm lazy.\", 'Je suis paresseuse.'),\n",
              " (\"I'm lazy.\", 'Je suis fainéante.'),\n",
              " (\"I'm okay.\", 'Je vais bien.'),\n",
              " (\"I'm okay.\", 'Je me porte bien.'),\n",
              " (\"I'm rich.\", 'Je suis riche.'),\n",
              " (\"I'm safe.\", 'Je suis en sécurité.'),\n",
              " (\"I'm sick.\", 'Je suis malade.'),\n",
              " (\"I'm sure.\", \"J'en suis certain.\"),\n",
              " (\"I'm sure.\", 'Je suis certain.'),\n",
              " (\"I'm sure.\", \"J'en suis sûr.\"),\n",
              " (\"I'm sure.\", \"J'en suis sûre.\"),\n",
              " (\"I'm tall.\", 'Je suis grande.'),\n",
              " (\"I'm thin.\", 'Je suis mince.'),\n",
              " (\"I'm tidy.\", 'Je suis ordonné.'),\n",
              " (\"I'm tidy.\", 'Je suis ordonnée.'),\n",
              " (\"I'm ugly.\", 'Je suis laid.'),\n",
              " (\"I'm ugly.\", 'Je suis laide.'),\n",
              " (\"I'm weak.\", 'Je suis faible.'),\n",
              " (\"I'm well.\", 'Je vais bien.'),\n",
              " (\"I'm well.\", 'Je me porte bien.'),\n",
              " (\"I've won.\", \"J'ai gagné.\"),\n",
              " (\"I've won.\", \"Je l'ai emporté.\"),\n",
              " ('It helps.', 'Ça aide.'),\n",
              " ('It hurts.', 'Ça fait mal.'),\n",
              " ('It works.', 'Elle marche.'),\n",
              " ('It works.', 'Ça fonctionne.'),\n",
              " (\"It's Tom.\", \"C'est Tom.\"),\n",
              " (\"It's fun.\", \"C'est marrant.\"),\n",
              " (\"It's fun.\", \"C'est rigolo.\"),\n",
              " (\"It's his.\", \"C'est le sien.\"),\n",
              " (\"It's his.\", \"C'est la sienne.\"),\n",
              " (\"It's new.\", \"C'est nouveau.\"),\n",
              " (\"It's new.\", \"C'est neuf.\"),\n",
              " (\"It's odd.\", \"C'est bizarre.\"),\n",
              " (\"It's red.\", 'Il est rouge.'),\n",
              " (\"It's sad.\", 'C’est triste.'),\n",
              " ('Keep out!', \"Défense d'entrer.\"),\n",
              " ('Keep out.', \"N'entrez pas.\"),\n",
              " ('Kiss Tom.', 'Embrasse Tom.'),\n",
              " ('Leave it.', 'Laisse tomber !'),\n",
              " ('Leave it.', 'Laissez tomber !'),\n",
              " ('Leave me.', 'Laissez-moi !'),\n",
              " ('Leave us.', 'Laisse-nous !'),\n",
              " ('Leave us.', 'Laissez-nous !'),\n",
              " (\"Let's go!\", 'Allons-y !'),\n",
              " (\"Let's go.\", 'Allons-y !'),\n",
              " ('Look out!', 'Attention !'),\n",
              " ('Look out!', 'Regarde donc !'),\n",
              " ('Marry me.', 'Épouse-moi !'),\n",
              " ('Marry me.', 'Épousez-moi !'),\n",
              " ('May I go?', 'Puis-je partir ?'),\n",
              " ('May I go?', 'Puis-je y aller ?'),\n",
              " ('May I go?', \"Puis-je m'y rendre ?\"),\n",
              " ('Save Tom.', 'Sauve Tom.'),\n",
              " ('Save Tom.', 'Sauvez Tom.'),\n",
              " ('She came.', 'Elle est venue.'),\n",
              " ('She died.', 'Elle est morte.'),\n",
              " ('She runs.', 'Elle court.'),\n",
              " ('Sit down!', 'Assieds-toi !'),\n",
              " ('Sit down!', 'Asseyez-vous !'),\n",
              " ('Sit down.', 'Assieds-toi.'),\n",
              " ('Sit here.', 'Assieds-toi ici.'),\n",
              " ('Sit here.', 'Asseyez-vous ici.'),\n",
              " ('Speak up!', 'Parle plus fort\\u202f!'),\n",
              " ('Speak up!', 'Parlez plus fort\\u202f!'),\n",
              " ('Stand up.', 'Lève-toi.'),\n",
              " ('Stop Tom.', 'Arrête Tom.'),\n",
              " ('Stop Tom.', 'Stoppez Tom.'),\n",
              " ('Taste it.', 'Goûte-le.'),\n",
              " ('Taste it.', 'Goûte-la.'),\n",
              " ('Taste it.', 'Goûtez-le.'),\n",
              " ('Taste it.', 'Goûtez-la.'),\n",
              " ('Tell Tom.', 'Dis-le à Tom.'),\n",
              " ('Tell Tom.', 'Informez-en Tom.'),\n",
              " ('Terrific!', 'Génial\\u202f!'),\n",
              " ('Terrific!', 'Excellent\\u202f!'),\n",
              " ('Terrific!', 'Formidable !'),\n",
              " ('They won.', 'Ils gagnèrent.'),\n",
              " ('They won.', 'Elles gagnèrent.'),\n",
              " ('They won.', 'Ils ont gagné.'),\n",
              " ('They won.', 'Elles ont gagné.'),\n",
              " ('Tom came.', 'Tom est venu.'),\n",
              " ('Tom died.', 'Tom est mort.'),\n",
              " ('Tom knew.', 'Tom savait.'),\n",
              " ('Tom left.', 'Tom est parti.'),\n",
              " ('Tom left.', 'Tom partit.'),\n",
              " ('Tom lied.', 'Tom a menti.'),\n",
              " ('Tom lies.', 'Tom ment.'),\n",
              " ('Tom lost.', 'Tom a perdu.'),\n",
              " ('Tom paid.', 'Tom a payé.'),\n",
              " ('Too late.', 'Trop tard.'),\n",
              " ('Trust me.', 'Faites-moi confiance.'),\n",
              " ('Trust me.', 'Fais-moi confiance.'),\n",
              " ('Try hard.', 'Fais un effort.'),\n",
              " ('Try some.', 'Essaies-en !'),\n",
              " ('Try some.', 'Essayez-en !'),\n",
              " ('Try this.', 'Essaie ceci !'),\n",
              " ('Try this.', 'Essayez ceci !'),\n",
              " ('Use this.', 'Utilise ceci.'),\n",
              " ('Use this.', 'Utilisez ceci.'),\n",
              " ('Use this.', 'Emploie ceci !'),\n",
              " ('Use this.', 'Employez ceci !'),\n",
              " ('Warn Tom.', 'Avertis Tom.'),\n",
              " ('Warn Tom.', 'Préviens Tom.'),\n",
              " ('Watch me.', 'Regarde-moi !'),\n",
              " ('Watch me.', 'Regardez-moi !'),\n",
              " ('Watch us.', 'Regardez-nous !'),\n",
              " ('Watch us.', 'Regarde-nous !'),\n",
              " ('We agree.', \"Nous sommes d'accord.\"),\n",
              " (\"We'll go.\", 'Nous irons.'),\n",
              " ('What for?', 'Pour quoi faire\\u202f?'),\n",
              " ('What for?', 'À quoi bon ?'),\n",
              " ('What fun!', \"Qu'est-ce qu'on s'est marrés !\"),\n",
              " ('What fun!', \"Qu'est-ce qu'on s'est marrées !\"),\n",
              " ('Who came?', 'Qui est venu ?'),\n",
              " ('Who died?', 'Qui est mort ?'),\n",
              " ('Who fell?', 'Qui est tombé\\xa0?'),\n",
              " ('Who quit?', 'Qui démissionne ?'),\n",
              " (\"Who's he?\", 'Qui est-il\\u202f?'),\n",
              " ('Write me.', 'Écris-moi !'),\n",
              " ('Write me.', 'Écrivez-moi !'),\n",
              " ('You lost.', 'Tu as perdu.'),\n",
              " ('You lost.', 'Vous avez perdu.'),\n",
              " ('After you.', 'Après vous.'),\n",
              " ('Aim. Fire!', 'En joue ! Feu !'),\n",
              " ('Am I late?', 'Suis-je en retard ?'),\n",
              " ('Answer me.', 'Répondez-moi.'),\n",
              " ('Be seated.', 'Assieds-toi !'),\n",
              " ('Be seated.', 'Asseyez-vous !'),\n",
              " ('Birds fly.', 'Les oiseaux volent.'),\n",
              " ('Bless you.', 'À tes souhaits\\u202f!'),\n",
              " ('Call home!', 'Appelle à la maison !'),\n",
              " ('Calm down!', 'Calmez-vous !'),\n",
              " ('Calm down.', 'Calme-toi.'),\n",
              " ('Can we go?', 'Pouvons-nous partir ?'),\n",
              " ('Can we go?', 'Pouvons-nous nous en aller ?'),\n",
              " ('Can we go?', 'Pouvons-nous y aller ?'),\n",
              " ('Catch Tom.', 'Attrape Tom.'),\n",
              " ('Catch Tom.', 'Attrapez Tom.'),\n",
              " ('Catch him.', 'Rattrape-le.'),\n",
              " ('Come back.', 'Reviens !'),\n",
              " ('Come back.', 'Revenez !'),\n",
              " ('Come here.', 'Viens ici.'),\n",
              " ('Come here.', 'Venez là.'),\n",
              " ('Come over!', 'Viens\\u202f!'),\n",
              " ('Come over!', 'Venez\\u202f!'),\n",
              " ('Come over.', 'Venez ici !'),\n",
              " ('Come over.', 'Viens chez nous !'),\n",
              " ('Come over.', 'Venez chez nous !'),\n",
              " ('Come over.', 'Viens chez moi !'),\n",
              " ('Come over.', 'Venez chez moi !'),\n",
              " ('Come soon.', 'Viens bientôt !'),\n",
              " ('Come soon.', 'Venez bientôt !'),\n",
              " ('Cool down.', 'Calmez-vous !'),\n",
              " ('Did I win?', 'Ai-je gagné ?'),\n",
              " ('Did I win?', \"L'ai-je emporté ?\"),\n",
              " ('Did I win?', 'Est-ce moi qui ai gagné ?'),\n",
              " ('Do it now.', 'Faites-le maintenant.'),\n",
              " ('Dogs bark.', 'Des chiens aboient.'),\n",
              " ('Dogs bark.', 'Les chiens aboient.'),\n",
              " (\"Don't ask.\", 'Ne demande pas !'),\n",
              " (\"Don't cry.\", 'Ne pleure pas !'),\n",
              " (\"Don't die.\", 'Ne meurs pas !'),\n",
              " (\"Don't die.\", 'Ne mourez pas !'),\n",
              " (\"Don't lie.\", 'Ne mens pas.'),\n",
              " (\"Don't run.\", 'Ne courez pas.'),\n",
              " (\"Don't run.\", 'Ne cours pas.'),\n",
              " ('Excuse me.', 'Excuse-moi.'),\n",
              " ('Excuse me.', 'Excusez-moi.'),\n",
              " ('Fantastic!', 'Fantastique\\u202f!'),\n",
              " ('Feel this.', 'Sens ça !'),\n",
              " ('Feel this.', 'Sentez ça !'),\n",
              " ('Feel this.', 'Touche ça !'),\n",
              " ('Feel this.', 'Touchez ça !'),\n",
              " ('Follow me.', 'Suis-moi.'),\n",
              " ('Follow us.', 'Suis-nous !'),\n",
              " ('Follow us.', 'Suivez-nous !'),\n",
              " ('Forget it!', 'Oublie !'),\n",
              " ('Forget it!', 'Oublie-le !'),\n",
              " ('Forget it!', 'Oubliez !'),\n",
              " ('Forget it!', 'Oubliez-le !'),\n",
              " ('Forget it.', 'Laisse tomber.'),\n",
              " ('Forget it.', 'Oublie.'),\n",
              " ('Forget it.', 'Oublie-le !'),\n",
              " ('Get a job.', 'Trouve un emploi !'),\n",
              " ('Get a job.', 'Trouve un boulot !'),\n",
              " ('Get a job.', 'Trouvez un emploi !'),\n",
              " ('Get a job.', 'Trouvez un boulot !'),\n",
              " ('Get ready.', 'Prépare-toi.'),\n",
              " ('Get ready.', 'Préparez-vous.'),\n",
              " ('Go get it.', 'Va le chercher !'),\n",
              " ('Go get it.', 'Allez le chercher !'),\n",
              " ('Go inside.', 'Entrez\\u202f!'),\n",
              " ('Go to bed.', 'Va au lit !'),\n",
              " ('Go to bed.', 'Allez au lit !'),\n",
              " ('Good luck.', 'Bonne chance\\u202f!'),\n",
              " ('Good luck.', 'Bonne chance.'),\n",
              " ('Grab that.', 'Attrape ça !'),\n",
              " ('Grab that.', 'Attrapez ça !'),\n",
              " ('Grab that.', 'Saisis-toi de ça !'),\n",
              " ('Grab that.', 'Saisissez-vous de ça !'),\n",
              " ('Grab this.', 'Attrape ça !'),\n",
              " ('Grab this.', 'Attrapez ça !'),\n",
              " ('Hands off.', 'Pas touche\\u202f!'),\n",
              " ('He is ill.', 'Il est malade.'),\n",
              " ('He is old.', 'Il est vieux.'),\n",
              " (\"He's a DJ.\", 'Il est DJ.'),\n",
              " (\"He's good.\", 'Il est bon.'),\n",
              " (\"He's lazy.\", 'Il est paresseux.'),\n",
              " (\"He's mine.\", 'Il est à moi.'),\n",
              " (\"He's rich.\", 'Il est riche.'),\n",
              " (\"He's sexy.\", 'Il est sexy.'),\n",
              " ('Here I am.', 'Me voici.'),\n",
              " (\"Here's $5.\", 'Voilà cinq dollars.'),\n",
              " ('Hold fire.', 'Halte au feu !'),\n",
              " ('Hold fire.', 'Cessez le feu !'),\n",
              " ('Hold this.', 'Tiens ça !'),\n",
              " ('Hold this.', 'Tenez ça !'),\n",
              " ('Hold this.', 'Tenez ceci !'),\n",
              " ('Hold this.', 'Tiens ceci !'),\n",
              " ('How awful!', \"C'est affreux\\u202f!\"),\n",
              " ('How weird!', \"Comme c'est bizarre !\"),\n",
              " (\"How's Tom?\", 'Comment Tom va-t-il ?'),\n",
              " (\"How's Tom?\", 'Comment va Tom ?'),\n",
              " ('I am busy.', 'Je suis occupé.'),\n",
              " ('I am calm.', 'Je suis calme.'),\n",
              " ('I am cold.', \"J'ai froid.\"),\n",
              " ('I am fine.', 'Je vais bien.'),\n",
              " ('I am good.', 'Je suis bon.'),\n",
              " ('I am here.', 'Je suis ici.'),\n",
              " ('I am lazy.', 'Je suis paresseux.'),\n",
              " ('I am lazy.', 'Je suis fainéant.'),\n",
              " ('I am lazy.', 'Je suis paresseuse.'),\n",
              " ('I am lazy.', 'Je suis fainéante.'),\n",
              " ('I am okay.', 'Je vais bien.'),\n",
              " ('I am sick.', 'Je suis malade.'),\n",
              " ('I am sure.', 'Je suis sûr.'),\n",
              " ('I am sure.', 'Je suis certain.'),\n",
              " ('I am weak.', 'Je suis faible.'),\n",
              " ('I beg you.', 'Je vous en prie.'),\n",
              " ('I beg you.', 'Je vous en conjure.'),\n",
              " ('I beg you.', 'Je vous en supplie.'),\n",
              " ('I beg you.', 'Je te prie.'),\n",
              " ('I can run.', 'Je sais courir.'),\n",
              " ('I can ski.', 'Je sais skier.'),\n",
              " ('I cringed.', \"J'eus un mouvement de recul.\"),\n",
              " ('I cringed.', \"J'ai eu un mouvement de recul.\"),\n",
              " ('I cringed.', 'Je suis rentré en moi-même.'),\n",
              " ('I exhaled.', 'J’ai expiré.'),\n",
              " ('I gave up.', \"J'ai abandonné.\"),\n",
              " ('I give in.', 'Je donne ma langue au chat.'),\n",
              " ('I give up.', \"J'abandonne.\"),\n",
              " ('I got hot.', 'Je me suis mis à avoir chaud.'),\n",
              " ('I got hot.', 'Je me suis mise à avoir chaud.'),\n",
              " ('I had fun.', 'Je me suis amusé.'),\n",
              " ('I had fun.', 'Je me suis amusée.'),\n",
              " ('I had fun.', 'Je me suis marré.'),\n",
              " ('I had fun.', 'Je me suis marrée.'),\n",
              " ('I hate it.', 'Je déteste ça.'),\n",
              " ('I have it.', \"Je l'ai.\"),\n",
              " ('I hit Tom.', \"J'ai frappé Tom.\"),\n",
              " ('I hope so.', \"J'espère bien.\"),\n",
              " ('I hurried.', 'Je me suis dépêché.'),\n",
              " ('I hurried.', 'Je me suis dépêchée.'),\n",
              " ('I inhaled.', 'J’ai inspiré.'),\n",
              " ('I knew it.', 'Je le savais.'),\n",
              " ('I like it.', \"J'aime ça.\"),\n",
              " ('I lost it.', 'Je l’ai perdu.'),\n",
              " ('I love it!', \"J'adore ça !\"),\n",
              " ('I love it.', \"J'adore ça !\"),\n",
              " ('I mean it!', 'Je suis sérieux\\u202f!'),\n",
              " ('I mean it.', 'Je suis sérieux.'),\n",
              " ('I must go.', 'Je dois y aller.'),\n",
              " ('I must go.', \"Il faut que j'y aille.\"),\n",
              " ('I must go.', 'Il me faut y aller.'),\n",
              " ('I must go.', 'Il me faut partir.'),\n",
              " ('I must go.', \"Il me faut m'en aller.\"),\n",
              " ('I must go.', 'Je dois partir.'),\n",
              " ('I must go.', \"Je dois m'en aller.\"),\n",
              " ('I must go.', \"Il faut que je m'en aille.\"),\n",
              " ('I need it.', \"J'en ai besoin.\"),\n",
              " ('I need it.', 'Il me le faut.'),\n",
              " ('I noticed.', \"J'ai remarqué.\"),\n",
              " ('I prepaid.', \"J'ai payé d'avance.\"),\n",
              " ('I promise.', 'Je le promets.'),\n",
              " ('I relaxed.', 'Je me suis détendu.'),\n",
              " ('I relaxed.', 'Je me suis détendue.'),\n",
              " ('I retired.', \"J'ai pris ma retraite.\"),\n",
              " ('I said no.', \"J'ai dit non.\"),\n",
              " ('I said so.', \"Je l'ai dit.\"),\n",
              " ('I saw him.', \"Je l'ai vu.\"),\n",
              " ('I saw him.', 'Je l’ai vu.'),\n",
              " ('I saw him.', 'Je le vis.'),\n",
              " ('I saw one.', \"J'en ai vu une.\"),\n",
              " ('I saw one.', \"J'en ai vu un.\"),\n",
              " ('I saw you.', 'Je vous vis.'),\n",
              " ('I saw you.', 'Je te vis.'),\n",
              " ('I saw you.', \"Je t'ai vue.\"),\n",
              " ('I saw you.', \"Je t'ai vu.\"),\n",
              " ('I saw you.', 'Je vous ai vues.'),\n",
              " ('I saw you.', 'Je vous ai vus.'),\n",
              " ('I saw you.', 'Je vous ai vue.'),\n",
              " ('I saw you.', 'Je vous ai vu.'),\n",
              " ('I see Tom.', 'Je vois Tom.'),\n",
              " ('I shouted.', \"J'ai crié.\"),\n",
              " ('I tripped.', \"J'ai trébuché.\"),\n",
              " ('I tripped.', \"J'ai plané.\"),\n",
              " ('I want it.', 'Je le veux.'),\n",
              " ('I was new.', \"J'étais nouveau.\"),\n",
              " ('I was new.', \"J'étais nouvelle.\"),\n",
              " ('I will go.', \"J'irai.\"),\n",
              " ('I woke up.', 'Je me suis réveillé.'),\n",
              " ('I woke up.', 'Je me suis éveillé.'),\n",
              " (\"I'd agree.\", \"Je serais d'accord.\"),\n",
              " (\"I'd leave.\", 'Je partirais.'),\n",
              " (\"I'll call.\", \"J'appellerai.\"),\n",
              " (\"I'll cook.\", 'Je cuisinerai.'),\n",
              " (\"I'll help.\", \"J'aiderai.\"),\n",
              " (\"I'll live.\", 'Je vivrai.'),\n",
              " (\"I'll obey.\", \"J'obéirai.\"),\n",
              " (\"I'll pack.\", 'Je ferai mon sac.'),\n",
              " (\"I'll pack.\", 'Je ferai ma valise.'),\n",
              " (\"I'll pack.\", 'Je plierai mes gaules.'),\n",
              " (\"I'll pass.\", 'Je passerai.'),\n",
              " (\"I'll quit.\", \"J'abandonnerai.\"),\n",
              " (\"I'll sing.\", 'Je chanterai.'),\n",
              " (\"I'll stop.\", \"J'arrêterai.\"),\n",
              " (\"I'll swim.\", 'Je nagerai.'),\n",
              " (\"I'll talk.\", 'Je parlerai.'),\n",
              " (\"I'll talk.\", 'Je vais parler.'),\n",
              " (\"I'll wait.\", \"J'attendrai.\"),\n",
              " (\"I'll walk.\", 'Je marcherai.'),\n",
              " (\"I'll work.\", 'Je vais travailler.'),\n",
              " (\"I'll work.\", 'Je travaillerai.'),\n",
              " (\"I'm a cop.\", 'Je suis flic.'),\n",
              " (\"I'm a man.\", 'Je suis un homme.'),\n",
              " (\"I'm alive.\", 'Je suis en vie.'),\n",
              " (\"I'm alive.\", 'Je suis vivant.'),\n",
              " (\"I'm alive.\", 'Je suis vivante.'),\n",
              " (\"I'm alone.\", 'Je suis seule.'),\n",
              " (\"I'm alone.\", 'Je suis seul.'),\n",
              " (\"I'm angry.\", 'Je suis énervé.'),\n",
              " (\"I'm angry.\", 'Je suis en colère.'),\n",
              " (\"I'm armed.\", 'Je suis armé.'),\n",
              " (\"I'm armed.\", 'Je suis armée.'),\n",
              " (\"I'm awake.\", 'Je suis réveillé.'),\n",
              " (\"I'm blind.\", 'Je suis aveugle.'),\n",
              " (\"I'm broke.\", 'Je suis fauché.'),\n",
              " (\"I'm clean.\", \"J'ai décroché.\"),\n",
              " (\"I'm clean.\", 'Je suis propre.'),\n",
              " (\"I'm crazy.\", 'Je suis fou.'),\n",
              " (\"I'm crazy.\", 'Je suis folle.'),\n",
              " (\"I'm cured.\", 'Je suis guéri.'),\n",
              " (\"I'm cured.\", 'Je suis guérie.'),\n",
              " (\"I'm dizzy.\", \"J'ai la tête qui tourne.\"),\n",
              " (\"I'm drunk.\", 'Je suis saoul.'),\n",
              " (\"I'm drunk.\", 'Je suis soûl.'),\n",
              " (\"I'm drunk.\", 'Je suis ivre.'),\n",
              " (\"I'm dying.\", 'Je me meurs.'),\n",
              " (\"I'm early.\", 'Je suis en avance.'),\n",
              " (\"I'm first.\", 'Je suis en premier.'),\n",
              " (\"I'm fussy.\", 'Je suis difficile.'),\n",
              " (\"I'm fussy.\", 'Je suis tatillon.'),\n",
              " (\"I'm fussy.\", 'Je suis tatillonne.'),\n",
              " (\"I'm going.\", 'Je pars maintenant.'),\n",
              " (\"I'm going.\", 'Je me tire.'),\n",
              " (\"I'm going.\", 'J’y vais.'),\n",
              " (\"I'm going.\", 'Je pars.'),\n",
              " (\"I'm loyal.\", 'Je suis loyal.'),\n",
              " (\"I'm loyal.\", 'Je suis loyale.'),\n",
              " (\"I'm lucky.\", 'Je suis veinard.'),\n",
              " (\"I'm lucky.\", 'Je suis veinarde.'),\n",
              " (\"I'm lucky.\", \"J'ai du pot.\"),\n",
              " (\"I'm lucky.\", 'Je suis chanceux.'),\n",
              " (\"I'm lucky.\", 'Je suis chanceuse.'),\n",
              " (\"I'm lying.\", 'Je suis en train de mentir.'),\n",
              " (\"I'm naked.\", 'Je suis nu.'),\n",
              " (\"I'm naked.\", 'Je suis nue.'),\n",
              " (\"I'm naked.\", 'Je me trouve nu.'),\n",
              " (\"I'm naked.\", 'Je me trouve nue.'),\n",
              " (\"I'm naked.\", 'Je suis à poil.'),\n",
              " (\"I'm quiet.\", 'Je suis tranquille.'),\n",
              " (\"I'm ready!\", 'Je suis prête !'),\n",
              " (\"I'm ready!\", 'Je suis prêt !'),\n",
              " (\"I'm ready.\", 'Je suis prêt.'),\n",
              " (\"I'm right.\", \"J'ai raison.\"),\n",
              " (\"I'm sober.\", 'Je suis sobre.'),\n",
              " (\"I'm sorry.\", 'Excuse-moi.'),\n",
              " (\"I'm sorry.\", 'Désolé.'),\n",
              " (\"I'm sorry.\", 'Excusez-moi.'),\n",
              " (\"I'm sorry.\", 'Désolé !'),\n",
              " (\"I'm sorry.\", 'Je suis désolé.'),\n",
              " (\"I'm sorry.\", 'Je suis désolée.'),\n",
              " (\"I'm stuck.\", 'Je suis coincée.'),\n",
              " (\"I'm timid.\", 'Je suis timide.'),\n",
              " (\"I'm tired.\", 'Je suis fatigué !'),\n",
              " (\"I'm tough.\", 'Je suis dur.'),\n",
              " (\"I'm tough.\", 'Je suis dure.'),\n",
              " (\"I'm tough.\", 'Je suis dur à cuire.'),\n",
              " (\"I'm tough.\", 'Je suis dure à cuire.'),\n",
              " (\"I'm yours.\", 'Je suis à toi.'),\n",
              " (\"I'm yours.\", 'Je suis à vous.'),\n",
              " (\"I've lost.\", \"J'ai perdu.\"),\n",
              " ('Is Tom OK?', 'Est-ce que Tom va bien ?'),\n",
              " ('Is Tom OK?', 'Tom va-t-il bien ?'),\n",
              " ('Is it bad?', \"C'est grave\\u202f?\"),\n",
              " ('Is it far?', 'Est-ce éloigné ?'),\n",
              " ('Is it far?', 'Est-ce loin ?'),\n",
              " ('Is it hot?', 'Est-ce chaud\\xa0?'),\n",
              " ('Is it you?', 'Est-ce toi ?'),\n",
              " ('Is it you?', 'Est-ce vous ?'),\n",
              " ('Is it you?', \"Est-ce que c'est vous ?\"),\n",
              " ('It failed.', 'Ça a échoué.'),\n",
              " ('It is new.', \"C'est nouveau.\"),\n",
              " ('It is new.', \"C'est neuf.\"),\n",
              " ('It snowed.', 'Il a neigé.'),\n",
              " ('It stinks.', 'Ça sent mauvais.'),\n",
              " ('It stinks.', 'Ça pue.'),\n",
              " ('It was OK.', \"C'était bon.\"),\n",
              " ('It was OK.', \"C'était correct.\"),\n",
              " ('It was OK.', \"C'était OK.\"),\n",
              " ('It worked.', 'Ça a fonctionné.'),\n",
              " ('It worked.', 'Ça a marché.'),\n",
              " (\"It's 3:30.\", 'Il est trois heures et demie.'),\n",
              " (\"It's 8:30.\", 'Il est huit heures trente.'),\n",
              " (\"It's 8:30.\", 'Il est 8\\xa0h\\xa030.'),\n",
              " (\"It's a TV.\", \"C'est une télé.\"),\n",
              " (\"It's cold.\", 'Il fait froid.'),\n",
              " (\"It's cold.\", \"C'est froid.\"),\n",
              " (\"It's dark.\", \"C'est sombre.\"),\n",
              " (\"It's dead.\", 'Elle est morte.'),\n",
              " (\"It's dead.\", \"C'est mort.\"),\n",
              " (\"It's dead.\", 'Il est mort.'),\n",
              " (\"It's done.\", \"C'est fait.\"),\n",
              " (\"It's easy.\", \"C'est simple.\"),\n",
              " (\"It's food.\", \"C'est de la nourriture.\"),\n",
              " (\"It's free.\", \"C'est gratuit.\"),\n",
              " (\"It's here.\", 'Elle est ici.'),\n",
              " (\"It's here.\", \"C'est ici.\"),\n",
              " (\"It's hers.\", \"C'est le sien.\"),\n",
              " (\"It's hers.\", \"C'est la sienne.\"),\n",
              " (\"It's late.\", 'Il est tard.'),\n",
              " (\"It's lost.\", \"C'est perdu.\"),\n",
              " (\"It's mine.\", \"C'est le mien.\"),\n",
              " (\"It's mine.\", \"C'est la mienne.\"),\n",
              " (\"It's mine.\", \"C'est à moi.\"),\n",
              " (\"It's mine.\", \"Il s'agit du mien.\"),\n",
              " (\"It's open.\", \"C'est ouvert.\"),\n",
              " (\"It's ours.\", \"C'est le nôtre.\"),\n",
              " (\"It's ours.\", \"C'est la nôtre.\"),\n",
              " (\"It's ours.\", \"C'est à nous.\"),\n",
              " (\"It's sand.\", \"C'est du sable.\"),\n",
              " (\"It's time.\", 'Il est temps !'),\n",
              " (\"It's time.\", \"C'est l'heure.\"),\n",
              " (\"It's true!\", \"C'est vrai\\u202f!\"),\n",
              " (\"It's work.\", \"C'est du boulot.\"),\n",
              " ('Keep calm.', 'Restez calme.'),\n",
              " ('Keep that.', 'Garde ça.'),\n",
              " ('Keep that.', 'Gardez cela.'),\n",
              " ('Keep this.', 'Garde ça.'),\n",
              " ('Keep this.', 'Gardez ceci.'),\n",
              " ('Let it be.', 'Ainsi soit-il.'),\n",
              " ('Let it be.', 'Laisse faire.'),\n",
              " ('Let me go!', 'Laisse-moi partir\\u202f!'),\n",
              " ('Let me go!', 'Laissez-moi partir\\u202f!'),\n",
              " ('Let me go!', 'Lâche-moi\\u202f!'),\n",
              " ('Let me go!', 'Lâchez-moi\\u202f!'),\n",
              " ('Let me go!', \"Laisse-moi m'en aller !\"),\n",
              " ('Let me go!', \"Laissez-moi m'en aller !\"),\n",
              " ('Let me go!', 'Laissez-moi y aller !'),\n",
              " ('Let me go!', 'Laisse-moi y aller !'),\n",
              " ('Let me go.', 'Laisse-moi partir\\u202f!'),\n",
              " ('Let me go.', 'Laissez-moi partir\\u202f!'),\n",
              " ('Let me go.', \"Laisse-moi m'en aller !\"),\n",
              " ('Let me go.', \"Laissez-moi m'en aller !\"),\n",
              " ('Let me in.', 'Laissez-moi rentrer.'),\n",
              " ('Let me in.', 'Laissez-moi entrer.'),\n",
              " (\"Let's ask.\", 'Demandons.'),\n",
              " (\"Let's eat.\", 'Mangeons.'),\n",
              " (\"Let's see.\", 'Voyons voir !'),\n",
              " ('Lie still.', 'Reste allongé, immobile !'),\n",
              " ('Lie still.', 'Reste allongée, immobile !'),\n",
              " ('Lie still.', 'Restez allongé, immobile !'),\n",
              " ('Lie still.', 'Restez allongée, immobile !'),\n",
              " ('Lie still.', 'Restez allongés, immobiles !'),\n",
              " ('Lie still.', 'Restez allongées, immobiles !'),\n",
              " ('Look back!', 'Regarde derrière toi\\u202f!'),\n",
              " ('Look back!', 'Regarde derrière\\u202f!'),\n",
              " ('Look here.', 'Regarde ici.'),\n",
              " ('Look here.', 'Regardez ici.'),\n",
              " ('Loosen up.', 'Échauffe-toi !'),\n",
              " ('Loosen up.', 'Échauffez-vous !'),\n",
              " ('Loosen up.', 'Détends-toi !'),\n",
              " ('Loosen up.', 'Laisse-toi aller !'),\n",
              " ('Loosen up.', 'Laissez-vous aller !'),\n",
              " ('Move over.', 'Bouge de là.'),\n",
              " ('Move over.', 'Poussez-vous.'),\n",
              " ('Move over.', 'Pousse-toi.'),\n",
              " ('Nice shot!', 'Joli coup !'),\n",
              " ('Of course!', 'Pour sûr.'),\n",
              " ('Of course!', 'Mais ouais !'),\n",
              " ('Of course!', 'Pardi !'),\n",
              " ('Of course.', 'Bien sûr.'),\n",
              " ('Of course.', 'Pour sûr.'),\n",
              " ('Oh please!', 'Je vous en prie !'),\n",
              " ('Oh please!', \"Je t'en prie !\"),\n",
              " ('Pardon me?', 'Pardon\\u202f?'),\n",
              " ('Pardon me?', 'Je vous demande pardon\\u202f?'),\n",
              " ('Pardon me?', 'Plaît-il\\u202f?'),\n",
              " ('Read this.', 'Lis ceci.'),\n",
              " ('Say hello.', 'Dis bonjour.'),\n",
              " ('See above.', 'Voyez ci-dessus.'),\n",
              " ('See below.', 'Voyez ci-dessous.'),\n",
              " ('See below.', 'Voir ci-dessous.'),\n",
              " ('Seize him!', 'Capturez-le\\xa0!'),\n",
              " ('Seize him!', 'Attrapez-le\\xa0!'),\n",
              " ('Seriously?', 'Vraiment\\u202f?'),\n",
              " ('Seriously?', 'Est-ce sérieux\\u202f?'),\n",
              " ('Seriously?', 'Sérieusement ?'),\n",
              " ('She cried.', 'Elle pleurait.'),\n",
              " ('She cried.', 'Elle pleura.'),\n",
              " ('She tried.', 'Elle a essayé.'),\n",
              " ('She walks.', 'Elle marche.'),\n",
              " (\"She's hot.\", 'Elle est chaude.'),\n",
              " (\"She's hot.\", 'Elle est très attirante.'),\n",
              " ('Sign here.', 'Signe ici.'),\n",
              " ('Sign here.', 'Signez ici.'),\n",
              " ('Sign this.', 'Signe ça.'),\n",
              " ('Sign this.', 'Signez ceci.'),\n",
              " ('Slow down.', 'Ralentis !'),\n",
              " ('Slow down.', 'Ralentissez !'),\n",
              " ('Stay back.', 'Reste en arrière !'),\n",
              " ('Stay back.', 'Restez en arrière !'),\n",
              " ('Stay calm.', 'Restez calme.'),\n",
              " ('Stay calm.', 'Reste calme.'),\n",
              " ('Stay calm.', 'Garde ton calme.'),\n",
              " ('Stay calm.', 'Garde ton sang-froid.'),\n",
              " ('Stay calm.', 'Reste tranquille.'),\n",
              " ('Stay down!', 'Reste baissé.'),\n",
              " ('Stay down!', 'Restez baissé.'),\n",
              " ('Stay down.', 'Reste baissé.'),\n",
              " ('Stay down.', 'Restez baissé.'),\n",
              " ('Stay here.', 'Restez là !'),\n",
              " ('Stay here.', 'Reste ici !'),\n",
              " ('Stay here.', 'Restez ici.'),\n",
              " ('Stay thin.', 'Reste mince !'),\n",
              " ('Step back.', 'Recule\\u2009!'),\n",
              " ('Step back.', 'Reculez\\u2009!'),\n",
              " ('Stop that!', 'Arrêtez !'),\n",
              " ('Stop that.', 'Arrêtez ça !'),\n",
              " ('Stop that.', 'Arrête ça !'),\n",
              " ('Stop them.', 'Arrêtez-les.'),\n",
              " ('Take care!', 'Prends soin de toi !'),\n",
              " ('Take care!', 'Soyez prudente !'),\n",
              " ('Take care.', 'Prends soin de toi.'),\n",
              " ('Take care.', 'Prenez soin de vous.'),\n",
              " ('Take mine.', 'Prends le mien.'),\n",
              " ('Take mine.', 'Prends la mienne.'),\n",
              " ('Take mine.', 'Prenez le mien.'),\n",
              " ('Take mine.', 'Prenez la mienne.'),\n",
              " ('Take mine.', 'Prends les miens.'),\n",
              " ('Take mine.', 'Prends les miennes.'),\n",
              " ('Take mine.', 'Prenez les miens.'),\n",
              " ('Take mine.', 'Prenez les miennes.'),\n",
              " ('Take this.', 'Prends ça.'),\n",
              " ('Take this.', 'Prenez ça.'),\n",
              " ('Thank you.', 'Merci !'),\n",
              " ('Thank you.', 'Merci.'),\n",
              " (\"That's OK.\", \"Il n'y a pas de problème.\"),\n",
              " (\"That's OK.\", 'Pas de problème.'),\n",
              " (\"That's OK.\", \"Ce n'est pas grave.\"),\n",
              " (\"That's OK.\", 'Ça va.'),\n",
              " (\"That's it.\", \"C'est ça.\"),\n",
              " ('Then what?', 'Et alors ?'),\n",
              " ('They fell.', 'Ils sont tombés.'),\n",
              " ('They fell.', 'Elles sont tombées.'),\n",
              " ('They left.', 'Ils sont partis.'),\n",
              " ('They left.', 'Elles sont parties.'),\n",
              " ('They lied.', 'Ils ont menti.'),\n",
              " ('They lied.', 'Elles ont menti.'),\n",
              " ('They lost.', 'Ils ont perdu.'),\n",
              " ('They lost.', 'Elles ont perdu.'),\n",
              " ('They swam.', 'Ils nageaient.'),\n",
              " ('They swam.', 'Elles nageaient.'),\n",
              " ('They swam.', 'Ils nagèrent.'),\n",
              " ('They swam.', 'Elles nagèrent.'),\n",
              " (\"Time's up.\", 'Le temps est écoulé.'),\n",
              " ('Tom cooks.', 'Tom cuisine.'),\n",
              " ('Tom cried.', 'Tom pleura.'),\n",
              " ('Tom is OK.', 'Tom va bien.'),\n",
              " ('Tom knits.', 'Tom tricote.'),\n",
              " ('Tom knows.', 'Tom sait.'),\n",
              " ('Tom rocks.', 'Tom assure.'),\n",
              " ('Tom spoke.', 'Tom a parlé.'),\n",
              " ('Tom waved.', 'Tom a fait signe de la main.'),\n",
              " ('Tom works.', 'Tom est en train de travailler.'),\n",
              " (\"Tom's fat.\", 'Tom est gros.'),\n",
              " (\"Tom's mad.\", 'Tom est en colère.'),\n",
              " (\"Tom's mad.\", 'Tom est fou.'),\n",
              " (\"Tom's sad.\", 'Tom est triste.'),\n",
              " ('Trust Tom.', 'Fais confiance à Tom.'),\n",
              " ('Trust Tom.', 'Faites confiance à Tom.'),\n",
              " ('Try again.', 'Essaie encore.'),\n",
              " ('Try again.', 'Essayez de nouveau.'),\n",
              " ('Try again.', 'Essaie de nouveau.'),\n",
              " ('Try it on.', 'Essaie-le\\u2009!'),\n",
              " ('Turn left.', 'Tourne à gauche.'),\n",
              " ('Wait here.', 'Attends ici.'),\n",
              " ('Wait here.', 'Attends là.'),\n",
              " ('Wait here.', 'Attendez ici.'),\n",
              " ('Wait here.', 'Attendez là.'),\n",
              " ('Watch out!', 'Attention !'),\n",
              " ('Watch out!', 'Faites attention\\u202f!'),\n",
              " ('Watch out!', 'Fais attention\\u202f!'),\n",
              " ('We agreed.', \"Nous sommes tombés d'accord.\"),\n",
              " ('We did it!', 'Nous avons réussi\\u202f!'),\n",
              " ('We did it.', 'Nous avons réussi\\u202f!'),\n",
              " ('We did it.', \"Nous l'avons fait.\"),\n",
              " ('We forgot.', 'Nous avons oublié.'),\n",
              " ('We saw it.', \"Nous l'avons vu.\"),\n",
              " ('We saw it.', \"Nous l'avons vue.\"),\n",
              " ('We smiled.', 'Nous avons souri.'),\n",
              " ('We talked.', 'Nous discutâmes.'),\n",
              " ('We talked.', 'Nous avons discuté.'),\n",
              " ('We talked.', 'Nous nous sommes entretenus.'),\n",
              " ('We talked.', 'Nous nous sommes entretenues.'),\n",
              " ('We talked.', 'Nous nous entretînmes.'),\n",
              " ('We waited.', 'Nous attendîmes.'),\n",
              " ('We waited.', 'Nous avons attendu.'),\n",
              " ('We walked.', 'Nous sommes allés à pied.'),\n",
              " ('We walked.', 'Nous sommes allées à pied.'),\n",
              " (\"We'll try.\", 'Nous essayerons.'),\n",
              " (\"We'll try.\", 'Nous tenterons.'),\n",
              " (\"We'll win.\", \"Nous l'emporterons.\"),\n",
              " (\"We'll win.\", 'Nous gagnerons.'),\n",
              " (\"We're hot.\", 'Nous avons chaud.'),\n",
              " (\"We're sad.\", 'Nous sommes tristes.'),\n",
              " (\"We're shy.\", 'Nous sommes timides.'),\n",
              " ('Well done!', 'Bien vu\\u202f!'),\n",
              " ('Well done!', 'Bien cuit\\u202f!'),\n",
              " ('Well done!', 'À la bonne heure\\u202f!'),\n",
              " ('Well done!', 'Bien joué\\u202f!'),\n",
              " ('Well done!', 'Pas mal !'),\n",
              " (\"What's up?\", 'Ça va ?'),\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV2_I2WFwwSD",
        "colab_type": "text"
      },
      "source": [
        "Damit unser Modell weiß wo Anfang und Ende der französischen Sätze sind, müssen wir noch ein spezielles Start- (🏳️) und Endsymbol (🏴) einfügen:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDF8ynLcwwSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pairs_cleaned_with_marker = [(e, \"🏳️\" + f + \"🏴\") for e, f in pairs_cleaned]\n",
        "# pairs_cleaned_with_marker"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdy3RV-EwwSI",
        "colab_type": "text"
      },
      "source": [
        "Speichert euch nun alle Character, die in den englischen Sätzen und in den französischen Sätzen in jeweils einem Set ab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asbeTdqbwwSK",
        "colab_type": "code",
        "outputId": "c5b980ed-abb2-4b24-b1c9-92e117f33f6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "english_characters = set(char for word in pairs_cleaned_with_marker for char in word[0])\n",
        "french_characters = set(char for word in pairs_cleaned_with_marker for char in word[1])\n",
        "# TODO\n",
        "french_characters"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ',\n",
              " '!',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '0',\n",
              " '1',\n",
              " '3',\n",
              " '5',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'Y',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '\\xa0',\n",
              " '«',\n",
              " '»',\n",
              " 'À',\n",
              " 'Ç',\n",
              " 'É',\n",
              " 'Ê',\n",
              " 'à',\n",
              " 'â',\n",
              " 'ç',\n",
              " 'è',\n",
              " 'é',\n",
              " 'ê',\n",
              " 'î',\n",
              " 'ï',\n",
              " 'ô',\n",
              " 'ù',\n",
              " 'û',\n",
              " 'œ',\n",
              " '\\u2009',\n",
              " '’',\n",
              " '\\u202f',\n",
              " '️',\n",
              " '🏳',\n",
              " '🏴'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk8YMqAowwSO",
        "colab_type": "text"
      },
      "source": [
        "Um unser Modell später mit passenden Eingabedaten füttern zu können, müssen wir nun noch die jeweiligen Vektorlängen für den encoder und den decoder bestimmen. Speichert die Längen in den Variablen  `encoder_vector_len` und `decoder_vector_len` ab. Hinweis: uns Modell bekommt Vektoren, die die Characters pro Wort abbilden als Eingabe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACt7zNvbwwSP",
        "colab_type": "code",
        "outputId": "5aabe263-d663-406b-ba0b-2668b842f414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "encoder_vector_len = len(english_characters) #TODO\n",
        "decoder_vector_len = len(french_characters) #TODO\n",
        "print(encoder_vector_len)\n",
        "print(decoder_vector_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "67\n",
            "89\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI-42ZS8wwST",
        "colab_type": "text"
      },
      "source": [
        "Um die Eingabevektoren bestimmen zu können, müssen wir uns noch Dictionaries bauen, die jeweils die Character auf die Komponenten des Vektors abbilden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TREmlluwwSU",
        "colab_type": "code",
        "outputId": "d7cf230a-52af-465f-ea61-0992fb8b0280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "english_token_index = {char: index for index, char in enumerate(english_characters)} #TODO \n",
        "french_token_index = {char: index for index, char in enumerate(french_characters)} #TODO\n",
        "english_token_index"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " '!': 31,\n",
              " '$': 35,\n",
              " '%': 54,\n",
              " '&': 13,\n",
              " \"'\": 42,\n",
              " ',': 52,\n",
              " '-': 29,\n",
              " '.': 55,\n",
              " '0': 37,\n",
              " '1': 50,\n",
              " '3': 15,\n",
              " '5': 59,\n",
              " '7': 30,\n",
              " '8': 64,\n",
              " '9': 25,\n",
              " ':': 28,\n",
              " '?': 5,\n",
              " 'A': 62,\n",
              " 'B': 26,\n",
              " 'C': 23,\n",
              " 'D': 14,\n",
              " 'E': 10,\n",
              " 'F': 36,\n",
              " 'G': 56,\n",
              " 'H': 44,\n",
              " 'I': 45,\n",
              " 'J': 32,\n",
              " 'K': 58,\n",
              " 'L': 66,\n",
              " 'M': 16,\n",
              " 'N': 2,\n",
              " 'O': 48,\n",
              " 'P': 46,\n",
              " 'R': 33,\n",
              " 'S': 61,\n",
              " 'T': 51,\n",
              " 'U': 43,\n",
              " 'V': 38,\n",
              " 'W': 49,\n",
              " 'Y': 63,\n",
              " 'a': 41,\n",
              " 'b': 3,\n",
              " 'c': 18,\n",
              " 'd': 22,\n",
              " 'e': 9,\n",
              " 'f': 11,\n",
              " 'g': 21,\n",
              " 'h': 39,\n",
              " 'i': 27,\n",
              " 'j': 47,\n",
              " 'k': 24,\n",
              " 'l': 53,\n",
              " 'm': 1,\n",
              " 'n': 60,\n",
              " 'o': 34,\n",
              " 'p': 19,\n",
              " 'q': 40,\n",
              " 'r': 6,\n",
              " 's': 57,\n",
              " 't': 7,\n",
              " 'u': 65,\n",
              " 'v': 12,\n",
              " 'w': 20,\n",
              " 'x': 4,\n",
              " 'y': 8,\n",
              " 'z': 17}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJKmlPIRwwSY",
        "colab_type": "text"
      },
      "source": [
        "Wir haben nun alle Dimensionen bestimmt, um die Trainingsdaten zu definieren. Dafür bauen wir uns drei Matrizen (eine als Eingabe für den Encoder, eine als Eingabe für den Decoder und eine als Ausgabe des Decoders) zusammen. Die Dimensionen dafür sind jeweils: Anzahl Sätze, Anzahl Wörter des längsten Satzes, Anzahl Characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qokLOTXwwSZ",
        "colab_type": "code",
        "outputId": "0a4ca25a-4878-4949-f574-5a5c8268b339",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "max_encoder_sentence_len = max((len(e) for e, _ in pairs_cleaned_with_marker))\n",
        "max_decoder_sentence_len = max((len(f) for _, f in pairs_cleaned_with_marker))\n",
        "\n",
        "print(max_encoder_sentence_len)\n",
        "print(max_decoder_sentence_len)\n",
        "\n",
        "print(len(pairs_cleaned_with_marker))\n",
        "print(encoder_vector_len)\n",
        "print(decoder_vector_len)\n",
        "\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(pairs_cleaned_with_marker), max_encoder_sentence_len, encoder_vector_len),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(pairs_cleaned_with_marker), max_decoder_sentence_len, decoder_vector_len),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(pairs_cleaned_with_marker), max_decoder_sentence_len, decoder_vector_len),\n",
        "    dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14\n",
            "60\n",
            "5000\n",
            "67\n",
            "89\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EI6xo8MwwSc",
        "colab_type": "text"
      },
      "source": [
        "Befüllt nun die Matrizen. Die `encoder_input_data` und die `decoder_input_data`-Matrix soll für jeden Satz aus den Trainingsdaten, einen Eintrag mit einem Token-Vektor pro Wort enthalten.\n",
        "Die `decoder_target_data`-Matrix soll den gleichen Inhalt wie die `decoder_input_data`-Matrix haben, allerdings um eine Position verschoben. (Schaut euch nochmal die Folien an, wir brauchen Platz für das Startsymbol) \n",
        "\n",
        "Die `encoder_input_data`-Matrix wird mit den englischen Daten befüllt, die beiden anderen mit den französischen Daten.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sqvy2uywwSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, (e, f) in enumerate(pairs_cleaned_with_marker):\n",
        "    for t, char in enumerate(e):\n",
        "        encoder_input_data[i, t, english_token_index[char]] = 1.\n",
        "    for t, char in enumerate(f):\n",
        "        decoder_input_data[i, t, french_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            decoder_target_data[i, t-1, french_token_index[char]] = 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TNJnYRqwwSg",
        "colab_type": "text"
      },
      "source": [
        "## Sequence-to-sequence Modelle\n",
        "\n",
        "Im Gegensatz zu den bisherigen Notebooks, wollen wir hier mit dem Modell beginnen. Einerseits, weil die Daten eher dröge sind (englisch-fränzosische Satzpaare), andererseits, weil das Modell selbst komplizierter ist und wir hier die Functional-API von Keras benutzen müssen.\n",
        "\n",
        "Im Gegensatz zu der Sequence-API, definiert man hier ein Modell in dem, den jeweiligen Layer mit dem Vorgänger Layer aufruft:\n",
        "```\n",
        "\n",
        "a = Input(...)\n",
        "b = Dense(...)\n",
        "\n",
        "t = b(a)\n",
        "\n",
        "\n",
        "```\n",
        "Als Rückgabe bekommt man einen Tensor.\n",
        "\n",
        "\n",
        "Ganz generell gesprochen, möchten wir hier ein Seq2Seq-Modell aufbauen, das auf LSTMs basiert. Wie auf den Folien beschrieben wurde, teilt sich so ein Modell in einen Encoder und Decoder auf. \n",
        "Wir beginnen die Implementierung mit dem Encoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1u48w5DwwSh",
        "colab_type": "text"
      },
      "source": [
        "### Encoder\n",
        "\n",
        "Auch das komplexeste Modell fängt mit einer Eingabe ein.\n",
        "\n",
        "Definiert einen Input-Layer, der als Eingabedimension, Sätze beliebiger Länge als Vektoren nimmt. Eine Komponente im Vektor repräsentiert einen Character. Unbekannte Teile der Eingabedimensionen kann man mit `None` definieren."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGpAhhKej32B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.load_weights(\"/data/My Drive/Colab Notebooks/data/model_machine_translation_5.h5\")\n",
        "#from keras.models import load_model\n",
        "#del model\n",
        "#model = load_model('/data/My Drive/Colab Notebooks/data/model_machine_translation_5.h5')\n",
        "#model.summary()\n",
        "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "#encoder_input = model.get_layer(name = 'input_1')\n",
        "#decoder_input = model.get_layer(name = 'input_2')\n",
        "#encoder_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkA-X_UDwwSh",
        "colab_type": "code",
        "outputId": "37359407-b53e-4579-b079-132ea812094c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "from keras.layers import Input\n",
        "\n",
        "encoder_input = Input(shape=(None, encoder_vector_len))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYtSo-iZwwSk",
        "colab_type": "text"
      },
      "source": [
        "Als nächstes definiert einen LSTM-Layer, der 256 hidden units hat. Die Ausgabe des Layers soll später an den Decoder 'verfüttert' werden. Seht in der Dokumentation nach wie man den Thought-Vektor zurückbekommen kann (https://keras.io/layers/recurrent/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMw4D_DnwwSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import LSTM\n",
        "\n",
        "encoder = LSTM(units=256, return_state=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JoinIXrwwSm",
        "colab_type": "text"
      },
      "source": [
        "Verbindet nun den `encoder_input`-Layer mit dem `encoder`-Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP3ugktPwwSn",
        "colab_type": "code",
        "outputId": "812a428b-268d-441e-b4b8-73654ed7e886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "_, state_h, state_c = encoder(encoder_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUMV3Zk1wwSp",
        "colab_type": "text"
      },
      "source": [
        "Der Encoder wäre damit fertig implementiert."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGQfKUBDwwSp",
        "colab_type": "text"
      },
      "source": [
        "### Decoder\n",
        "\n",
        "Auch der Decoder fängt mit einem Input-Layer an. Definiert einen Input-Layer analog zum Encoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIpC-H11wwSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_input = Input(shape=(None, decoder_vector_len))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUPlX_rawwSs",
        "colab_type": "text"
      },
      "source": [
        "Wie auch im Encoder, ist das Herzstück ein LSTM-Layer. Definiert einen LSTM-Layer mit 256 hidden units. Seht in der Dokumentation nach, wie man neben den Thought-Vektoren, auch die komplette Ausgabe-Sequence zurückbekommt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxmQsfFywwSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_lstm = LSTM(256, return_state=True, return_sequences=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe33Jg_1wwSu",
        "colab_type": "text"
      },
      "source": [
        "Verbindet nun den `decoder_input`-Layer mit dem `decoder_lstm`-Layer. An welcher der drei Ausgaben sind wir hier interessiert? Außerdem müssen wir hier, den Thought-Vektor des Encoders mit übergeben, dies geschieht über den `initial_state`-Parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0hQ8HsHwwSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_outputs, _, _ = decoder_lstm(decoder_input, initial_state=[state_h, state_c])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRnRu6-bwwSw",
        "colab_type": "text"
      },
      "source": [
        "Den Abschluss unseres Modells bildet ein Dense-Layer, der gleich viele `hidden_units` wie der Input-Layer des Decoders hat. Als Aktivierungsfunktion nehmen wir die Softmax-Funktion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLUGiG5KwwSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense\n",
        "\n",
        "decoder_layer = Dense(decoder_vector_len, activation=\"softmax\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoK_oS_TwwS3",
        "colab_type": "text"
      },
      "source": [
        "Verbindet diesen Layer mit dem bisherigen Decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2W1g_9kwwS4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder = decoder_layer(decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkY1eU3jwwS6",
        "colab_type": "text"
      },
      "source": [
        "Wir haben nun alle Elemente für ein Sequence-To-Sequence-Modell zusammen. Im letzten Schritt bauen wir das ganze Modell zusammen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMEsJRetwwS6",
        "colab_type": "code",
        "outputId": "e7a67eaf-52f9-4bb7-9122-407d9502adaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "from keras import Model\n",
        "\n",
        "model = Model(inputs=[encoder_input, decoder_input], outputs=[decoder])\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, 67)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, None, 89)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 256), (None, 331776      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 256),  354304      input_2[0][0]                    \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 89)     22873       lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 708,953\n",
            "Trainable params: 708,953\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SasN0sXjwwS8",
        "colab_type": "text"
      },
      "source": [
        "Fertig! Nun kann das Modell trainiert werden."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cURRMRhFwwS8",
        "colab_type": "code",
        "outputId": "5f46b9e1-0993-4f62-e32e-ec7eee582617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=64,\n",
        "          epochs=100,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 4000 samples, validate on 1000 samples\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "4000/4000 [==============================] - 9s 2ms/step - loss: 0.9018 - val_loss: 0.9388\n",
            "Epoch 2/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.8025 - val_loss: 0.8796\n",
            "Epoch 3/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.7158 - val_loss: 0.7920\n",
            "Epoch 4/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.6352 - val_loss: 0.7121\n",
            "Epoch 5/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.5811 - val_loss: 0.6634\n",
            "Epoch 6/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.5445 - val_loss: 0.6311\n",
            "Epoch 7/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.5170 - val_loss: 0.6175\n",
            "Epoch 8/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.4933 - val_loss: 0.5819\n",
            "Epoch 9/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.4730 - val_loss: 0.5644\n",
            "Epoch 10/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.4551 - val_loss: 0.5504\n",
            "Epoch 11/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.4375 - val_loss: 0.5357\n",
            "Epoch 12/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.4231 - val_loss: 0.5232\n",
            "Epoch 13/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.4090 - val_loss: 0.5122\n",
            "Epoch 14/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.3957 - val_loss: 0.5114\n",
            "Epoch 15/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.3848 - val_loss: 0.4996\n",
            "Epoch 16/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.3723 - val_loss: 0.4930\n",
            "Epoch 17/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.3626 - val_loss: 0.4860\n",
            "Epoch 18/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.3521 - val_loss: 0.4842\n",
            "Epoch 19/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.3421 - val_loss: 0.4745\n",
            "Epoch 20/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.3324 - val_loss: 0.4704\n",
            "Epoch 21/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.3234 - val_loss: 0.4703\n",
            "Epoch 22/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.3136 - val_loss: 0.4678\n",
            "Epoch 23/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.3055 - val_loss: 0.4652\n",
            "Epoch 24/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.2970 - val_loss: 0.4626\n",
            "Epoch 25/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.2880 - val_loss: 0.4658\n",
            "Epoch 26/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.2802 - val_loss: 0.4647\n",
            "Epoch 27/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.2725 - val_loss: 0.4645\n",
            "Epoch 28/100\n",
            "4000/4000 [==============================] - 8s 2ms/step - loss: 0.2646 - val_loss: 0.4640\n",
            "Epoch 29/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.2572 - val_loss: 0.4676\n",
            "Epoch 30/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.2501 - val_loss: 0.4758\n",
            "Epoch 31/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.2433 - val_loss: 0.4697\n",
            "Epoch 32/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.2361 - val_loss: 0.4709\n",
            "Epoch 33/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.2300 - val_loss: 0.4726\n",
            "Epoch 34/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.2230 - val_loss: 0.4750\n",
            "Epoch 35/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.2171 - val_loss: 0.4807\n",
            "Epoch 36/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.2117 - val_loss: 0.4823\n",
            "Epoch 37/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.2062 - val_loss: 0.4774\n",
            "Epoch 38/100\n",
            "4000/4000 [==============================] - 8s 2ms/step - loss: 0.1997 - val_loss: 0.4828\n",
            "Epoch 39/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1948 - val_loss: 0.4899\n",
            "Epoch 40/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1889 - val_loss: 0.4863\n",
            "Epoch 41/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1841 - val_loss: 0.4956\n",
            "Epoch 42/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1793 - val_loss: 0.4903\n",
            "Epoch 43/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1746 - val_loss: 0.5120\n",
            "Epoch 44/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1703 - val_loss: 0.5092\n",
            "Epoch 45/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1653 - val_loss: 0.5077\n",
            "Epoch 46/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1612 - val_loss: 0.5080\n",
            "Epoch 47/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1566 - val_loss: 0.5126\n",
            "Epoch 48/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1529 - val_loss: 0.5195\n",
            "Epoch 49/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1494 - val_loss: 0.5290\n",
            "Epoch 50/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1456 - val_loss: 0.5328\n",
            "Epoch 51/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1420 - val_loss: 0.5278\n",
            "Epoch 52/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1390 - val_loss: 0.5434\n",
            "Epoch 53/100\n",
            "4000/4000 [==============================] - 6s 2ms/step - loss: 0.1353 - val_loss: 0.5383\n",
            "Epoch 54/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1319 - val_loss: 0.5471\n",
            "Epoch 55/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1296 - val_loss: 0.5491\n",
            "Epoch 56/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1261 - val_loss: 0.5596\n",
            "Epoch 57/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1237 - val_loss: 0.5485\n",
            "Epoch 58/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1208 - val_loss: 0.5625\n",
            "Epoch 59/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1182 - val_loss: 0.5669\n",
            "Epoch 60/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1160 - val_loss: 0.5830\n",
            "Epoch 61/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1131 - val_loss: 0.5772\n",
            "Epoch 62/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1112 - val_loss: 0.5787\n",
            "Epoch 63/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1088 - val_loss: 0.5807\n",
            "Epoch 64/100\n",
            "4000/4000 [==============================] - 6s 2ms/step - loss: 0.1064 - val_loss: 0.5877\n",
            "Epoch 65/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1045 - val_loss: 0.5915\n",
            "Epoch 66/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.1023 - val_loss: 0.5930\n",
            "Epoch 67/100\n",
            "4000/4000 [==============================] - 6s 2ms/step - loss: 0.1007 - val_loss: 0.5947\n",
            "Epoch 68/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0983 - val_loss: 0.6062\n",
            "Epoch 69/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0969 - val_loss: 0.6217\n",
            "Epoch 70/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0950 - val_loss: 0.6095\n",
            "Epoch 71/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0933 - val_loss: 0.6160\n",
            "Epoch 72/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0916 - val_loss: 0.6088\n",
            "Epoch 73/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0903 - val_loss: 0.6335\n",
            "Epoch 74/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0886 - val_loss: 0.6251\n",
            "Epoch 75/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0869 - val_loss: 0.6280\n",
            "Epoch 76/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0855 - val_loss: 0.6282\n",
            "Epoch 77/100\n",
            "4000/4000 [==============================] - 6s 2ms/step - loss: 0.0839 - val_loss: 0.6404\n",
            "Epoch 78/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0829 - val_loss: 0.6383\n",
            "Epoch 79/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0814 - val_loss: 0.6428\n",
            "Epoch 80/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0801 - val_loss: 0.6528\n",
            "Epoch 81/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0787 - val_loss: 0.6540\n",
            "Epoch 82/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0776 - val_loss: 0.6527\n",
            "Epoch 83/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0762 - val_loss: 0.6582\n",
            "Epoch 84/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0749 - val_loss: 0.6617\n",
            "Epoch 85/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0736 - val_loss: 0.6611\n",
            "Epoch 86/100\n",
            "4000/4000 [==============================] - 6s 2ms/step - loss: 0.0728 - val_loss: 0.6668\n",
            "Epoch 87/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0710 - val_loss: 0.6745\n",
            "Epoch 88/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0704 - val_loss: 0.6720\n",
            "Epoch 89/100\n",
            "4000/4000 [==============================] - 6s 2ms/step - loss: 0.0697 - val_loss: 0.6770\n",
            "Epoch 90/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0685 - val_loss: 0.6865\n",
            "Epoch 91/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0669 - val_loss: 0.6872\n",
            "Epoch 92/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0667 - val_loss: 0.6812\n",
            "Epoch 93/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0656 - val_loss: 0.6970\n",
            "Epoch 94/100\n",
            "4000/4000 [==============================] - 6s 2ms/step - loss: 0.0643 - val_loss: 0.6868\n",
            "Epoch 95/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0637 - val_loss: 0.6979\n",
            "Epoch 96/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0625 - val_loss: 0.6971\n",
            "Epoch 97/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0615 - val_loss: 0.7077\n",
            "Epoch 98/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0609 - val_loss: 0.7083\n",
            "Epoch 99/100\n",
            "4000/4000 [==============================] - 7s 2ms/step - loss: 0.0598 - val_loss: 0.7063\n",
            "Epoch 100/100\n",
            "4000/4000 [==============================] - 6s 2ms/step - loss: 0.0592 - val_loss: 0.7054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8bd46d4be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOw2rxMzOILt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.save(\"/data/My Drive/Colab Notebooks/data/model_machine_translation_5.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U7kswHswwS9",
        "colab_type": "text"
      },
      "source": [
        "### Inferenz\n",
        "\n",
        "Um mit dem trainierten Modell Texte übersetzen zu können, müssen wir nun noch unser bisheriges Modell etwas umbauen.\n",
        "Im ersten Schritt definieren wir uns ein `Model` das einen Eingabetext encodiert. Als Eingabe hat dieses `Model` den bisherigen `encoder_input`-Layer und die Thought-Vektoren als Output. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y79c0cNWwwS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model = Model(encoder_input, [state_h, state_c])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOiRWS9zwwTA",
        "colab_type": "text"
      },
      "source": [
        "Etwas komplizierter ist das Decoder-Modell. Als Input nimmt es zum einen die Thought-Vektoren des Encoders, zum anderen den `decoder_input`-Layer von oben.\n",
        "Definiert zunächst zwei Input-Layer für die Thought-Vektoren."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqtJytbSwwTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_state_input_h = Input(shape=(256,))\n",
        "decoder_state_input_c = Input(shape=(256,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-pIMuU8wwTC",
        "colab_type": "text"
      },
      "source": [
        "Setzt diese beiden Input-Layer als `initial_state` und den `decoder_input`-Layer als Input in das `decoder_lstm` von oben ein."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iE5uqBOwwTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_input, initial_state=[decoder_state_input_h, decoder_state_input_c])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GVtnOmFwwTE",
        "colab_type": "text"
      },
      "source": [
        "Setzt nun den `decoder_outputs`-Tensor in den `decoder_layer` von oben ein."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGYCtAXZwwTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_outputs = decoder_layer(decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGXPhxLFwwTH",
        "colab_type": "text"
      },
      "source": [
        "Nun können wir ein `Model` zusammenbauen, das uns als Decoder dient. Input ist hier der `decoder_input`-Layer, zusammen mit den `decoder_state_input_h` und dem `decoder_state_input_c`-Tensor. Als Output dient uns der `decoder_outputs`-Tensor und der `state_h` mit dem `state_c`-Tensor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqWFY4o5wwTH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_model = Model(inputs=[decoder_input,decoder_state_input_h,decoder_state_input_c], outputs=[decoder_outputs, state_h, state_c])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBkMw92WwwTJ",
        "colab_type": "text"
      },
      "source": [
        "Ein kleiner Zwischenschritt ist noch nötig, bevor wir mit dem Modell Texte übersetzen können. Damit wir aus unseren Vektoren wieder Texte bekommen, müssen wir noch das Dictionary `reverse_french_token_index` befüllen, das die \"Umkehrung\" von `french_token_index` ist."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYJTFGGkwwTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_french_token_index = {char: index for index, char in french_token_index.items()} #TODO\n",
        "reverse_french_token_index\n",
        "reverse_target_char_index = {char: index for index, char in english_token_index.items()} #TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPy1mmeIwwTL",
        "colab_type": "text"
      },
      "source": [
        "Nun können wir eine Funktion `translate` implementieren, die als Eingabe einen englischen Text als Vektoren nimmt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3r5YKScwwTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(english_text):\n",
        "    # Wandelt mit dem encoder_model, `english_text` in einen Thought-Vektor um\n",
        "    thought = encoder_model.predict(english_text)\n",
        "    \n",
        "    # Als Input für den Decoder, wir zum einen der thought-Vektor benötigt, \n",
        "    # zum anderen die Vektor-Repräsentation des Startsymbols\n",
        "    french_text = np.zeros((1, 1, decoder_vector_len))\n",
        "    \n",
        "    # Belegt die Komponente des Start-Symbols mit 1\n",
        "    french_text[0, 0, french_token_index['🏳']] = 1.\n",
        "    \n",
        "    # und übergebt beides an den Decoder\n",
        "    chars, h, c = decoder_model.predict([french_text] + thought)\n",
        "    \n",
        "    # chars beinhaltet eine 1 x 1 x decoder_vector_len Matrix, die für jeden französische Character\n",
        "    # eine Art \"Wahrscheinlichkeit\" angibt.\n",
        "    # Findet die Komponente, mit der größten Wahrscheinlichkeit und wandelt sie in ein Character um\n",
        "    french_char_idx = np.argmax(chars[0, -1, :])\n",
        "    \n",
        "    french_char = reverse_french_token_index[french_char_idx]\n",
        "\n",
        "    decoded_sentence = ''\n",
        "    while french_char != '🏴':\n",
        "      # die nächste Prediction wäre dann\n",
        "      french_text = np.zeros((1, 1, decoder_vector_len))\n",
        "      french_text[0, 0, french_char_idx] = 1.\n",
        "      chars, h, c = decoder_model.predict([french_text, h, c])\n",
        "      \n",
        "      french_char_idx = np.argmax(chars[0, -1, :])\n",
        "      \n",
        "      french_char = reverse_french_token_index[french_char_idx]\n",
        "      decoded_sentence += french_char\n",
        "    \n",
        "    # baut eine Schleife mit geeigneter Abbruchbedingung, die die Schritte von oben umfasst \n",
        "    # und dabei aus french_char einen übersetzen Text zusammenbaut\n",
        "    return decoded_sentence[:-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GhH7rppwwTN",
        "colab_type": "code",
        "outputId": "57a6a834-eef2-428c-bc1a-3588f4795c94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "for seq_index in range(400,415):\n",
        "  english_text = encoder_input_data[seq_index:seq_index+1] \n",
        "  french_text = translate(english_text)\n",
        "  print(pairs_cleaned[seq_index])\n",
        "  print(french_text)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(\"Let's go!\", 'Allons-y !')\n",
            "Faisons-le !\n",
            "(\"Let's go.\", 'Allons-y !')\n",
            "Allons-y !\n",
            "('Look out!', 'Attention !')\n",
            "Attentoir !\n",
            "('Look out!', 'Regarde donc !')\n",
            "Attentoir !\n",
            "('Marry me.', 'Épouse-moi !')\n",
            "Épousez-moi !\n",
            "('Marry me.', 'Épousez-moi !')\n",
            "Épousez-moi !\n",
            "('May I go?', 'Puis-je partir ?')\n",
            "Puis-je m'y rendre ?\n",
            "('May I go?', 'Puis-je y aller ?')\n",
            "Puis-je m'y rendre ?\n",
            "('May I go?', \"Puis-je m'y rendre ?\")\n",
            "Puis-je m'y rendre ?\n",
            "('Save Tom.', 'Sauve Tom.')\n",
            "Sauve Tom.\n",
            "('Save Tom.', 'Sauvez Tom.')\n",
            "Sauve Tom.\n",
            "('She came.', 'Elle est venue.')\n",
            "Elle est venue.\n",
            "('She died.', 'Elle est morte.')\n",
            "Elle est morte.\n",
            "('She runs.', 'Elle court.')\n",
            "Elle court.\n",
            "('Sit down!', 'Assieds-toi !')\n",
            "Assieds-toi !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7m07cThwwTO",
        "colab_type": "text"
      },
      "source": [
        "### Hausaufgabe: \n",
        " Implementiert die BLEU-Metrik wie auf den Folien nach und evaluiert euer Modell damit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjJotDmRbfqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "def getMN(n, reference, translated_text):\n",
        "  reference_tokens = reference.split()\n",
        "  translation_tokens = translated_text.split()\n",
        "  number_correct = 0\n",
        "  for i in range(len(reference_tokens) - n + 1):\n",
        "    n_gramm = ' '.join(reference_tokens[i:i+n])\n",
        "    for j in range(len(translation_tokens) - n + 1):\n",
        "      if n_gramm == ' '.join(translation_tokens[j:j+n]):\n",
        "        number_correct += 1\n",
        "  return number_correct\n",
        "\n",
        "def getWN(n, translated_text):\n",
        "  return len(translated_text.split()) - n + 1\n",
        "\n",
        "def getMNRef(n, reference):\n",
        "  return len(reference.split()) - n + 1\n",
        "\n",
        "def getPN(n, reference, translated_text):\n",
        "  return (min(getMN(n, reference, translated_text), getMNRef(n, reference))) / getWN(n, translated_text)\n",
        "\n",
        "def getBLEU(reference, translated_text):\n",
        "  bleu = 1\n",
        "  lenTranslated = len(translated_text.split())\n",
        "  lenReference = len(reference.split())\n",
        "  r = min(5, min(lenReference, lenTranslated))\n",
        "  for n in range(r):\n",
        "    bleu *= getPN(n, reference, translated_text)\n",
        "  return min(1, math.exp(1 - (lenReference/lenTranslated))) * (bleu ** (1/4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqHwXcxmpSFK",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_3NmVOOo5gR",
        "colab_type": "code",
        "outputId": "2dd12d4e-03b6-4f0d-c1f7-77f41f6cfaec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "getMN(3, \"the cat sat on the mat\", \"the the on cat sat mat\")\n",
        "getPN(3, \"the cat sat on the mat\", \"the cat sat on the mat\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBO2ZF4Dqy2y",
        "colab_type": "code",
        "outputId": "1b99146d-0e4d-4b68-bb2d-dd961e285782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "n = 3\n",
        "reference = \"Israeli officials are responsible for airport security\"\n",
        "translated_text = \"airport security Israeli officials are responsible\"\n",
        "\n",
        "print(\"getMN: \", getMN(n, reference, translated_text))\n",
        "print(\"getWN: \", getWN(n, translated_text))\n",
        "print(\"getMNRef: \", getMNRef(n, reference))\n",
        "print(\"getPN: \", getPN(n, reference, translated_text))\n",
        "print(\"getBLEU: \", getBLEU(reference, translated_text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "getMN:  2\n",
            "getWN:  4\n",
            "getMNRef:  5\n",
            "getPN:  0.5\n",
            "getBLEU:  0.5288716132517868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvjqx4Ie6M3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETLk24m0tlc-",
        "colab_type": "code",
        "outputId": "93070afd-bbea-4556-9262-96afb7b10320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sumBleu = 0\n",
        "\n",
        "for seq_index in range(len(pairs_cleaned)):\n",
        "  english_text = encoder_input_data[seq_index:seq_index+1] \n",
        "  french_text = translate(english_text)\n",
        "  sumBleu += getBLEU(pairs_cleaned[seq_index][1], french_text)\n",
        "\n",
        "print(sumBleu / len(pairs_cleaned))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.429910475420674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQTPNr1O6ITd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}